Log file created at: 2017/09/28 20:40:43
Running on machine: DNR4IPCOUPNVNIN
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0928 20:40:43.922101  6508 caffe.cpp:211] Use CPU.
I0928 20:40:43.923100  6508 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 600000
base_lr: 0.1
display: 20
max_iter: 10
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 150000
snapshot: 5000
snapshot_prefix: "snapshots/test"
solver_mode: CPU
net: "resnet_20_train_test_STN.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0928 20:40:43.942101  6508 solver.cpp:91] Creating training net from net file: resnet_20_train_test_STN.prototxt
I0928 20:40:43.944102  6508 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet_20_train_test_STN.prototxt
I0928 20:40:43.944102  6508 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 20:40:43.945101  6508 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer ImageData1
I0928 20:40:43.945101  6508 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0928 20:40:43.946101  6508 net.cpp:58] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "ImageData1"
  type: "ImageData"
  top: "ImageData1"
  top: "ImageData2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    crop_size: 112
    mean_value: 128
  }
  image_data_param {
    source: "image_list.txt"
    batch_size: 1
    shuffle: true
    new_height: 0
    new_width: 0
    is_color: false
    root_folder: ""
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "ImageData1"
  top: "Convolution1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling2"
  top: "InnerProduct1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "InnerProduct2"
  top: "InnerProduct3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 6
    weight_filler {
      type: "gaussian"
      value: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Transformer1"
  type: "Transformer"
  bottom: "ImageData1"
  bottom: "InnerProduct3"
  top: "Transformer1"
  transformer_param {
    num_theta: 6
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Transformer1"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution5"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution7"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution9"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise3"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel1"
  type: "PadChannel"
  bottom: "Pooling3"
  top: "PadChannel1"
  pad_channel_param {
    num_channels_to_pad: 16
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "PadChannel1"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution15"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Eltwise6"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel2"
  type: "PadChannel"
  bottom: "Pooling4"
  top: "PadChannel2"
  pad_channel_param {
    num_channels_to_pad: 32
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "PadChannel2"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Pooling5"
  top: "InnerProduct4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "SoftmaxWithLoss1"
}
I0928 20:40:44.012105  6508 layer_factory.cpp:58] Creating layer ImageData1
I0928 20:40:44.012105  6508 net.cpp:100] Creating Layer ImageData1
I0928 20:40:44.013105  6508 net.cpp:408] ImageData1 -> ImageData1
I0928 20:40:44.013105  6508 net.cpp:408] ImageData1 -> ImageData2
I0928 20:40:44.013105  6508 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0928 20:40:44.013105  6508 image_data_layer.cpp:38] Opening file image_list.txt
I0928 20:40:44.015105  6508 image_data_layer.cpp:53] Shuffling data
I0928 20:40:44.015105  6508 image_data_layer.cpp:58] A total of 1 images.
I0928 20:40:44.016105  6508 image_data_layer.cpp:85] output data size: 1,1,112,112
I0928 20:40:44.016105  6508 net.cpp:150] Setting up ImageData1
I0928 20:40:44.016105  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.016105  6508 net.cpp:157] Top shape: 1 (1)
I0928 20:40:44.016105  6508 net.cpp:165] Memory required for data: 50180
I0928 20:40:44.017105  6508 layer_factory.cpp:58] Creating layer ImageData1_ImageData1_0_split
I0928 20:40:44.017105  6508 net.cpp:100] Creating Layer ImageData1_ImageData1_0_split
I0928 20:40:44.017105  6508 net.cpp:434] ImageData1_ImageData1_0_split <- ImageData1
I0928 20:40:44.017105  6508 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_0
I0928 20:40:44.017105  6508 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_1
I0928 20:40:44.017105  6508 net.cpp:150] Setting up ImageData1_ImageData1_0_split
I0928 20:40:44.017105  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.017105  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.018105  6508 net.cpp:165] Memory required for data: 150532
I0928 20:40:44.018105  6508 layer_factory.cpp:58] Creating layer Convolution1
I0928 20:40:44.018105  6508 net.cpp:100] Creating Layer Convolution1
I0928 20:40:44.018105  6508 net.cpp:434] Convolution1 <- ImageData1_ImageData1_0_split_0
I0928 20:40:44.018105  6508 net.cpp:408] Convolution1 -> Convolution1
I0928 20:40:44.018105  6508 net.cpp:150] Setting up Convolution1
I0928 20:40:44.018105  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.019105  6508 net.cpp:165] Memory required for data: 953348
I0928 20:40:44.019105  6508 layer_factory.cpp:58] Creating layer ReLU1
I0928 20:40:44.019105  6508 net.cpp:100] Creating Layer ReLU1
I0928 20:40:44.019105  6508 net.cpp:434] ReLU1 <- Convolution1
I0928 20:40:44.019105  6508 net.cpp:395] ReLU1 -> Convolution1 (in-place)
I0928 20:40:44.019105  6508 net.cpp:150] Setting up ReLU1
I0928 20:40:44.019105  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.019105  6508 net.cpp:165] Memory required for data: 1756164
I0928 20:40:44.019105  6508 layer_factory.cpp:58] Creating layer Pooling1
I0928 20:40:44.019105  6508 net.cpp:100] Creating Layer Pooling1
I0928 20:40:44.020105  6508 net.cpp:434] Pooling1 <- Convolution1
I0928 20:40:44.020105  6508 net.cpp:408] Pooling1 -> Pooling1
I0928 20:40:44.020105  6508 net.cpp:150] Setting up Pooling1
I0928 20:40:44.020105  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.020105  6508 net.cpp:165] Memory required for data: 1956868
I0928 20:40:44.020105  6508 layer_factory.cpp:58] Creating layer Convolution2
I0928 20:40:44.020105  6508 net.cpp:100] Creating Layer Convolution2
I0928 20:40:44.021106  6508 net.cpp:434] Convolution2 <- Pooling1
I0928 20:40:44.021106  6508 net.cpp:408] Convolution2 -> Convolution2
I0928 20:40:44.021106  6508 net.cpp:150] Setting up Convolution2
I0928 20:40:44.021106  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.021106  6508 net.cpp:165] Memory required for data: 2157572
I0928 20:40:44.021106  6508 layer_factory.cpp:58] Creating layer ReLU2
I0928 20:40:44.021106  6508 net.cpp:100] Creating Layer ReLU2
I0928 20:40:44.022105  6508 net.cpp:434] ReLU2 <- Convolution2
I0928 20:40:44.022105  6508 net.cpp:395] ReLU2 -> Convolution2 (in-place)
I0928 20:40:44.022105  6508 net.cpp:150] Setting up ReLU2
I0928 20:40:44.022105  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.022105  6508 net.cpp:165] Memory required for data: 2358276
I0928 20:40:44.023105  6508 layer_factory.cpp:58] Creating layer Pooling2
I0928 20:40:44.023105  6508 net.cpp:100] Creating Layer Pooling2
I0928 20:40:44.023105  6508 net.cpp:434] Pooling2 <- Convolution2
I0928 20:40:44.023105  6508 net.cpp:408] Pooling2 -> Pooling2
I0928 20:40:44.023105  6508 net.cpp:150] Setting up Pooling2
I0928 20:40:44.023105  6508 net.cpp:157] Top shape: 1 16 28 28 (12544)
I0928 20:40:44.023105  6508 net.cpp:165] Memory required for data: 2408452
I0928 20:40:44.024106  6508 layer_factory.cpp:58] Creating layer InnerProduct1
I0928 20:40:44.024106  6508 net.cpp:100] Creating Layer InnerProduct1
I0928 20:40:44.024106  6508 net.cpp:434] InnerProduct1 <- Pooling2
I0928 20:40:44.024106  6508 net.cpp:408] InnerProduct1 -> InnerProduct1
I0928 20:40:44.027107  6508 net.cpp:150] Setting up InnerProduct1
I0928 20:40:44.027107  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.027107  6508 net.cpp:165] Memory required for data: 2408516
I0928 20:40:44.027107  6508 layer_factory.cpp:58] Creating layer ReLU3
I0928 20:40:44.027107  6508 net.cpp:100] Creating Layer ReLU3
I0928 20:40:44.028106  6508 net.cpp:434] ReLU3 <- InnerProduct1
I0928 20:40:44.028106  6508 net.cpp:395] ReLU3 -> InnerProduct1 (in-place)
I0928 20:40:44.028106  6508 net.cpp:150] Setting up ReLU3
I0928 20:40:44.028106  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.028106  6508 net.cpp:165] Memory required for data: 2408580
I0928 20:40:44.028106  6508 layer_factory.cpp:58] Creating layer InnerProduct2
I0928 20:40:44.028106  6508 net.cpp:100] Creating Layer InnerProduct2
I0928 20:40:44.028106  6508 net.cpp:434] InnerProduct2 <- InnerProduct1
I0928 20:40:44.029106  6508 net.cpp:408] InnerProduct2 -> InnerProduct2
I0928 20:40:44.029106  6508 net.cpp:150] Setting up InnerProduct2
I0928 20:40:44.029106  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.029106  6508 net.cpp:165] Memory required for data: 2408644
I0928 20:40:44.029106  6508 layer_factory.cpp:58] Creating layer InnerProduct3
I0928 20:40:44.029106  6508 net.cpp:100] Creating Layer InnerProduct3
I0928 20:40:44.029106  6508 net.cpp:434] InnerProduct3 <- InnerProduct2
I0928 20:40:44.029106  6508 net.cpp:408] InnerProduct3 -> InnerProduct3
I0928 20:40:44.029106  6508 net.cpp:150] Setting up InnerProduct3
I0928 20:40:44.029106  6508 net.cpp:157] Top shape: 1 6 (6)
I0928 20:40:44.030107  6508 net.cpp:165] Memory required for data: 2408668
I0928 20:40:44.030107  6508 layer_factory.cpp:58] Creating layer Transformer1
I0928 20:40:44.030107  6508 net.cpp:100] Creating Layer Transformer1
I0928 20:40:44.030107  6508 net.cpp:434] Transformer1 <- ImageData1_ImageData1_0_split_1
I0928 20:40:44.030107  6508 net.cpp:434] Transformer1 <- InnerProduct3
I0928 20:40:44.030107  6508 net.cpp:408] Transformer1 -> Transformer1
I0928 20:40:44.031106  6508 net.cpp:150] Setting up Transformer1
I0928 20:40:44.031106  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.031106  6508 net.cpp:165] Memory required for data: 2458844
I0928 20:40:44.031106  6508 layer_factory.cpp:58] Creating layer Convolution3
I0928 20:40:44.031106  6508 net.cpp:100] Creating Layer Convolution3
I0928 20:40:44.031106  6508 net.cpp:434] Convolution3 <- Transformer1
I0928 20:40:44.032106  6508 net.cpp:408] Convolution3 -> Convolution3
I0928 20:40:44.032106  6508 net.cpp:150] Setting up Convolution3
I0928 20:40:44.032106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.032106  6508 net.cpp:165] Memory required for data: 3261660
I0928 20:40:44.032106  6508 layer_factory.cpp:58] Creating layer BatchNorm1
I0928 20:40:44.032106  6508 net.cpp:100] Creating Layer BatchNorm1
I0928 20:40:44.032106  6508 net.cpp:434] BatchNorm1 <- Convolution3
I0928 20:40:44.032106  6508 net.cpp:395] BatchNorm1 -> Convolution3 (in-place)
I0928 20:40:44.032106  6508 net.cpp:150] Setting up BatchNorm1
I0928 20:40:44.033107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.033107  6508 net.cpp:165] Memory required for data: 4064476
I0928 20:40:44.033107  6508 layer_factory.cpp:58] Creating layer Scale1
I0928 20:40:44.033107  6508 net.cpp:100] Creating Layer Scale1
I0928 20:40:44.033107  6508 net.cpp:434] Scale1 <- Convolution3
I0928 20:40:44.033107  6508 net.cpp:395] Scale1 -> Convolution3 (in-place)
I0928 20:40:44.033107  6508 layer_factory.cpp:58] Creating layer Scale1
I0928 20:40:44.033107  6508 net.cpp:150] Setting up Scale1
I0928 20:40:44.034106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.034106  6508 net.cpp:165] Memory required for data: 4867292
I0928 20:40:44.034106  6508 layer_factory.cpp:58] Creating layer ReLU4
I0928 20:40:44.034106  6508 net.cpp:100] Creating Layer ReLU4
I0928 20:40:44.034106  6508 net.cpp:434] ReLU4 <- Convolution3
I0928 20:40:44.034106  6508 net.cpp:395] ReLU4 -> Convolution3 (in-place)
I0928 20:40:44.034106  6508 net.cpp:150] Setting up ReLU4
I0928 20:40:44.034106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.034106  6508 net.cpp:165] Memory required for data: 5670108
I0928 20:40:44.034106  6508 layer_factory.cpp:58] Creating layer Convolution3_ReLU4_0_split
I0928 20:40:44.035106  6508 net.cpp:100] Creating Layer Convolution3_ReLU4_0_split
I0928 20:40:44.035106  6508 net.cpp:434] Convolution3_ReLU4_0_split <- Convolution3
I0928 20:40:44.035106  6508 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_0
I0928 20:40:44.035106  6508 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_1
I0928 20:40:44.035106  6508 net.cpp:150] Setting up Convolution3_ReLU4_0_split
I0928 20:40:44.035106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.035106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.035106  6508 net.cpp:165] Memory required for data: 7275740
I0928 20:40:44.035106  6508 layer_factory.cpp:58] Creating layer Convolution4
I0928 20:40:44.036106  6508 net.cpp:100] Creating Layer Convolution4
I0928 20:40:44.036106  6508 net.cpp:434] Convolution4 <- Convolution3_ReLU4_0_split_0
I0928 20:40:44.036106  6508 net.cpp:408] Convolution4 -> Convolution4
I0928 20:40:44.036106  6508 net.cpp:150] Setting up Convolution4
I0928 20:40:44.036106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.036106  6508 net.cpp:165] Memory required for data: 8078556
I0928 20:40:44.036106  6508 layer_factory.cpp:58] Creating layer BatchNorm2
I0928 20:40:44.036106  6508 net.cpp:100] Creating Layer BatchNorm2
I0928 20:40:44.037106  6508 net.cpp:434] BatchNorm2 <- Convolution4
I0928 20:40:44.037106  6508 net.cpp:395] BatchNorm2 -> Convolution4 (in-place)
I0928 20:40:44.037106  6508 net.cpp:150] Setting up BatchNorm2
I0928 20:40:44.037106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.037106  6508 net.cpp:165] Memory required for data: 8881372
I0928 20:40:44.037106  6508 layer_factory.cpp:58] Creating layer Scale2
I0928 20:40:44.037106  6508 net.cpp:100] Creating Layer Scale2
I0928 20:40:44.038106  6508 net.cpp:434] Scale2 <- Convolution4
I0928 20:40:44.038106  6508 net.cpp:395] Scale2 -> Convolution4 (in-place)
I0928 20:40:44.038106  6508 layer_factory.cpp:58] Creating layer Scale2
I0928 20:40:44.038106  6508 net.cpp:150] Setting up Scale2
I0928 20:40:44.038106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.038106  6508 net.cpp:165] Memory required for data: 9684188
I0928 20:40:44.038106  6508 layer_factory.cpp:58] Creating layer ReLU5
I0928 20:40:44.038106  6508 net.cpp:100] Creating Layer ReLU5
I0928 20:40:44.039106  6508 net.cpp:434] ReLU5 <- Convolution4
I0928 20:40:44.039106  6508 net.cpp:395] ReLU5 -> Convolution4 (in-place)
I0928 20:40:44.039106  6508 net.cpp:150] Setting up ReLU5
I0928 20:40:44.039106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.039106  6508 net.cpp:165] Memory required for data: 10487004
I0928 20:40:44.039106  6508 layer_factory.cpp:58] Creating layer Convolution5
I0928 20:40:44.039106  6508 net.cpp:100] Creating Layer Convolution5
I0928 20:40:44.039106  6508 net.cpp:434] Convolution5 <- Convolution4
I0928 20:40:44.039106  6508 net.cpp:408] Convolution5 -> Convolution5
I0928 20:40:44.040107  6508 net.cpp:150] Setting up Convolution5
I0928 20:40:44.040107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.040107  6508 net.cpp:165] Memory required for data: 11289820
I0928 20:40:44.040107  6508 layer_factory.cpp:58] Creating layer BatchNorm3
I0928 20:40:44.040107  6508 net.cpp:100] Creating Layer BatchNorm3
I0928 20:40:44.040107  6508 net.cpp:434] BatchNorm3 <- Convolution5
I0928 20:40:44.040107  6508 net.cpp:395] BatchNorm3 -> Convolution5 (in-place)
I0928 20:40:44.040107  6508 net.cpp:150] Setting up BatchNorm3
I0928 20:40:44.041106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.041106  6508 net.cpp:165] Memory required for data: 12092636
I0928 20:40:44.041106  6508 layer_factory.cpp:58] Creating layer Scale3
I0928 20:40:44.041106  6508 net.cpp:100] Creating Layer Scale3
I0928 20:40:44.041106  6508 net.cpp:434] Scale3 <- Convolution5
I0928 20:40:44.041106  6508 net.cpp:395] Scale3 -> Convolution5 (in-place)
I0928 20:40:44.041106  6508 layer_factory.cpp:58] Creating layer Scale3
I0928 20:40:44.041106  6508 net.cpp:150] Setting up Scale3
I0928 20:40:44.041106  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.042107  6508 net.cpp:165] Memory required for data: 12895452
I0928 20:40:44.042107  6508 layer_factory.cpp:58] Creating layer Eltwise1
I0928 20:40:44.042107  6508 net.cpp:100] Creating Layer Eltwise1
I0928 20:40:44.042107  6508 net.cpp:434] Eltwise1 <- Convolution3_ReLU4_0_split_1
I0928 20:40:44.042107  6508 net.cpp:434] Eltwise1 <- Convolution5
I0928 20:40:44.042107  6508 net.cpp:408] Eltwise1 -> Eltwise1
I0928 20:40:44.042107  6508 net.cpp:150] Setting up Eltwise1
I0928 20:40:44.042107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.042107  6508 net.cpp:165] Memory required for data: 13698268
I0928 20:40:44.042107  6508 layer_factory.cpp:58] Creating layer Eltwise1_Eltwise1_0_split
I0928 20:40:44.043107  6508 net.cpp:100] Creating Layer Eltwise1_Eltwise1_0_split
I0928 20:40:44.043107  6508 net.cpp:434] Eltwise1_Eltwise1_0_split <- Eltwise1
I0928 20:40:44.043107  6508 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_0
I0928 20:40:44.043107  6508 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_1
I0928 20:40:44.043107  6508 net.cpp:150] Setting up Eltwise1_Eltwise1_0_split
I0928 20:40:44.043107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.043107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.043107  6508 net.cpp:165] Memory required for data: 15303900
I0928 20:40:44.043107  6508 layer_factory.cpp:58] Creating layer Convolution6
I0928 20:40:44.044107  6508 net.cpp:100] Creating Layer Convolution6
I0928 20:40:44.044107  6508 net.cpp:434] Convolution6 <- Eltwise1_Eltwise1_0_split_0
I0928 20:40:44.044107  6508 net.cpp:408] Convolution6 -> Convolution6
I0928 20:40:44.044107  6508 net.cpp:150] Setting up Convolution6
I0928 20:40:44.044107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.044107  6508 net.cpp:165] Memory required for data: 16106716
I0928 20:40:44.044107  6508 layer_factory.cpp:58] Creating layer BatchNorm4
I0928 20:40:44.044107  6508 net.cpp:100] Creating Layer BatchNorm4
I0928 20:40:44.044107  6508 net.cpp:434] BatchNorm4 <- Convolution6
I0928 20:40:44.045107  6508 net.cpp:395] BatchNorm4 -> Convolution6 (in-place)
I0928 20:40:44.045107  6508 net.cpp:150] Setting up BatchNorm4
I0928 20:40:44.045107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.045107  6508 net.cpp:165] Memory required for data: 16909532
I0928 20:40:44.045107  6508 layer_factory.cpp:58] Creating layer Scale4
I0928 20:40:44.045107  6508 net.cpp:100] Creating Layer Scale4
I0928 20:40:44.045107  6508 net.cpp:434] Scale4 <- Convolution6
I0928 20:40:44.045107  6508 net.cpp:395] Scale4 -> Convolution6 (in-place)
I0928 20:40:44.045107  6508 layer_factory.cpp:58] Creating layer Scale4
I0928 20:40:44.046108  6508 net.cpp:150] Setting up Scale4
I0928 20:40:44.046108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.046108  6508 net.cpp:165] Memory required for data: 17712348
I0928 20:40:44.046108  6508 layer_factory.cpp:58] Creating layer ReLU6
I0928 20:40:44.046108  6508 net.cpp:100] Creating Layer ReLU6
I0928 20:40:44.046108  6508 net.cpp:434] ReLU6 <- Convolution6
I0928 20:40:44.046108  6508 net.cpp:395] ReLU6 -> Convolution6 (in-place)
I0928 20:40:44.046108  6508 net.cpp:150] Setting up ReLU6
I0928 20:40:44.046108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.047107  6508 net.cpp:165] Memory required for data: 18515164
I0928 20:40:44.047107  6508 layer_factory.cpp:58] Creating layer Convolution7
I0928 20:40:44.047107  6508 net.cpp:100] Creating Layer Convolution7
I0928 20:40:44.047107  6508 net.cpp:434] Convolution7 <- Convolution6
I0928 20:40:44.047107  6508 net.cpp:408] Convolution7 -> Convolution7
I0928 20:40:44.047107  6508 net.cpp:150] Setting up Convolution7
I0928 20:40:44.047107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.047107  6508 net.cpp:165] Memory required for data: 19317980
I0928 20:40:44.047107  6508 layer_factory.cpp:58] Creating layer BatchNorm5
I0928 20:40:44.048107  6508 net.cpp:100] Creating Layer BatchNorm5
I0928 20:40:44.048107  6508 net.cpp:434] BatchNorm5 <- Convolution7
I0928 20:40:44.048107  6508 net.cpp:395] BatchNorm5 -> Convolution7 (in-place)
I0928 20:40:44.048107  6508 net.cpp:150] Setting up BatchNorm5
I0928 20:40:44.048107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.048107  6508 net.cpp:165] Memory required for data: 20120796
I0928 20:40:44.048107  6508 layer_factory.cpp:58] Creating layer Scale5
I0928 20:40:44.048107  6508 net.cpp:100] Creating Layer Scale5
I0928 20:40:44.048107  6508 net.cpp:434] Scale5 <- Convolution7
I0928 20:40:44.048107  6508 net.cpp:395] Scale5 -> Convolution7 (in-place)
I0928 20:40:44.049108  6508 layer_factory.cpp:58] Creating layer Scale5
I0928 20:40:44.049108  6508 net.cpp:150] Setting up Scale5
I0928 20:40:44.049108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.049108  6508 net.cpp:165] Memory required for data: 20923612
I0928 20:40:44.049108  6508 layer_factory.cpp:58] Creating layer Eltwise2
I0928 20:40:44.049108  6508 net.cpp:100] Creating Layer Eltwise2
I0928 20:40:44.049108  6508 net.cpp:434] Eltwise2 <- Eltwise1_Eltwise1_0_split_1
I0928 20:40:44.049108  6508 net.cpp:434] Eltwise2 <- Convolution7
I0928 20:40:44.049108  6508 net.cpp:408] Eltwise2 -> Eltwise2
I0928 20:40:44.050107  6508 net.cpp:150] Setting up Eltwise2
I0928 20:40:44.050107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.050107  6508 net.cpp:165] Memory required for data: 21726428
I0928 20:40:44.050107  6508 layer_factory.cpp:58] Creating layer Eltwise2_Eltwise2_0_split
I0928 20:40:44.050107  6508 net.cpp:100] Creating Layer Eltwise2_Eltwise2_0_split
I0928 20:40:44.050107  6508 net.cpp:434] Eltwise2_Eltwise2_0_split <- Eltwise2
I0928 20:40:44.050107  6508 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_0
I0928 20:40:44.050107  6508 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_1
I0928 20:40:44.050107  6508 net.cpp:150] Setting up Eltwise2_Eltwise2_0_split
I0928 20:40:44.051107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.051107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.051107  6508 net.cpp:165] Memory required for data: 23332060
I0928 20:40:44.051107  6508 layer_factory.cpp:58] Creating layer Convolution8
I0928 20:40:44.051107  6508 net.cpp:100] Creating Layer Convolution8
I0928 20:40:44.051107  6508 net.cpp:434] Convolution8 <- Eltwise2_Eltwise2_0_split_0
I0928 20:40:44.051107  6508 net.cpp:408] Convolution8 -> Convolution8
I0928 20:40:44.051107  6508 net.cpp:150] Setting up Convolution8
I0928 20:40:44.052108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.052108  6508 net.cpp:165] Memory required for data: 24134876
I0928 20:40:44.052108  6508 layer_factory.cpp:58] Creating layer BatchNorm6
I0928 20:40:44.052108  6508 net.cpp:100] Creating Layer BatchNorm6
I0928 20:40:44.053107  6508 net.cpp:434] BatchNorm6 <- Convolution8
I0928 20:40:44.053107  6508 net.cpp:395] BatchNorm6 -> Convolution8 (in-place)
I0928 20:40:44.053107  6508 net.cpp:150] Setting up BatchNorm6
I0928 20:40:44.053107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.053107  6508 net.cpp:165] Memory required for data: 24937692
I0928 20:40:44.053107  6508 layer_factory.cpp:58] Creating layer Scale6
I0928 20:40:44.053107  6508 net.cpp:100] Creating Layer Scale6
I0928 20:40:44.053107  6508 net.cpp:434] Scale6 <- Convolution8
I0928 20:40:44.053107  6508 net.cpp:395] Scale6 -> Convolution8 (in-place)
I0928 20:40:44.054107  6508 layer_factory.cpp:58] Creating layer Scale6
I0928 20:40:44.054107  6508 net.cpp:150] Setting up Scale6
I0928 20:40:44.054107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.054107  6508 net.cpp:165] Memory required for data: 25740508
I0928 20:40:44.054107  6508 layer_factory.cpp:58] Creating layer ReLU7
I0928 20:40:44.054107  6508 net.cpp:100] Creating Layer ReLU7
I0928 20:40:44.054107  6508 net.cpp:434] ReLU7 <- Convolution8
I0928 20:40:44.054107  6508 net.cpp:395] ReLU7 -> Convolution8 (in-place)
I0928 20:40:44.054107  6508 net.cpp:150] Setting up ReLU7
I0928 20:40:44.054107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.055107  6508 net.cpp:165] Memory required for data: 26543324
I0928 20:40:44.055107  6508 layer_factory.cpp:58] Creating layer Convolution9
I0928 20:40:44.055107  6508 net.cpp:100] Creating Layer Convolution9
I0928 20:40:44.055107  6508 net.cpp:434] Convolution9 <- Convolution8
I0928 20:40:44.056107  6508 net.cpp:408] Convolution9 -> Convolution9
I0928 20:40:44.056107  6508 net.cpp:150] Setting up Convolution9
I0928 20:40:44.056107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.056107  6508 net.cpp:165] Memory required for data: 27346140
I0928 20:40:44.056107  6508 layer_factory.cpp:58] Creating layer BatchNorm7
I0928 20:40:44.056107  6508 net.cpp:100] Creating Layer BatchNorm7
I0928 20:40:44.056107  6508 net.cpp:434] BatchNorm7 <- Convolution9
I0928 20:40:44.056107  6508 net.cpp:395] BatchNorm7 -> Convolution9 (in-place)
I0928 20:40:44.056107  6508 net.cpp:150] Setting up BatchNorm7
I0928 20:40:44.057107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.057107  6508 net.cpp:165] Memory required for data: 28148956
I0928 20:40:44.057107  6508 layer_factory.cpp:58] Creating layer Scale7
I0928 20:40:44.057107  6508 net.cpp:100] Creating Layer Scale7
I0928 20:40:44.057107  6508 net.cpp:434] Scale7 <- Convolution9
I0928 20:40:44.057107  6508 net.cpp:395] Scale7 -> Convolution9 (in-place)
I0928 20:40:44.057107  6508 layer_factory.cpp:58] Creating layer Scale7
I0928 20:40:44.057107  6508 net.cpp:150] Setting up Scale7
I0928 20:40:44.057107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.058107  6508 net.cpp:165] Memory required for data: 28951772
I0928 20:40:44.058107  6508 layer_factory.cpp:58] Creating layer Eltwise3
I0928 20:40:44.058107  6508 net.cpp:100] Creating Layer Eltwise3
I0928 20:40:44.058107  6508 net.cpp:434] Eltwise3 <- Eltwise2_Eltwise2_0_split_1
I0928 20:40:44.058107  6508 net.cpp:434] Eltwise3 <- Convolution9
I0928 20:40:44.058107  6508 net.cpp:408] Eltwise3 -> Eltwise3
I0928 20:40:44.058107  6508 net.cpp:150] Setting up Eltwise3
I0928 20:40:44.058107  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.058107  6508 net.cpp:165] Memory required for data: 29754588
I0928 20:40:44.059108  6508 layer_factory.cpp:58] Creating layer Eltwise3_Eltwise3_0_split
I0928 20:40:44.059108  6508 net.cpp:100] Creating Layer Eltwise3_Eltwise3_0_split
I0928 20:40:44.059108  6508 net.cpp:434] Eltwise3_Eltwise3_0_split <- Eltwise3
I0928 20:40:44.059108  6508 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_0
I0928 20:40:44.059108  6508 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_1
I0928 20:40:44.059108  6508 net.cpp:150] Setting up Eltwise3_Eltwise3_0_split
I0928 20:40:44.059108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.059108  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.060108  6508 net.cpp:165] Memory required for data: 31360220
I0928 20:40:44.060108  6508 layer_factory.cpp:58] Creating layer Convolution10
I0928 20:40:44.060108  6508 net.cpp:100] Creating Layer Convolution10
I0928 20:40:44.060108  6508 net.cpp:434] Convolution10 <- Eltwise3_Eltwise3_0_split_0
I0928 20:40:44.060108  6508 net.cpp:408] Convolution10 -> Convolution10
I0928 20:40:44.060108  6508 net.cpp:150] Setting up Convolution10
I0928 20:40:44.060108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.062108  6508 net.cpp:165] Memory required for data: 31761628
I0928 20:40:44.062108  6508 layer_factory.cpp:58] Creating layer BatchNorm8
I0928 20:40:44.062108  6508 net.cpp:100] Creating Layer BatchNorm8
I0928 20:40:44.063108  6508 net.cpp:434] BatchNorm8 <- Convolution10
I0928 20:40:44.063108  6508 net.cpp:395] BatchNorm8 -> Convolution10 (in-place)
I0928 20:40:44.063108  6508 net.cpp:150] Setting up BatchNorm8
I0928 20:40:44.063108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.063108  6508 net.cpp:165] Memory required for data: 32163036
I0928 20:40:44.063108  6508 layer_factory.cpp:58] Creating layer Scale8
I0928 20:40:44.063108  6508 net.cpp:100] Creating Layer Scale8
I0928 20:40:44.063108  6508 net.cpp:434] Scale8 <- Convolution10
I0928 20:40:44.063108  6508 net.cpp:395] Scale8 -> Convolution10 (in-place)
I0928 20:40:44.064108  6508 layer_factory.cpp:58] Creating layer Scale8
I0928 20:40:44.064108  6508 net.cpp:150] Setting up Scale8
I0928 20:40:44.064108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.064108  6508 net.cpp:165] Memory required for data: 32564444
I0928 20:40:44.064108  6508 layer_factory.cpp:58] Creating layer ReLU8
I0928 20:40:44.064108  6508 net.cpp:100] Creating Layer ReLU8
I0928 20:40:44.064108  6508 net.cpp:434] ReLU8 <- Convolution10
I0928 20:40:44.064108  6508 net.cpp:395] ReLU8 -> Convolution10 (in-place)
I0928 20:40:44.064108  6508 net.cpp:150] Setting up ReLU8
I0928 20:40:44.065109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.065109  6508 net.cpp:165] Memory required for data: 32965852
I0928 20:40:44.065109  6508 layer_factory.cpp:58] Creating layer Convolution11
I0928 20:40:44.065109  6508 net.cpp:100] Creating Layer Convolution11
I0928 20:40:44.065109  6508 net.cpp:434] Convolution11 <- Convolution10
I0928 20:40:44.065109  6508 net.cpp:408] Convolution11 -> Convolution11
I0928 20:40:44.065109  6508 net.cpp:150] Setting up Convolution11
I0928 20:40:44.065109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.066108  6508 net.cpp:165] Memory required for data: 33367260
I0928 20:40:44.066108  6508 layer_factory.cpp:58] Creating layer BatchNorm9
I0928 20:40:44.066108  6508 net.cpp:100] Creating Layer BatchNorm9
I0928 20:40:44.066108  6508 net.cpp:434] BatchNorm9 <- Convolution11
I0928 20:40:44.066108  6508 net.cpp:395] BatchNorm9 -> Convolution11 (in-place)
I0928 20:40:44.066108  6508 net.cpp:150] Setting up BatchNorm9
I0928 20:40:44.066108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.067108  6508 net.cpp:165] Memory required for data: 33768668
I0928 20:40:44.067108  6508 layer_factory.cpp:58] Creating layer Scale9
I0928 20:40:44.067108  6508 net.cpp:100] Creating Layer Scale9
I0928 20:40:44.067108  6508 net.cpp:434] Scale9 <- Convolution11
I0928 20:40:44.067108  6508 net.cpp:395] Scale9 -> Convolution11 (in-place)
I0928 20:40:44.067108  6508 layer_factory.cpp:58] Creating layer Scale9
I0928 20:40:44.067108  6508 net.cpp:150] Setting up Scale9
I0928 20:40:44.067108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.067108  6508 net.cpp:165] Memory required for data: 34170076
I0928 20:40:44.067108  6508 layer_factory.cpp:58] Creating layer Pooling3
I0928 20:40:44.068109  6508 net.cpp:100] Creating Layer Pooling3
I0928 20:40:44.068109  6508 net.cpp:434] Pooling3 <- Eltwise3_Eltwise3_0_split_1
I0928 20:40:44.068109  6508 net.cpp:408] Pooling3 -> Pooling3
I0928 20:40:44.068109  6508 net.cpp:150] Setting up Pooling3
I0928 20:40:44.068109  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.068109  6508 net.cpp:165] Memory required for data: 34370780
I0928 20:40:44.068109  6508 layer_factory.cpp:58] Creating layer PadChannel1
I0928 20:40:44.068109  6508 net.cpp:100] Creating Layer PadChannel1
I0928 20:40:44.068109  6508 net.cpp:434] PadChannel1 <- Pooling3
I0928 20:40:44.069108  6508 net.cpp:408] PadChannel1 -> PadChannel1
I0928 20:40:44.069108  6508 net.cpp:150] Setting up PadChannel1
I0928 20:40:44.069108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.069108  6508 net.cpp:165] Memory required for data: 34772188
I0928 20:40:44.069108  6508 layer_factory.cpp:58] Creating layer Eltwise4
I0928 20:40:44.069108  6508 net.cpp:100] Creating Layer Eltwise4
I0928 20:40:44.069108  6508 net.cpp:434] Eltwise4 <- Convolution11
I0928 20:40:44.069108  6508 net.cpp:434] Eltwise4 <- PadChannel1
I0928 20:40:44.069108  6508 net.cpp:408] Eltwise4 -> Eltwise4
I0928 20:40:44.069108  6508 net.cpp:150] Setting up Eltwise4
I0928 20:40:44.070108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.070108  6508 net.cpp:165] Memory required for data: 35173596
I0928 20:40:44.070108  6508 layer_factory.cpp:58] Creating layer Eltwise4_Eltwise4_0_split
I0928 20:40:44.070108  6508 net.cpp:100] Creating Layer Eltwise4_Eltwise4_0_split
I0928 20:40:44.070108  6508 net.cpp:434] Eltwise4_Eltwise4_0_split <- Eltwise4
I0928 20:40:44.070108  6508 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I0928 20:40:44.070108  6508 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I0928 20:40:44.070108  6508 net.cpp:150] Setting up Eltwise4_Eltwise4_0_split
I0928 20:40:44.070108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.071108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.071108  6508 net.cpp:165] Memory required for data: 35976412
I0928 20:40:44.071108  6508 layer_factory.cpp:58] Creating layer Convolution12
I0928 20:40:44.071108  6508 net.cpp:100] Creating Layer Convolution12
I0928 20:40:44.071108  6508 net.cpp:434] Convolution12 <- Eltwise4_Eltwise4_0_split_0
I0928 20:40:44.071108  6508 net.cpp:408] Convolution12 -> Convolution12
I0928 20:40:44.071108  6508 net.cpp:150] Setting up Convolution12
I0928 20:40:44.072108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.072108  6508 net.cpp:165] Memory required for data: 36377820
I0928 20:40:44.072108  6508 layer_factory.cpp:58] Creating layer BatchNorm10
I0928 20:40:44.072108  6508 net.cpp:100] Creating Layer BatchNorm10
I0928 20:40:44.072108  6508 net.cpp:434] BatchNorm10 <- Convolution12
I0928 20:40:44.072108  6508 net.cpp:395] BatchNorm10 -> Convolution12 (in-place)
I0928 20:40:44.073108  6508 net.cpp:150] Setting up BatchNorm10
I0928 20:40:44.073108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.073108  6508 net.cpp:165] Memory required for data: 36779228
I0928 20:40:44.073108  6508 layer_factory.cpp:58] Creating layer Scale10
I0928 20:40:44.073108  6508 net.cpp:100] Creating Layer Scale10
I0928 20:40:44.073108  6508 net.cpp:434] Scale10 <- Convolution12
I0928 20:40:44.073108  6508 net.cpp:395] Scale10 -> Convolution12 (in-place)
I0928 20:40:44.073108  6508 layer_factory.cpp:58] Creating layer Scale10
I0928 20:40:44.073108  6508 net.cpp:150] Setting up Scale10
I0928 20:40:44.074108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.074108  6508 net.cpp:165] Memory required for data: 37180636
I0928 20:40:44.074108  6508 layer_factory.cpp:58] Creating layer ReLU9
I0928 20:40:44.074108  6508 net.cpp:100] Creating Layer ReLU9
I0928 20:40:44.074108  6508 net.cpp:434] ReLU9 <- Convolution12
I0928 20:40:44.074108  6508 net.cpp:395] ReLU9 -> Convolution12 (in-place)
I0928 20:40:44.074108  6508 net.cpp:150] Setting up ReLU9
I0928 20:40:44.074108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.074108  6508 net.cpp:165] Memory required for data: 37582044
I0928 20:40:44.074108  6508 layer_factory.cpp:58] Creating layer Convolution13
I0928 20:40:44.075109  6508 net.cpp:100] Creating Layer Convolution13
I0928 20:40:44.075109  6508 net.cpp:434] Convolution13 <- Convolution12
I0928 20:40:44.075109  6508 net.cpp:408] Convolution13 -> Convolution13
I0928 20:40:44.075109  6508 net.cpp:150] Setting up Convolution13
I0928 20:40:44.075109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.075109  6508 net.cpp:165] Memory required for data: 37983452
I0928 20:40:44.076108  6508 layer_factory.cpp:58] Creating layer BatchNorm11
I0928 20:40:44.076108  6508 net.cpp:100] Creating Layer BatchNorm11
I0928 20:40:44.076108  6508 net.cpp:434] BatchNorm11 <- Convolution13
I0928 20:40:44.076108  6508 net.cpp:395] BatchNorm11 -> Convolution13 (in-place)
I0928 20:40:44.076108  6508 net.cpp:150] Setting up BatchNorm11
I0928 20:40:44.076108  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.076108  6508 net.cpp:165] Memory required for data: 38384860
I0928 20:40:44.076108  6508 layer_factory.cpp:58] Creating layer Scale11
I0928 20:40:44.076108  6508 net.cpp:100] Creating Layer Scale11
I0928 20:40:44.077109  6508 net.cpp:434] Scale11 <- Convolution13
I0928 20:40:44.077109  6508 net.cpp:395] Scale11 -> Convolution13 (in-place)
I0928 20:40:44.077109  6508 layer_factory.cpp:58] Creating layer Scale11
I0928 20:40:44.077109  6508 net.cpp:150] Setting up Scale11
I0928 20:40:44.077109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.077109  6508 net.cpp:165] Memory required for data: 38786268
I0928 20:40:44.077109  6508 layer_factory.cpp:58] Creating layer Eltwise5
I0928 20:40:44.077109  6508 net.cpp:100] Creating Layer Eltwise5
I0928 20:40:44.077109  6508 net.cpp:434] Eltwise5 <- Eltwise4_Eltwise4_0_split_1
I0928 20:40:44.078109  6508 net.cpp:434] Eltwise5 <- Convolution13
I0928 20:40:44.078109  6508 net.cpp:408] Eltwise5 -> Eltwise5
I0928 20:40:44.078109  6508 net.cpp:150] Setting up Eltwise5
I0928 20:40:44.078109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.078109  6508 net.cpp:165] Memory required for data: 39187676
I0928 20:40:44.078109  6508 layer_factory.cpp:58] Creating layer Eltwise5_Eltwise5_0_split
I0928 20:40:44.078109  6508 net.cpp:100] Creating Layer Eltwise5_Eltwise5_0_split
I0928 20:40:44.078109  6508 net.cpp:434] Eltwise5_Eltwise5_0_split <- Eltwise5
I0928 20:40:44.078109  6508 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_0
I0928 20:40:44.079109  6508 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_1
I0928 20:40:44.079109  6508 net.cpp:150] Setting up Eltwise5_Eltwise5_0_split
I0928 20:40:44.079109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.079109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.079109  6508 net.cpp:165] Memory required for data: 39990492
I0928 20:40:44.079109  6508 layer_factory.cpp:58] Creating layer Convolution14
I0928 20:40:44.079109  6508 net.cpp:100] Creating Layer Convolution14
I0928 20:40:44.079109  6508 net.cpp:434] Convolution14 <- Eltwise5_Eltwise5_0_split_0
I0928 20:40:44.079109  6508 net.cpp:408] Convolution14 -> Convolution14
I0928 20:40:44.080109  6508 net.cpp:150] Setting up Convolution14
I0928 20:40:44.080109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.080109  6508 net.cpp:165] Memory required for data: 40391900
I0928 20:40:44.080109  6508 layer_factory.cpp:58] Creating layer BatchNorm12
I0928 20:40:44.080109  6508 net.cpp:100] Creating Layer BatchNorm12
I0928 20:40:44.080109  6508 net.cpp:434] BatchNorm12 <- Convolution14
I0928 20:40:44.080109  6508 net.cpp:395] BatchNorm12 -> Convolution14 (in-place)
I0928 20:40:44.081110  6508 net.cpp:150] Setting up BatchNorm12
I0928 20:40:44.081110  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.081110  6508 net.cpp:165] Memory required for data: 40793308
I0928 20:40:44.081110  6508 layer_factory.cpp:58] Creating layer Scale12
I0928 20:40:44.081110  6508 net.cpp:100] Creating Layer Scale12
I0928 20:40:44.081110  6508 net.cpp:434] Scale12 <- Convolution14
I0928 20:40:44.081110  6508 net.cpp:395] Scale12 -> Convolution14 (in-place)
I0928 20:40:44.081110  6508 layer_factory.cpp:58] Creating layer Scale12
I0928 20:40:44.081110  6508 net.cpp:150] Setting up Scale12
I0928 20:40:44.082109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.082109  6508 net.cpp:165] Memory required for data: 41194716
I0928 20:40:44.082109  6508 layer_factory.cpp:58] Creating layer ReLU10
I0928 20:40:44.082109  6508 net.cpp:100] Creating Layer ReLU10
I0928 20:40:44.082109  6508 net.cpp:434] ReLU10 <- Convolution14
I0928 20:40:44.082109  6508 net.cpp:395] ReLU10 -> Convolution14 (in-place)
I0928 20:40:44.082109  6508 net.cpp:150] Setting up ReLU10
I0928 20:40:44.082109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.082109  6508 net.cpp:165] Memory required for data: 41596124
I0928 20:40:44.083109  6508 layer_factory.cpp:58] Creating layer Convolution15
I0928 20:40:44.083109  6508 net.cpp:100] Creating Layer Convolution15
I0928 20:40:44.083109  6508 net.cpp:434] Convolution15 <- Convolution14
I0928 20:40:44.083109  6508 net.cpp:408] Convolution15 -> Convolution15
I0928 20:40:44.083109  6508 net.cpp:150] Setting up Convolution15
I0928 20:40:44.083109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.083109  6508 net.cpp:165] Memory required for data: 41997532
I0928 20:40:44.083109  6508 layer_factory.cpp:58] Creating layer BatchNorm13
I0928 20:40:44.084110  6508 net.cpp:100] Creating Layer BatchNorm13
I0928 20:40:44.084110  6508 net.cpp:434] BatchNorm13 <- Convolution15
I0928 20:40:44.084110  6508 net.cpp:395] BatchNorm13 -> Convolution15 (in-place)
I0928 20:40:44.084110  6508 net.cpp:150] Setting up BatchNorm13
I0928 20:40:44.084110  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.084110  6508 net.cpp:165] Memory required for data: 42398940
I0928 20:40:44.084110  6508 layer_factory.cpp:58] Creating layer Scale13
I0928 20:40:44.084110  6508 net.cpp:100] Creating Layer Scale13
I0928 20:40:44.085109  6508 net.cpp:434] Scale13 <- Convolution15
I0928 20:40:44.085109  6508 net.cpp:395] Scale13 -> Convolution15 (in-place)
I0928 20:40:44.085109  6508 layer_factory.cpp:58] Creating layer Scale13
I0928 20:40:44.085109  6508 net.cpp:150] Setting up Scale13
I0928 20:40:44.085109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.085109  6508 net.cpp:165] Memory required for data: 42800348
I0928 20:40:44.085109  6508 layer_factory.cpp:58] Creating layer Eltwise6
I0928 20:40:44.085109  6508 net.cpp:100] Creating Layer Eltwise6
I0928 20:40:44.085109  6508 net.cpp:434] Eltwise6 <- Eltwise5_Eltwise5_0_split_1
I0928 20:40:44.086109  6508 net.cpp:434] Eltwise6 <- Convolution15
I0928 20:40:44.086109  6508 net.cpp:408] Eltwise6 -> Eltwise6
I0928 20:40:44.086109  6508 net.cpp:150] Setting up Eltwise6
I0928 20:40:44.086109  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.086109  6508 net.cpp:165] Memory required for data: 43201756
I0928 20:40:44.086109  6508 layer_factory.cpp:58] Creating layer Eltwise6_Eltwise6_0_split
I0928 20:40:44.086109  6508 net.cpp:100] Creating Layer Eltwise6_Eltwise6_0_split
I0928 20:40:44.086109  6508 net.cpp:434] Eltwise6_Eltwise6_0_split <- Eltwise6
I0928 20:40:44.086109  6508 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_0
I0928 20:40:44.087110  6508 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_1
I0928 20:40:44.087110  6508 net.cpp:150] Setting up Eltwise6_Eltwise6_0_split
I0928 20:40:44.087110  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.087110  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.087110  6508 net.cpp:165] Memory required for data: 44004572
I0928 20:40:44.087110  6508 layer_factory.cpp:58] Creating layer Convolution16
I0928 20:40:44.087110  6508 net.cpp:100] Creating Layer Convolution16
I0928 20:40:44.087110  6508 net.cpp:434] Convolution16 <- Eltwise6_Eltwise6_0_split_0
I0928 20:40:44.087110  6508 net.cpp:408] Convolution16 -> Convolution16
I0928 20:40:44.088109  6508 net.cpp:150] Setting up Convolution16
I0928 20:40:44.088109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.088109  6508 net.cpp:165] Memory required for data: 44205276
I0928 20:40:44.088109  6508 layer_factory.cpp:58] Creating layer BatchNorm14
I0928 20:40:44.088109  6508 net.cpp:100] Creating Layer BatchNorm14
I0928 20:40:44.088109  6508 net.cpp:434] BatchNorm14 <- Convolution16
I0928 20:40:44.088109  6508 net.cpp:395] BatchNorm14 -> Convolution16 (in-place)
I0928 20:40:44.089109  6508 net.cpp:150] Setting up BatchNorm14
I0928 20:40:44.089109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.089109  6508 net.cpp:165] Memory required for data: 44405980
I0928 20:40:44.089109  6508 layer_factory.cpp:58] Creating layer Scale14
I0928 20:40:44.089109  6508 net.cpp:100] Creating Layer Scale14
I0928 20:40:44.089109  6508 net.cpp:434] Scale14 <- Convolution16
I0928 20:40:44.089109  6508 net.cpp:395] Scale14 -> Convolution16 (in-place)
I0928 20:40:44.090109  6508 layer_factory.cpp:58] Creating layer Scale14
I0928 20:40:44.090109  6508 net.cpp:150] Setting up Scale14
I0928 20:40:44.090109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.090109  6508 net.cpp:165] Memory required for data: 44606684
I0928 20:40:44.090109  6508 layer_factory.cpp:58] Creating layer ReLU11
I0928 20:40:44.090109  6508 net.cpp:100] Creating Layer ReLU11
I0928 20:40:44.090109  6508 net.cpp:434] ReLU11 <- Convolution16
I0928 20:40:44.090109  6508 net.cpp:395] ReLU11 -> Convolution16 (in-place)
I0928 20:40:44.090109  6508 net.cpp:150] Setting up ReLU11
I0928 20:40:44.091109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.091109  6508 net.cpp:165] Memory required for data: 44807388
I0928 20:40:44.091109  6508 layer_factory.cpp:58] Creating layer Convolution17
I0928 20:40:44.091109  6508 net.cpp:100] Creating Layer Convolution17
I0928 20:40:44.091109  6508 net.cpp:434] Convolution17 <- Convolution16
I0928 20:40:44.091109  6508 net.cpp:408] Convolution17 -> Convolution17
I0928 20:40:44.092109  6508 net.cpp:150] Setting up Convolution17
I0928 20:40:44.092109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.092109  6508 net.cpp:165] Memory required for data: 45008092
I0928 20:40:44.092109  6508 layer_factory.cpp:58] Creating layer BatchNorm15
I0928 20:40:44.092109  6508 net.cpp:100] Creating Layer BatchNorm15
I0928 20:40:44.092109  6508 net.cpp:434] BatchNorm15 <- Convolution17
I0928 20:40:44.093109  6508 net.cpp:395] BatchNorm15 -> Convolution17 (in-place)
I0928 20:40:44.093109  6508 net.cpp:150] Setting up BatchNorm15
I0928 20:40:44.093109  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.093109  6508 net.cpp:165] Memory required for data: 45208796
I0928 20:40:44.093109  6508 layer_factory.cpp:58] Creating layer Scale15
I0928 20:40:44.093109  6508 net.cpp:100] Creating Layer Scale15
I0928 20:40:44.093109  6508 net.cpp:434] Scale15 <- Convolution17
I0928 20:40:44.093109  6508 net.cpp:395] Scale15 -> Convolution17 (in-place)
I0928 20:40:44.093109  6508 layer_factory.cpp:58] Creating layer Scale15
I0928 20:40:44.094110  6508 net.cpp:150] Setting up Scale15
I0928 20:40:44.094110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.094110  6508 net.cpp:165] Memory required for data: 45409500
I0928 20:40:44.094110  6508 layer_factory.cpp:58] Creating layer Pooling4
I0928 20:40:44.094110  6508 net.cpp:100] Creating Layer Pooling4
I0928 20:40:44.094110  6508 net.cpp:434] Pooling4 <- Eltwise6_Eltwise6_0_split_1
I0928 20:40:44.094110  6508 net.cpp:408] Pooling4 -> Pooling4
I0928 20:40:44.094110  6508 net.cpp:150] Setting up Pooling4
I0928 20:40:44.094110  6508 net.cpp:157] Top shape: 1 32 28 28 (25088)
I0928 20:40:44.094110  6508 net.cpp:165] Memory required for data: 45509852
I0928 20:40:44.095110  6508 layer_factory.cpp:58] Creating layer PadChannel2
I0928 20:40:44.095110  6508 net.cpp:100] Creating Layer PadChannel2
I0928 20:40:44.095110  6508 net.cpp:434] PadChannel2 <- Pooling4
I0928 20:40:44.095110  6508 net.cpp:408] PadChannel2 -> PadChannel2
I0928 20:40:44.095110  6508 net.cpp:150] Setting up PadChannel2
I0928 20:40:44.095110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.095110  6508 net.cpp:165] Memory required for data: 45710556
I0928 20:40:44.096110  6508 layer_factory.cpp:58] Creating layer Eltwise7
I0928 20:40:44.096110  6508 net.cpp:100] Creating Layer Eltwise7
I0928 20:40:44.096110  6508 net.cpp:434] Eltwise7 <- Convolution17
I0928 20:40:44.096110  6508 net.cpp:434] Eltwise7 <- PadChannel2
I0928 20:40:44.096110  6508 net.cpp:408] Eltwise7 -> Eltwise7
I0928 20:40:44.096110  6508 net.cpp:150] Setting up Eltwise7
I0928 20:40:44.096110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.096110  6508 net.cpp:165] Memory required for data: 45911260
I0928 20:40:44.096110  6508 layer_factory.cpp:58] Creating layer Eltwise7_Eltwise7_0_split
I0928 20:40:44.097110  6508 net.cpp:100] Creating Layer Eltwise7_Eltwise7_0_split
I0928 20:40:44.097110  6508 net.cpp:434] Eltwise7_Eltwise7_0_split <- Eltwise7
I0928 20:40:44.097110  6508 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_0
I0928 20:40:44.097110  6508 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_1
I0928 20:40:44.097110  6508 net.cpp:150] Setting up Eltwise7_Eltwise7_0_split
I0928 20:40:44.097110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.097110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.097110  6508 net.cpp:165] Memory required for data: 46312668
I0928 20:40:44.097110  6508 layer_factory.cpp:58] Creating layer Convolution18
I0928 20:40:44.098110  6508 net.cpp:100] Creating Layer Convolution18
I0928 20:40:44.098110  6508 net.cpp:434] Convolution18 <- Eltwise7_Eltwise7_0_split_0
I0928 20:40:44.098110  6508 net.cpp:408] Convolution18 -> Convolution18
I0928 20:40:44.098110  6508 net.cpp:150] Setting up Convolution18
I0928 20:40:44.099110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.099110  6508 net.cpp:165] Memory required for data: 46513372
I0928 20:40:44.099110  6508 layer_factory.cpp:58] Creating layer BatchNorm16
I0928 20:40:44.099110  6508 net.cpp:100] Creating Layer BatchNorm16
I0928 20:40:44.099110  6508 net.cpp:434] BatchNorm16 <- Convolution18
I0928 20:40:44.099110  6508 net.cpp:395] BatchNorm16 -> Convolution18 (in-place)
I0928 20:40:44.099110  6508 net.cpp:150] Setting up BatchNorm16
I0928 20:40:44.099110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.099110  6508 net.cpp:165] Memory required for data: 46714076
I0928 20:40:44.099110  6508 layer_factory.cpp:58] Creating layer Scale16
I0928 20:40:44.100111  6508 net.cpp:100] Creating Layer Scale16
I0928 20:40:44.100111  6508 net.cpp:434] Scale16 <- Convolution18
I0928 20:40:44.100111  6508 net.cpp:395] Scale16 -> Convolution18 (in-place)
I0928 20:40:44.100111  6508 layer_factory.cpp:58] Creating layer Scale16
I0928 20:40:44.100111  6508 net.cpp:150] Setting up Scale16
I0928 20:40:44.100111  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.100111  6508 net.cpp:165] Memory required for data: 46914780
I0928 20:40:44.100111  6508 layer_factory.cpp:58] Creating layer ReLU12
I0928 20:40:44.100111  6508 net.cpp:100] Creating Layer ReLU12
I0928 20:40:44.101110  6508 net.cpp:434] ReLU12 <- Convolution18
I0928 20:40:44.101110  6508 net.cpp:395] ReLU12 -> Convolution18 (in-place)
I0928 20:40:44.101110  6508 net.cpp:150] Setting up ReLU12
I0928 20:40:44.101110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.101110  6508 net.cpp:165] Memory required for data: 47115484
I0928 20:40:44.101110  6508 layer_factory.cpp:58] Creating layer Convolution19
I0928 20:40:44.101110  6508 net.cpp:100] Creating Layer Convolution19
I0928 20:40:44.101110  6508 net.cpp:434] Convolution19 <- Convolution18
I0928 20:40:44.101110  6508 net.cpp:408] Convolution19 -> Convolution19
I0928 20:40:44.102110  6508 net.cpp:150] Setting up Convolution19
I0928 20:40:44.102110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.102110  6508 net.cpp:165] Memory required for data: 47316188
I0928 20:40:44.102110  6508 layer_factory.cpp:58] Creating layer BatchNorm17
I0928 20:40:44.102110  6508 net.cpp:100] Creating Layer BatchNorm17
I0928 20:40:44.103111  6508 net.cpp:434] BatchNorm17 <- Convolution19
I0928 20:40:44.103111  6508 net.cpp:395] BatchNorm17 -> Convolution19 (in-place)
I0928 20:40:44.103111  6508 net.cpp:150] Setting up BatchNorm17
I0928 20:40:44.103111  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.103111  6508 net.cpp:165] Memory required for data: 47516892
I0928 20:40:44.103111  6508 layer_factory.cpp:58] Creating layer Scale17
I0928 20:40:44.103111  6508 net.cpp:100] Creating Layer Scale17
I0928 20:40:44.103111  6508 net.cpp:434] Scale17 <- Convolution19
I0928 20:40:44.103111  6508 net.cpp:395] Scale17 -> Convolution19 (in-place)
I0928 20:40:44.104110  6508 layer_factory.cpp:58] Creating layer Scale17
I0928 20:40:44.104110  6508 net.cpp:150] Setting up Scale17
I0928 20:40:44.104110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.104110  6508 net.cpp:165] Memory required for data: 47717596
I0928 20:40:44.104110  6508 layer_factory.cpp:58] Creating layer Eltwise8
I0928 20:40:44.104110  6508 net.cpp:100] Creating Layer Eltwise8
I0928 20:40:44.104110  6508 net.cpp:434] Eltwise8 <- Eltwise7_Eltwise7_0_split_1
I0928 20:40:44.104110  6508 net.cpp:434] Eltwise8 <- Convolution19
I0928 20:40:44.104110  6508 net.cpp:408] Eltwise8 -> Eltwise8
I0928 20:40:44.104110  6508 net.cpp:150] Setting up Eltwise8
I0928 20:40:44.105110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.105110  6508 net.cpp:165] Memory required for data: 47918300
I0928 20:40:44.105110  6508 layer_factory.cpp:58] Creating layer Eltwise8_Eltwise8_0_split
I0928 20:40:44.105110  6508 net.cpp:100] Creating Layer Eltwise8_Eltwise8_0_split
I0928 20:40:44.105110  6508 net.cpp:434] Eltwise8_Eltwise8_0_split <- Eltwise8
I0928 20:40:44.105110  6508 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I0928 20:40:44.105110  6508 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I0928 20:40:44.105110  6508 net.cpp:150] Setting up Eltwise8_Eltwise8_0_split
I0928 20:40:44.105110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.106111  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.106111  6508 net.cpp:165] Memory required for data: 48319708
I0928 20:40:44.106111  6508 layer_factory.cpp:58] Creating layer Convolution20
I0928 20:40:44.106111  6508 net.cpp:100] Creating Layer Convolution20
I0928 20:40:44.106111  6508 net.cpp:434] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I0928 20:40:44.106111  6508 net.cpp:408] Convolution20 -> Convolution20
I0928 20:40:44.107110  6508 net.cpp:150] Setting up Convolution20
I0928 20:40:44.107110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.107110  6508 net.cpp:165] Memory required for data: 48520412
I0928 20:40:44.107110  6508 layer_factory.cpp:58] Creating layer BatchNorm18
I0928 20:40:44.107110  6508 net.cpp:100] Creating Layer BatchNorm18
I0928 20:40:44.107110  6508 net.cpp:434] BatchNorm18 <- Convolution20
I0928 20:40:44.107110  6508 net.cpp:395] BatchNorm18 -> Convolution20 (in-place)
I0928 20:40:44.108110  6508 net.cpp:150] Setting up BatchNorm18
I0928 20:40:44.108110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.108110  6508 net.cpp:165] Memory required for data: 48721116
I0928 20:40:44.108110  6508 layer_factory.cpp:58] Creating layer Scale18
I0928 20:40:44.108110  6508 net.cpp:100] Creating Layer Scale18
I0928 20:40:44.108110  6508 net.cpp:434] Scale18 <- Convolution20
I0928 20:40:44.108110  6508 net.cpp:395] Scale18 -> Convolution20 (in-place)
I0928 20:40:44.108110  6508 layer_factory.cpp:58] Creating layer Scale18
I0928 20:40:44.108110  6508 net.cpp:150] Setting up Scale18
I0928 20:40:44.108110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.109110  6508 net.cpp:165] Memory required for data: 48921820
I0928 20:40:44.109110  6508 layer_factory.cpp:58] Creating layer ReLU13
I0928 20:40:44.109110  6508 net.cpp:100] Creating Layer ReLU13
I0928 20:40:44.109110  6508 net.cpp:434] ReLU13 <- Convolution20
I0928 20:40:44.109110  6508 net.cpp:395] ReLU13 -> Convolution20 (in-place)
I0928 20:40:44.109110  6508 net.cpp:150] Setting up ReLU13
I0928 20:40:44.109110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.110110  6508 net.cpp:165] Memory required for data: 49122524
I0928 20:40:44.110110  6508 layer_factory.cpp:58] Creating layer Convolution21
I0928 20:40:44.110110  6508 net.cpp:100] Creating Layer Convolution21
I0928 20:40:44.110110  6508 net.cpp:434] Convolution21 <- Convolution20
I0928 20:40:44.110110  6508 net.cpp:408] Convolution21 -> Convolution21
I0928 20:40:44.111110  6508 net.cpp:150] Setting up Convolution21
I0928 20:40:44.111110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.111110  6508 net.cpp:165] Memory required for data: 49323228
I0928 20:40:44.111110  6508 layer_factory.cpp:58] Creating layer BatchNorm19
I0928 20:40:44.111110  6508 net.cpp:100] Creating Layer BatchNorm19
I0928 20:40:44.111110  6508 net.cpp:434] BatchNorm19 <- Convolution21
I0928 20:40:44.111110  6508 net.cpp:395] BatchNorm19 -> Convolution21 (in-place)
I0928 20:40:44.111110  6508 net.cpp:150] Setting up BatchNorm19
I0928 20:40:44.111110  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.111110  6508 net.cpp:165] Memory required for data: 49523932
I0928 20:40:44.112112  6508 layer_factory.cpp:58] Creating layer Scale19
I0928 20:40:44.112112  6508 net.cpp:100] Creating Layer Scale19
I0928 20:40:44.112112  6508 net.cpp:434] Scale19 <- Convolution21
I0928 20:40:44.112112  6508 net.cpp:395] Scale19 -> Convolution21 (in-place)
I0928 20:40:44.112112  6508 layer_factory.cpp:58] Creating layer Scale19
I0928 20:40:44.112112  6508 net.cpp:150] Setting up Scale19
I0928 20:40:44.112112  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.112112  6508 net.cpp:165] Memory required for data: 49724636
I0928 20:40:44.112112  6508 layer_factory.cpp:58] Creating layer Eltwise9
I0928 20:40:44.113111  6508 net.cpp:100] Creating Layer Eltwise9
I0928 20:40:44.113111  6508 net.cpp:434] Eltwise9 <- Eltwise8_Eltwise8_0_split_1
I0928 20:40:44.113111  6508 net.cpp:434] Eltwise9 <- Convolution21
I0928 20:40:44.113111  6508 net.cpp:408] Eltwise9 -> Eltwise9
I0928 20:40:44.113111  6508 net.cpp:150] Setting up Eltwise9
I0928 20:40:44.113111  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.113111  6508 net.cpp:165] Memory required for data: 49925340
I0928 20:40:44.113111  6508 layer_factory.cpp:58] Creating layer Pooling5
I0928 20:40:44.113111  6508 net.cpp:100] Creating Layer Pooling5
I0928 20:40:44.113111  6508 net.cpp:434] Pooling5 <- Eltwise9
I0928 20:40:44.114111  6508 net.cpp:408] Pooling5 -> Pooling5
I0928 20:40:44.114111  6508 net.cpp:150] Setting up Pooling5
I0928 20:40:44.114111  6508 net.cpp:157] Top shape: 1 64 1 1 (64)
I0928 20:40:44.114111  6508 net.cpp:165] Memory required for data: 49925596
I0928 20:40:44.114111  6508 layer_factory.cpp:58] Creating layer InnerProduct4
I0928 20:40:44.114111  6508 net.cpp:100] Creating Layer InnerProduct4
I0928 20:40:44.114111  6508 net.cpp:434] InnerProduct4 <- Pooling5
I0928 20:40:44.114111  6508 net.cpp:408] InnerProduct4 -> InnerProduct4
I0928 20:40:44.115111  6508 net.cpp:150] Setting up InnerProduct4
I0928 20:40:44.115111  6508 net.cpp:157] Top shape: 1 2 (2)
I0928 20:40:44.115111  6508 net.cpp:165] Memory required for data: 49925604
I0928 20:40:44.115111  6508 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:40:44.115111  6508 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0928 20:40:44.115111  6508 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct4
I0928 20:40:44.115111  6508 net.cpp:434] SoftmaxWithLoss1 <- ImageData2
I0928 20:40:44.115111  6508 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 20:40:44.115111  6508 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:40:44.116111  6508 net.cpp:150] Setting up SoftmaxWithLoss1
I0928 20:40:44.116111  6508 net.cpp:157] Top shape: (1)
I0928 20:40:44.116111  6508 net.cpp:160]     with loss weight 1
I0928 20:40:44.116111  6508 net.cpp:165] Memory required for data: 49925608
I0928 20:40:44.116111  6508 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0928 20:40:44.116111  6508 net.cpp:226] InnerProduct4 needs backward computation.
I0928 20:40:44.116111  6508 net.cpp:226] Pooling5 needs backward computation.
I0928 20:40:44.116111  6508 net.cpp:226] Eltwise9 needs backward computation.
I0928 20:40:44.116111  6508 net.cpp:226] Scale19 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] BatchNorm19 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Convolution21 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] ReLU13 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Scale18 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] BatchNorm18 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Convolution20 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Eltwise8_Eltwise8_0_split needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Eltwise8 needs backward computation.
I0928 20:40:44.117111  6508 net.cpp:226] Scale17 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] BatchNorm17 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] Convolution19 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] ReLU12 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] Scale16 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] BatchNorm16 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] Convolution18 needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] Eltwise7_Eltwise7_0_split needs backward computation.
I0928 20:40:44.118111  6508 net.cpp:226] Eltwise7 needs backward computation.
I0928 20:40:44.119112  6508 net.cpp:226] PadChannel2 needs backward computation.
I0928 20:40:44.119112  6508 net.cpp:226] Pooling4 needs backward computation.
I0928 20:40:44.119112  6508 net.cpp:226] Scale15 needs backward computation.
I0928 20:40:44.119112  6508 net.cpp:226] BatchNorm15 needs backward computation.
I0928 20:40:44.119112  6508 net.cpp:226] Convolution17 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] ReLU11 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Scale14 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] BatchNorm14 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Convolution16 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Eltwise6_Eltwise6_0_split needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Eltwise6 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Scale13 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] BatchNorm13 needs backward computation.
I0928 20:40:44.120111  6508 net.cpp:226] Convolution15 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] ReLU10 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Scale12 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] BatchNorm12 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Convolution14 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Eltwise5_Eltwise5_0_split needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Eltwise5 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Scale11 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] BatchNorm11 needs backward computation.
I0928 20:40:44.121111  6508 net.cpp:226] Convolution13 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] ReLU9 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Scale10 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] BatchNorm10 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Convolution12 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Eltwise4_Eltwise4_0_split needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Eltwise4 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] PadChannel1 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Pooling3 needs backward computation.
I0928 20:40:44.122112  6508 net.cpp:226] Scale9 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] BatchNorm9 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Convolution11 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] ReLU8 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Scale8 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] BatchNorm8 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Convolution10 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Eltwise3_Eltwise3_0_split needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Eltwise3 needs backward computation.
I0928 20:40:44.123111  6508 net.cpp:226] Scale7 needs backward computation.
I0928 20:40:44.124111  6508 net.cpp:226] BatchNorm7 needs backward computation.
I0928 20:40:44.124111  6508 net.cpp:226] Convolution9 needs backward computation.
I0928 20:40:44.124111  6508 net.cpp:226] ReLU7 needs backward computation.
I0928 20:40:44.124111  6508 net.cpp:226] Scale6 needs backward computation.
I0928 20:40:44.124111  6508 net.cpp:226] BatchNorm6 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Convolution8 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Eltwise2_Eltwise2_0_split needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Eltwise2 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Scale5 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] BatchNorm5 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Convolution7 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] ReLU6 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Scale4 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] BatchNorm4 needs backward computation.
I0928 20:40:44.125111  6508 net.cpp:226] Convolution6 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] Eltwise1_Eltwise1_0_split needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] Eltwise1 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] Scale3 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] BatchNorm3 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] Convolution5 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] ReLU5 needs backward computation.
I0928 20:40:44.126111  6508 net.cpp:226] Scale2 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] BatchNorm2 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] Convolution4 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] Convolution3_ReLU4_0_split needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] ReLU4 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] Scale1 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] BatchNorm1 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] Convolution3 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] Transformer1 needs backward computation.
I0928 20:40:44.127111  6508 net.cpp:226] InnerProduct3 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] InnerProduct2 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] ReLU3 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] InnerProduct1 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] Pooling2 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] ReLU2 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] Convolution2 needs backward computation.
I0928 20:40:44.128111  6508 net.cpp:226] Pooling1 needs backward computation.
I0928 20:40:44.129112  6508 net.cpp:226] ReLU1 needs backward computation.
I0928 20:40:44.129112  6508 net.cpp:226] Convolution1 needs backward computation.
I0928 20:40:44.129112  6508 net.cpp:228] ImageData1_ImageData1_0_split does not need backward computation.
I0928 20:40:44.129112  6508 net.cpp:228] ImageData1 does not need backward computation.
I0928 20:40:44.129112  6508 net.cpp:270] This network produces output SoftmaxWithLoss1
I0928 20:40:44.129112  6508 net.cpp:283] Network initialization done.
I0928 20:40:44.131112  6508 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet_20_train_test_STN.prototxt
I0928 20:40:44.131112  6508 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 20:40:44.131112  6508 solver.cpp:181] Creating test net (#0) specified by net file: resnet_20_train_test_STN.prototxt
I0928 20:40:44.131112  6508 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer ImageData1
I0928 20:40:44.132112  6508 net.cpp:58] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "ImageData1"
  type: "ImageData"
  top: "ImageData1"
  top: "ImageData2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    crop_size: 112
    mean_value: 128
  }
  image_data_param {
    source: "image_list.txt"
    batch_size: 1
    shuffle: true
    new_height: 0
    new_width: 0
    is_color: false
    root_folder: ""
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "ImageData1"
  top: "Convolution1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling2"
  top: "InnerProduct1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "InnerProduct2"
  top: "InnerProduct3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 6
    weight_filler {
      type: "gaussian"
      value: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Transformer1"
  type: "Transformer"
  bottom: "ImageData1"
  bottom: "InnerProduct3"
  top: "Transformer1"
  transformer_param {
    num_theta: 6
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Transformer1"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution5"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution7"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution9"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise3"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel1"
  type: "PadChannel"
  bottom: "Pooling3"
  top: "PadChannel1"
  pad_channel_param {
    num_channels_to_pad: 16
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "PadChannel1"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution15"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Eltwise6"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel2"
  type: "PadChannel"
  bottom: "Pooling4"
  top: "PadChannel2"
  pad_channel_param {
    num_channels_to_pad: 32
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "PadChannel2"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Pooling5"
  top: "InnerProduct4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0928 20:40:44.182116  6508 layer_factory.cpp:58] Creating layer ImageData1
I0928 20:40:44.182116  6508 net.cpp:100] Creating Layer ImageData1
I0928 20:40:44.182116  6508 net.cpp:408] ImageData1 -> ImageData1
I0928 20:40:44.183115  6508 net.cpp:408] ImageData1 -> ImageData2
I0928 20:40:44.183115  6508 image_data_layer.cpp:38] Opening file image_list.txt
I0928 20:40:44.183115  6508 image_data_layer.cpp:53] Shuffling data
I0928 20:40:44.183115  6508 image_data_layer.cpp:58] A total of 1 images.
I0928 20:40:44.184115  6508 image_data_layer.cpp:85] output data size: 1,1,112,112
I0928 20:40:44.185115  6508 net.cpp:150] Setting up ImageData1
I0928 20:40:44.185115  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.185115  6508 net.cpp:157] Top shape: 1 (1)
I0928 20:40:44.185115  6508 net.cpp:165] Memory required for data: 50180
I0928 20:40:44.185115  6508 layer_factory.cpp:58] Creating layer ImageData1_ImageData1_0_split
I0928 20:40:44.185115  6508 net.cpp:100] Creating Layer ImageData1_ImageData1_0_split
I0928 20:40:44.185115  6508 net.cpp:434] ImageData1_ImageData1_0_split <- ImageData1
I0928 20:40:44.186115  6508 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_0
I0928 20:40:44.186115  6508 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_1
I0928 20:40:44.186115  6508 net.cpp:150] Setting up ImageData1_ImageData1_0_split
I0928 20:40:44.186115  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.186115  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.186115  6508 net.cpp:165] Memory required for data: 150532
I0928 20:40:44.186115  6508 layer_factory.cpp:58] Creating layer ImageData2_ImageData1_1_split
I0928 20:40:44.186115  6508 net.cpp:100] Creating Layer ImageData2_ImageData1_1_split
I0928 20:40:44.187115  6508 net.cpp:434] ImageData2_ImageData1_1_split <- ImageData2
I0928 20:40:44.187115  6508 net.cpp:408] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_0
I0928 20:40:44.187115  6508 net.cpp:408] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_1
I0928 20:40:44.187115  6508 net.cpp:150] Setting up ImageData2_ImageData1_1_split
I0928 20:40:44.187115  6508 net.cpp:157] Top shape: 1 (1)
I0928 20:40:44.187115  6508 net.cpp:157] Top shape: 1 (1)
I0928 20:40:44.188115  6508 net.cpp:165] Memory required for data: 150540
I0928 20:40:44.188115  6508 layer_factory.cpp:58] Creating layer Convolution1
I0928 20:40:44.188115  6508 net.cpp:100] Creating Layer Convolution1
I0928 20:40:44.188115  6508 net.cpp:434] Convolution1 <- ImageData1_ImageData1_0_split_0
I0928 20:40:44.188115  6508 net.cpp:408] Convolution1 -> Convolution1
I0928 20:40:44.189116  6508 net.cpp:150] Setting up Convolution1
I0928 20:40:44.189116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.189116  6508 net.cpp:165] Memory required for data: 953356
I0928 20:40:44.189116  6508 layer_factory.cpp:58] Creating layer ReLU1
I0928 20:40:44.189116  6508 net.cpp:100] Creating Layer ReLU1
I0928 20:40:44.189116  6508 net.cpp:434] ReLU1 <- Convolution1
I0928 20:40:44.189116  6508 net.cpp:395] ReLU1 -> Convolution1 (in-place)
I0928 20:40:44.190115  6508 net.cpp:150] Setting up ReLU1
I0928 20:40:44.190115  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.190115  6508 net.cpp:165] Memory required for data: 1756172
I0928 20:40:44.190115  6508 layer_factory.cpp:58] Creating layer Pooling1
I0928 20:40:44.190115  6508 net.cpp:100] Creating Layer Pooling1
I0928 20:40:44.190115  6508 net.cpp:434] Pooling1 <- Convolution1
I0928 20:40:44.190115  6508 net.cpp:408] Pooling1 -> Pooling1
I0928 20:40:44.190115  6508 net.cpp:150] Setting up Pooling1
I0928 20:40:44.190115  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.190115  6508 net.cpp:165] Memory required for data: 1956876
I0928 20:40:44.191115  6508 layer_factory.cpp:58] Creating layer Convolution2
I0928 20:40:44.191115  6508 net.cpp:100] Creating Layer Convolution2
I0928 20:40:44.191115  6508 net.cpp:434] Convolution2 <- Pooling1
I0928 20:40:44.191115  6508 net.cpp:408] Convolution2 -> Convolution2
I0928 20:40:44.191115  6508 net.cpp:150] Setting up Convolution2
I0928 20:40:44.191115  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.191115  6508 net.cpp:165] Memory required for data: 2157580
I0928 20:40:44.191115  6508 layer_factory.cpp:58] Creating layer ReLU2
I0928 20:40:44.192116  6508 net.cpp:100] Creating Layer ReLU2
I0928 20:40:44.192116  6508 net.cpp:434] ReLU2 <- Convolution2
I0928 20:40:44.192116  6508 net.cpp:395] ReLU2 -> Convolution2 (in-place)
I0928 20:40:44.192116  6508 net.cpp:150] Setting up ReLU2
I0928 20:40:44.192116  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.192116  6508 net.cpp:165] Memory required for data: 2358284
I0928 20:40:44.192116  6508 layer_factory.cpp:58] Creating layer Pooling2
I0928 20:40:44.192116  6508 net.cpp:100] Creating Layer Pooling2
I0928 20:40:44.192116  6508 net.cpp:434] Pooling2 <- Convolution2
I0928 20:40:44.192116  6508 net.cpp:408] Pooling2 -> Pooling2
I0928 20:40:44.193115  6508 net.cpp:150] Setting up Pooling2
I0928 20:40:44.193115  6508 net.cpp:157] Top shape: 1 16 28 28 (12544)
I0928 20:40:44.193115  6508 net.cpp:165] Memory required for data: 2408460
I0928 20:40:44.193115  6508 layer_factory.cpp:58] Creating layer InnerProduct1
I0928 20:40:44.193115  6508 net.cpp:100] Creating Layer InnerProduct1
I0928 20:40:44.193115  6508 net.cpp:434] InnerProduct1 <- Pooling2
I0928 20:40:44.193115  6508 net.cpp:408] InnerProduct1 -> InnerProduct1
I0928 20:40:44.196115  6508 net.cpp:150] Setting up InnerProduct1
I0928 20:40:44.196115  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.196115  6508 net.cpp:165] Memory required for data: 2408524
I0928 20:40:44.196115  6508 layer_factory.cpp:58] Creating layer ReLU3
I0928 20:40:44.196115  6508 net.cpp:100] Creating Layer ReLU3
I0928 20:40:44.196115  6508 net.cpp:434] ReLU3 <- InnerProduct1
I0928 20:40:44.197115  6508 net.cpp:395] ReLU3 -> InnerProduct1 (in-place)
I0928 20:40:44.197115  6508 net.cpp:150] Setting up ReLU3
I0928 20:40:44.197115  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.197115  6508 net.cpp:165] Memory required for data: 2408588
I0928 20:40:44.197115  6508 layer_factory.cpp:58] Creating layer InnerProduct2
I0928 20:40:44.197115  6508 net.cpp:100] Creating Layer InnerProduct2
I0928 20:40:44.197115  6508 net.cpp:434] InnerProduct2 <- InnerProduct1
I0928 20:40:44.198115  6508 net.cpp:408] InnerProduct2 -> InnerProduct2
I0928 20:40:44.198115  6508 net.cpp:150] Setting up InnerProduct2
I0928 20:40:44.198115  6508 net.cpp:157] Top shape: 1 16 (16)
I0928 20:40:44.198115  6508 net.cpp:165] Memory required for data: 2408652
I0928 20:40:44.198115  6508 layer_factory.cpp:58] Creating layer InnerProduct3
I0928 20:40:44.198115  6508 net.cpp:100] Creating Layer InnerProduct3
I0928 20:40:44.198115  6508 net.cpp:434] InnerProduct3 <- InnerProduct2
I0928 20:40:44.198115  6508 net.cpp:408] InnerProduct3 -> InnerProduct3
I0928 20:40:44.198115  6508 net.cpp:150] Setting up InnerProduct3
I0928 20:40:44.198115  6508 net.cpp:157] Top shape: 1 6 (6)
I0928 20:40:44.198115  6508 net.cpp:165] Memory required for data: 2408676
I0928 20:40:44.199116  6508 layer_factory.cpp:58] Creating layer Transformer1
I0928 20:40:44.199116  6508 net.cpp:100] Creating Layer Transformer1
I0928 20:40:44.199116  6508 net.cpp:434] Transformer1 <- ImageData1_ImageData1_0_split_1
I0928 20:40:44.199116  6508 net.cpp:434] Transformer1 <- InnerProduct3
I0928 20:40:44.199116  6508 net.cpp:408] Transformer1 -> Transformer1
I0928 20:40:44.200116  6508 net.cpp:150] Setting up Transformer1
I0928 20:40:44.200116  6508 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:40:44.200116  6508 net.cpp:165] Memory required for data: 2458852
I0928 20:40:44.200116  6508 layer_factory.cpp:58] Creating layer Convolution3
I0928 20:40:44.200116  6508 net.cpp:100] Creating Layer Convolution3
I0928 20:40:44.200116  6508 net.cpp:434] Convolution3 <- Transformer1
I0928 20:40:44.201117  6508 net.cpp:408] Convolution3 -> Convolution3
I0928 20:40:44.201117  6508 net.cpp:150] Setting up Convolution3
I0928 20:40:44.201117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.201117  6508 net.cpp:165] Memory required for data: 3261668
I0928 20:40:44.201117  6508 layer_factory.cpp:58] Creating layer BatchNorm1
I0928 20:40:44.201117  6508 net.cpp:100] Creating Layer BatchNorm1
I0928 20:40:44.201117  6508 net.cpp:434] BatchNorm1 <- Convolution3
I0928 20:40:44.201117  6508 net.cpp:395] BatchNorm1 -> Convolution3 (in-place)
I0928 20:40:44.201117  6508 net.cpp:150] Setting up BatchNorm1
I0928 20:40:44.201117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.202116  6508 net.cpp:165] Memory required for data: 4064484
I0928 20:40:44.202116  6508 layer_factory.cpp:58] Creating layer Scale1
I0928 20:40:44.202116  6508 net.cpp:100] Creating Layer Scale1
I0928 20:40:44.202116  6508 net.cpp:434] Scale1 <- Convolution3
I0928 20:40:44.202116  6508 net.cpp:395] Scale1 -> Convolution3 (in-place)
I0928 20:40:44.202116  6508 layer_factory.cpp:58] Creating layer Scale1
I0928 20:40:44.202116  6508 net.cpp:150] Setting up Scale1
I0928 20:40:44.202116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.203116  6508 net.cpp:165] Memory required for data: 4867300
I0928 20:40:44.203116  6508 layer_factory.cpp:58] Creating layer ReLU4
I0928 20:40:44.203116  6508 net.cpp:100] Creating Layer ReLU4
I0928 20:40:44.203116  6508 net.cpp:434] ReLU4 <- Convolution3
I0928 20:40:44.203116  6508 net.cpp:395] ReLU4 -> Convolution3 (in-place)
I0928 20:40:44.203116  6508 net.cpp:150] Setting up ReLU4
I0928 20:40:44.203116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.203116  6508 net.cpp:165] Memory required for data: 5670116
I0928 20:40:44.203116  6508 layer_factory.cpp:58] Creating layer Convolution3_ReLU4_0_split
I0928 20:40:44.203116  6508 net.cpp:100] Creating Layer Convolution3_ReLU4_0_split
I0928 20:40:44.204116  6508 net.cpp:434] Convolution3_ReLU4_0_split <- Convolution3
I0928 20:40:44.204116  6508 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_0
I0928 20:40:44.204116  6508 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_1
I0928 20:40:44.204116  6508 net.cpp:150] Setting up Convolution3_ReLU4_0_split
I0928 20:40:44.204116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.204116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.204116  6508 net.cpp:165] Memory required for data: 7275748
I0928 20:40:44.204116  6508 layer_factory.cpp:58] Creating layer Convolution4
I0928 20:40:44.205116  6508 net.cpp:100] Creating Layer Convolution4
I0928 20:40:44.205116  6508 net.cpp:434] Convolution4 <- Convolution3_ReLU4_0_split_0
I0928 20:40:44.205116  6508 net.cpp:408] Convolution4 -> Convolution4
I0928 20:40:44.205116  6508 net.cpp:150] Setting up Convolution4
I0928 20:40:44.205116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.205116  6508 net.cpp:165] Memory required for data: 8078564
I0928 20:40:44.205116  6508 layer_factory.cpp:58] Creating layer BatchNorm2
I0928 20:40:44.205116  6508 net.cpp:100] Creating Layer BatchNorm2
I0928 20:40:44.205116  6508 net.cpp:434] BatchNorm2 <- Convolution4
I0928 20:40:44.206116  6508 net.cpp:395] BatchNorm2 -> Convolution4 (in-place)
I0928 20:40:44.206116  6508 net.cpp:150] Setting up BatchNorm2
I0928 20:40:44.206116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.206116  6508 net.cpp:165] Memory required for data: 8881380
I0928 20:40:44.206116  6508 layer_factory.cpp:58] Creating layer Scale2
I0928 20:40:44.206116  6508 net.cpp:100] Creating Layer Scale2
I0928 20:40:44.206116  6508 net.cpp:434] Scale2 <- Convolution4
I0928 20:40:44.206116  6508 net.cpp:395] Scale2 -> Convolution4 (in-place)
I0928 20:40:44.206116  6508 layer_factory.cpp:58] Creating layer Scale2
I0928 20:40:44.206116  6508 net.cpp:150] Setting up Scale2
I0928 20:40:44.207116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.207116  6508 net.cpp:165] Memory required for data: 9684196
I0928 20:40:44.207116  6508 layer_factory.cpp:58] Creating layer ReLU5
I0928 20:40:44.207116  6508 net.cpp:100] Creating Layer ReLU5
I0928 20:40:44.207116  6508 net.cpp:434] ReLU5 <- Convolution4
I0928 20:40:44.207116  6508 net.cpp:395] ReLU5 -> Convolution4 (in-place)
I0928 20:40:44.207116  6508 net.cpp:150] Setting up ReLU5
I0928 20:40:44.207116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.207116  6508 net.cpp:165] Memory required for data: 10487012
I0928 20:40:44.207116  6508 layer_factory.cpp:58] Creating layer Convolution5
I0928 20:40:44.208117  6508 net.cpp:100] Creating Layer Convolution5
I0928 20:40:44.208117  6508 net.cpp:434] Convolution5 <- Convolution4
I0928 20:40:44.208117  6508 net.cpp:408] Convolution5 -> Convolution5
I0928 20:40:44.208117  6508 net.cpp:150] Setting up Convolution5
I0928 20:40:44.208117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.208117  6508 net.cpp:165] Memory required for data: 11289828
I0928 20:40:44.208117  6508 layer_factory.cpp:58] Creating layer BatchNorm3
I0928 20:40:44.208117  6508 net.cpp:100] Creating Layer BatchNorm3
I0928 20:40:44.208117  6508 net.cpp:434] BatchNorm3 <- Convolution5
I0928 20:40:44.209116  6508 net.cpp:395] BatchNorm3 -> Convolution5 (in-place)
I0928 20:40:44.209116  6508 net.cpp:150] Setting up BatchNorm3
I0928 20:40:44.209116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.209116  6508 net.cpp:165] Memory required for data: 12092644
I0928 20:40:44.209116  6508 layer_factory.cpp:58] Creating layer Scale3
I0928 20:40:44.210116  6508 net.cpp:100] Creating Layer Scale3
I0928 20:40:44.210116  6508 net.cpp:434] Scale3 <- Convolution5
I0928 20:40:44.210116  6508 net.cpp:395] Scale3 -> Convolution5 (in-place)
I0928 20:40:44.210116  6508 layer_factory.cpp:58] Creating layer Scale3
I0928 20:40:44.210116  6508 net.cpp:150] Setting up Scale3
I0928 20:40:44.210116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.210116  6508 net.cpp:165] Memory required for data: 12895460
I0928 20:40:44.210116  6508 layer_factory.cpp:58] Creating layer Eltwise1
I0928 20:40:44.211117  6508 net.cpp:100] Creating Layer Eltwise1
I0928 20:40:44.211117  6508 net.cpp:434] Eltwise1 <- Convolution3_ReLU4_0_split_1
I0928 20:40:44.211117  6508 net.cpp:434] Eltwise1 <- Convolution5
I0928 20:40:44.211117  6508 net.cpp:408] Eltwise1 -> Eltwise1
I0928 20:40:44.211117  6508 net.cpp:150] Setting up Eltwise1
I0928 20:40:44.211117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.211117  6508 net.cpp:165] Memory required for data: 13698276
I0928 20:40:44.211117  6508 layer_factory.cpp:58] Creating layer Eltwise1_Eltwise1_0_split
I0928 20:40:44.212116  6508 net.cpp:100] Creating Layer Eltwise1_Eltwise1_0_split
I0928 20:40:44.212116  6508 net.cpp:434] Eltwise1_Eltwise1_0_split <- Eltwise1
I0928 20:40:44.212116  6508 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_0
I0928 20:40:44.212116  6508 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_1
I0928 20:40:44.212116  6508 net.cpp:150] Setting up Eltwise1_Eltwise1_0_split
I0928 20:40:44.212116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.212116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.212116  6508 net.cpp:165] Memory required for data: 15303908
I0928 20:40:44.212116  6508 layer_factory.cpp:58] Creating layer Convolution6
I0928 20:40:44.213116  6508 net.cpp:100] Creating Layer Convolution6
I0928 20:40:44.213116  6508 net.cpp:434] Convolution6 <- Eltwise1_Eltwise1_0_split_0
I0928 20:40:44.213116  6508 net.cpp:408] Convolution6 -> Convolution6
I0928 20:40:44.213116  6508 net.cpp:150] Setting up Convolution6
I0928 20:40:44.213116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.213116  6508 net.cpp:165] Memory required for data: 16106724
I0928 20:40:44.213116  6508 layer_factory.cpp:58] Creating layer BatchNorm4
I0928 20:40:44.213116  6508 net.cpp:100] Creating Layer BatchNorm4
I0928 20:40:44.213116  6508 net.cpp:434] BatchNorm4 <- Convolution6
I0928 20:40:44.214117  6508 net.cpp:395] BatchNorm4 -> Convolution6 (in-place)
I0928 20:40:44.214117  6508 net.cpp:150] Setting up BatchNorm4
I0928 20:40:44.214117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.214117  6508 net.cpp:165] Memory required for data: 16909540
I0928 20:40:44.214117  6508 layer_factory.cpp:58] Creating layer Scale4
I0928 20:40:44.214117  6508 net.cpp:100] Creating Layer Scale4
I0928 20:40:44.214117  6508 net.cpp:434] Scale4 <- Convolution6
I0928 20:40:44.215116  6508 net.cpp:395] Scale4 -> Convolution6 (in-place)
I0928 20:40:44.215116  6508 layer_factory.cpp:58] Creating layer Scale4
I0928 20:40:44.215116  6508 net.cpp:150] Setting up Scale4
I0928 20:40:44.215116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.215116  6508 net.cpp:165] Memory required for data: 17712356
I0928 20:40:44.215116  6508 layer_factory.cpp:58] Creating layer ReLU6
I0928 20:40:44.215116  6508 net.cpp:100] Creating Layer ReLU6
I0928 20:40:44.215116  6508 net.cpp:434] ReLU6 <- Convolution6
I0928 20:40:44.215116  6508 net.cpp:395] ReLU6 -> Convolution6 (in-place)
I0928 20:40:44.216116  6508 net.cpp:150] Setting up ReLU6
I0928 20:40:44.216116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.216116  6508 net.cpp:165] Memory required for data: 18515172
I0928 20:40:44.216116  6508 layer_factory.cpp:58] Creating layer Convolution7
I0928 20:40:44.216116  6508 net.cpp:100] Creating Layer Convolution7
I0928 20:40:44.216116  6508 net.cpp:434] Convolution7 <- Convolution6
I0928 20:40:44.216116  6508 net.cpp:408] Convolution7 -> Convolution7
I0928 20:40:44.216116  6508 net.cpp:150] Setting up Convolution7
I0928 20:40:44.216116  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.217118  6508 net.cpp:165] Memory required for data: 19317988
I0928 20:40:44.217118  6508 layer_factory.cpp:58] Creating layer BatchNorm5
I0928 20:40:44.217118  6508 net.cpp:100] Creating Layer BatchNorm5
I0928 20:40:44.217118  6508 net.cpp:434] BatchNorm5 <- Convolution7
I0928 20:40:44.217118  6508 net.cpp:395] BatchNorm5 -> Convolution7 (in-place)
I0928 20:40:44.217118  6508 net.cpp:150] Setting up BatchNorm5
I0928 20:40:44.217118  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.217118  6508 net.cpp:165] Memory required for data: 20120804
I0928 20:40:44.217118  6508 layer_factory.cpp:58] Creating layer Scale5
I0928 20:40:44.217118  6508 net.cpp:100] Creating Layer Scale5
I0928 20:40:44.218117  6508 net.cpp:434] Scale5 <- Convolution7
I0928 20:40:44.218117  6508 net.cpp:395] Scale5 -> Convolution7 (in-place)
I0928 20:40:44.218117  6508 layer_factory.cpp:58] Creating layer Scale5
I0928 20:40:44.218117  6508 net.cpp:150] Setting up Scale5
I0928 20:40:44.218117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.218117  6508 net.cpp:165] Memory required for data: 20923620
I0928 20:40:44.218117  6508 layer_factory.cpp:58] Creating layer Eltwise2
I0928 20:40:44.218117  6508 net.cpp:100] Creating Layer Eltwise2
I0928 20:40:44.218117  6508 net.cpp:434] Eltwise2 <- Eltwise1_Eltwise1_0_split_1
I0928 20:40:44.219117  6508 net.cpp:434] Eltwise2 <- Convolution7
I0928 20:40:44.219117  6508 net.cpp:408] Eltwise2 -> Eltwise2
I0928 20:40:44.219117  6508 net.cpp:150] Setting up Eltwise2
I0928 20:40:44.219117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.219117  6508 net.cpp:165] Memory required for data: 21726436
I0928 20:40:44.219117  6508 layer_factory.cpp:58] Creating layer Eltwise2_Eltwise2_0_split
I0928 20:40:44.219117  6508 net.cpp:100] Creating Layer Eltwise2_Eltwise2_0_split
I0928 20:40:44.219117  6508 net.cpp:434] Eltwise2_Eltwise2_0_split <- Eltwise2
I0928 20:40:44.219117  6508 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_0
I0928 20:40:44.219117  6508 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_1
I0928 20:40:44.220118  6508 net.cpp:150] Setting up Eltwise2_Eltwise2_0_split
I0928 20:40:44.220118  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.220118  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.220118  6508 net.cpp:165] Memory required for data: 23332068
I0928 20:40:44.220118  6508 layer_factory.cpp:58] Creating layer Convolution8
I0928 20:40:44.220118  6508 net.cpp:100] Creating Layer Convolution8
I0928 20:40:44.220118  6508 net.cpp:434] Convolution8 <- Eltwise2_Eltwise2_0_split_0
I0928 20:40:44.220118  6508 net.cpp:408] Convolution8 -> Convolution8
I0928 20:40:44.221117  6508 net.cpp:150] Setting up Convolution8
I0928 20:40:44.221117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.221117  6508 net.cpp:165] Memory required for data: 24134884
I0928 20:40:44.221117  6508 layer_factory.cpp:58] Creating layer BatchNorm6
I0928 20:40:44.221117  6508 net.cpp:100] Creating Layer BatchNorm6
I0928 20:40:44.221117  6508 net.cpp:434] BatchNorm6 <- Convolution8
I0928 20:40:44.221117  6508 net.cpp:395] BatchNorm6 -> Convolution8 (in-place)
I0928 20:40:44.221117  6508 net.cpp:150] Setting up BatchNorm6
I0928 20:40:44.221117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.221117  6508 net.cpp:165] Memory required for data: 24937700
I0928 20:40:44.222117  6508 layer_factory.cpp:58] Creating layer Scale6
I0928 20:40:44.222117  6508 net.cpp:100] Creating Layer Scale6
I0928 20:40:44.222117  6508 net.cpp:434] Scale6 <- Convolution8
I0928 20:40:44.222117  6508 net.cpp:395] Scale6 -> Convolution8 (in-place)
I0928 20:40:44.222117  6508 layer_factory.cpp:58] Creating layer Scale6
I0928 20:40:44.222117  6508 net.cpp:150] Setting up Scale6
I0928 20:40:44.222117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.222117  6508 net.cpp:165] Memory required for data: 25740516
I0928 20:40:44.223117  6508 layer_factory.cpp:58] Creating layer ReLU7
I0928 20:40:44.223117  6508 net.cpp:100] Creating Layer ReLU7
I0928 20:40:44.223117  6508 net.cpp:434] ReLU7 <- Convolution8
I0928 20:40:44.223117  6508 net.cpp:395] ReLU7 -> Convolution8 (in-place)
I0928 20:40:44.223117  6508 net.cpp:150] Setting up ReLU7
I0928 20:40:44.223117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.223117  6508 net.cpp:165] Memory required for data: 26543332
I0928 20:40:44.223117  6508 layer_factory.cpp:58] Creating layer Convolution9
I0928 20:40:44.224117  6508 net.cpp:100] Creating Layer Convolution9
I0928 20:40:44.224117  6508 net.cpp:434] Convolution9 <- Convolution8
I0928 20:40:44.224117  6508 net.cpp:408] Convolution9 -> Convolution9
I0928 20:40:44.224117  6508 net.cpp:150] Setting up Convolution9
I0928 20:40:44.224117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.224117  6508 net.cpp:165] Memory required for data: 27346148
I0928 20:40:44.224117  6508 layer_factory.cpp:58] Creating layer BatchNorm7
I0928 20:40:44.225117  6508 net.cpp:100] Creating Layer BatchNorm7
I0928 20:40:44.225117  6508 net.cpp:434] BatchNorm7 <- Convolution9
I0928 20:40:44.225117  6508 net.cpp:395] BatchNorm7 -> Convolution9 (in-place)
I0928 20:40:44.225117  6508 net.cpp:150] Setting up BatchNorm7
I0928 20:40:44.225117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.225117  6508 net.cpp:165] Memory required for data: 28148964
I0928 20:40:44.225117  6508 layer_factory.cpp:58] Creating layer Scale7
I0928 20:40:44.225117  6508 net.cpp:100] Creating Layer Scale7
I0928 20:40:44.225117  6508 net.cpp:434] Scale7 <- Convolution9
I0928 20:40:44.225117  6508 net.cpp:395] Scale7 -> Convolution9 (in-place)
I0928 20:40:44.226117  6508 layer_factory.cpp:58] Creating layer Scale7
I0928 20:40:44.226117  6508 net.cpp:150] Setting up Scale7
I0928 20:40:44.226117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.226117  6508 net.cpp:165] Memory required for data: 28951780
I0928 20:40:44.226117  6508 layer_factory.cpp:58] Creating layer Eltwise3
I0928 20:40:44.226117  6508 net.cpp:100] Creating Layer Eltwise3
I0928 20:40:44.226117  6508 net.cpp:434] Eltwise3 <- Eltwise2_Eltwise2_0_split_1
I0928 20:40:44.226117  6508 net.cpp:434] Eltwise3 <- Convolution9
I0928 20:40:44.226117  6508 net.cpp:408] Eltwise3 -> Eltwise3
I0928 20:40:44.227118  6508 net.cpp:150] Setting up Eltwise3
I0928 20:40:44.227118  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.227118  6508 net.cpp:165] Memory required for data: 29754596
I0928 20:40:44.227118  6508 layer_factory.cpp:58] Creating layer Eltwise3_Eltwise3_0_split
I0928 20:40:44.227118  6508 net.cpp:100] Creating Layer Eltwise3_Eltwise3_0_split
I0928 20:40:44.227118  6508 net.cpp:434] Eltwise3_Eltwise3_0_split <- Eltwise3
I0928 20:40:44.227118  6508 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_0
I0928 20:40:44.227118  6508 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_1
I0928 20:40:44.227118  6508 net.cpp:150] Setting up Eltwise3_Eltwise3_0_split
I0928 20:40:44.228117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.228117  6508 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:40:44.228117  6508 net.cpp:165] Memory required for data: 31360228
I0928 20:40:44.228117  6508 layer_factory.cpp:58] Creating layer Convolution10
I0928 20:40:44.228117  6508 net.cpp:100] Creating Layer Convolution10
I0928 20:40:44.228117  6508 net.cpp:434] Convolution10 <- Eltwise3_Eltwise3_0_split_0
I0928 20:40:44.228117  6508 net.cpp:408] Convolution10 -> Convolution10
I0928 20:40:44.228117  6508 net.cpp:150] Setting up Convolution10
I0928 20:40:44.229117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.229117  6508 net.cpp:165] Memory required for data: 31761636
I0928 20:40:44.229117  6508 layer_factory.cpp:58] Creating layer BatchNorm8
I0928 20:40:44.229117  6508 net.cpp:100] Creating Layer BatchNorm8
I0928 20:40:44.229117  6508 net.cpp:434] BatchNorm8 <- Convolution10
I0928 20:40:44.229117  6508 net.cpp:395] BatchNorm8 -> Convolution10 (in-place)
I0928 20:40:44.229117  6508 net.cpp:150] Setting up BatchNorm8
I0928 20:40:44.229117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.229117  6508 net.cpp:165] Memory required for data: 32163044
I0928 20:40:44.229117  6508 layer_factory.cpp:58] Creating layer Scale8
I0928 20:40:44.230118  6508 net.cpp:100] Creating Layer Scale8
I0928 20:40:44.230118  6508 net.cpp:434] Scale8 <- Convolution10
I0928 20:40:44.230118  6508 net.cpp:395] Scale8 -> Convolution10 (in-place)
I0928 20:40:44.230118  6508 layer_factory.cpp:58] Creating layer Scale8
I0928 20:40:44.230118  6508 net.cpp:150] Setting up Scale8
I0928 20:40:44.230118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.230118  6508 net.cpp:165] Memory required for data: 32564452
I0928 20:40:44.230118  6508 layer_factory.cpp:58] Creating layer ReLU8
I0928 20:40:44.230118  6508 net.cpp:100] Creating Layer ReLU8
I0928 20:40:44.230118  6508 net.cpp:434] ReLU8 <- Convolution10
I0928 20:40:44.231117  6508 net.cpp:395] ReLU8 -> Convolution10 (in-place)
I0928 20:40:44.231117  6508 net.cpp:150] Setting up ReLU8
I0928 20:40:44.231117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.231117  6508 net.cpp:165] Memory required for data: 32965860
I0928 20:40:44.231117  6508 layer_factory.cpp:58] Creating layer Convolution11
I0928 20:40:44.231117  6508 net.cpp:100] Creating Layer Convolution11
I0928 20:40:44.231117  6508 net.cpp:434] Convolution11 <- Convolution10
I0928 20:40:44.231117  6508 net.cpp:408] Convolution11 -> Convolution11
I0928 20:40:44.232117  6508 net.cpp:150] Setting up Convolution11
I0928 20:40:44.232117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.232117  6508 net.cpp:165] Memory required for data: 33367268
I0928 20:40:44.232117  6508 layer_factory.cpp:58] Creating layer BatchNorm9
I0928 20:40:44.232117  6508 net.cpp:100] Creating Layer BatchNorm9
I0928 20:40:44.232117  6508 net.cpp:434] BatchNorm9 <- Convolution11
I0928 20:40:44.232117  6508 net.cpp:395] BatchNorm9 -> Convolution11 (in-place)
I0928 20:40:44.232117  6508 net.cpp:150] Setting up BatchNorm9
I0928 20:40:44.233117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.233117  6508 net.cpp:165] Memory required for data: 33768676
I0928 20:40:44.233117  6508 layer_factory.cpp:58] Creating layer Scale9
I0928 20:40:44.233117  6508 net.cpp:100] Creating Layer Scale9
I0928 20:40:44.233117  6508 net.cpp:434] Scale9 <- Convolution11
I0928 20:40:44.233117  6508 net.cpp:395] Scale9 -> Convolution11 (in-place)
I0928 20:40:44.233117  6508 layer_factory.cpp:58] Creating layer Scale9
I0928 20:40:44.233117  6508 net.cpp:150] Setting up Scale9
I0928 20:40:44.233117  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.233117  6508 net.cpp:165] Memory required for data: 34170084
I0928 20:40:44.234118  6508 layer_factory.cpp:58] Creating layer Pooling3
I0928 20:40:44.234118  6508 net.cpp:100] Creating Layer Pooling3
I0928 20:40:44.234118  6508 net.cpp:434] Pooling3 <- Eltwise3_Eltwise3_0_split_1
I0928 20:40:44.234118  6508 net.cpp:408] Pooling3 -> Pooling3
I0928 20:40:44.234118  6508 net.cpp:150] Setting up Pooling3
I0928 20:40:44.234118  6508 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:40:44.234118  6508 net.cpp:165] Memory required for data: 34370788
I0928 20:40:44.234118  6508 layer_factory.cpp:58] Creating layer PadChannel1
I0928 20:40:44.235118  6508 net.cpp:100] Creating Layer PadChannel1
I0928 20:40:44.235118  6508 net.cpp:434] PadChannel1 <- Pooling3
I0928 20:40:44.235118  6508 net.cpp:408] PadChannel1 -> PadChannel1
I0928 20:40:44.235118  6508 net.cpp:150] Setting up PadChannel1
I0928 20:40:44.235118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.235118  6508 net.cpp:165] Memory required for data: 34772196
I0928 20:40:44.235118  6508 layer_factory.cpp:58] Creating layer Eltwise4
I0928 20:40:44.235118  6508 net.cpp:100] Creating Layer Eltwise4
I0928 20:40:44.235118  6508 net.cpp:434] Eltwise4 <- Convolution11
I0928 20:40:44.236119  6508 net.cpp:434] Eltwise4 <- PadChannel1
I0928 20:40:44.236119  6508 net.cpp:408] Eltwise4 -> Eltwise4
I0928 20:40:44.236119  6508 net.cpp:150] Setting up Eltwise4
I0928 20:40:44.236119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.236119  6508 net.cpp:165] Memory required for data: 35173604
I0928 20:40:44.236119  6508 layer_factory.cpp:58] Creating layer Eltwise4_Eltwise4_0_split
I0928 20:40:44.236119  6508 net.cpp:100] Creating Layer Eltwise4_Eltwise4_0_split
I0928 20:40:44.236119  6508 net.cpp:434] Eltwise4_Eltwise4_0_split <- Eltwise4
I0928 20:40:44.236119  6508 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I0928 20:40:44.237118  6508 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I0928 20:40:44.237118  6508 net.cpp:150] Setting up Eltwise4_Eltwise4_0_split
I0928 20:40:44.237118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.237118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.237118  6508 net.cpp:165] Memory required for data: 35976420
I0928 20:40:44.237118  6508 layer_factory.cpp:58] Creating layer Convolution12
I0928 20:40:44.237118  6508 net.cpp:100] Creating Layer Convolution12
I0928 20:40:44.237118  6508 net.cpp:434] Convolution12 <- Eltwise4_Eltwise4_0_split_0
I0928 20:40:44.237118  6508 net.cpp:408] Convolution12 -> Convolution12
I0928 20:40:44.238118  6508 net.cpp:150] Setting up Convolution12
I0928 20:40:44.238118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.238118  6508 net.cpp:165] Memory required for data: 36377828
I0928 20:40:44.238118  6508 layer_factory.cpp:58] Creating layer BatchNorm10
I0928 20:40:44.238118  6508 net.cpp:100] Creating Layer BatchNorm10
I0928 20:40:44.238118  6508 net.cpp:434] BatchNorm10 <- Convolution12
I0928 20:40:44.238118  6508 net.cpp:395] BatchNorm10 -> Convolution12 (in-place)
I0928 20:40:44.239118  6508 net.cpp:150] Setting up BatchNorm10
I0928 20:40:44.239118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.239118  6508 net.cpp:165] Memory required for data: 36779236
I0928 20:40:44.239118  6508 layer_factory.cpp:58] Creating layer Scale10
I0928 20:40:44.239118  6508 net.cpp:100] Creating Layer Scale10
I0928 20:40:44.239118  6508 net.cpp:434] Scale10 <- Convolution12
I0928 20:40:44.239118  6508 net.cpp:395] Scale10 -> Convolution12 (in-place)
I0928 20:40:44.239118  6508 layer_factory.cpp:58] Creating layer Scale10
I0928 20:40:44.239118  6508 net.cpp:150] Setting up Scale10
I0928 20:40:44.239118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.240118  6508 net.cpp:165] Memory required for data: 37180644
I0928 20:40:44.240118  6508 layer_factory.cpp:58] Creating layer ReLU9
I0928 20:40:44.240118  6508 net.cpp:100] Creating Layer ReLU9
I0928 20:40:44.240118  6508 net.cpp:434] ReLU9 <- Convolution12
I0928 20:40:44.240118  6508 net.cpp:395] ReLU9 -> Convolution12 (in-place)
I0928 20:40:44.240118  6508 net.cpp:150] Setting up ReLU9
I0928 20:40:44.240118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.240118  6508 net.cpp:165] Memory required for data: 37582052
I0928 20:40:44.240118  6508 layer_factory.cpp:58] Creating layer Convolution13
I0928 20:40:44.240118  6508 net.cpp:100] Creating Layer Convolution13
I0928 20:40:44.241118  6508 net.cpp:434] Convolution13 <- Convolution12
I0928 20:40:44.241118  6508 net.cpp:408] Convolution13 -> Convolution13
I0928 20:40:44.241118  6508 net.cpp:150] Setting up Convolution13
I0928 20:40:44.241118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.241118  6508 net.cpp:165] Memory required for data: 37983460
I0928 20:40:44.241118  6508 layer_factory.cpp:58] Creating layer BatchNorm11
I0928 20:40:44.241118  6508 net.cpp:100] Creating Layer BatchNorm11
I0928 20:40:44.241118  6508 net.cpp:434] BatchNorm11 <- Convolution13
I0928 20:40:44.242118  6508 net.cpp:395] BatchNorm11 -> Convolution13 (in-place)
I0928 20:40:44.242118  6508 net.cpp:150] Setting up BatchNorm11
I0928 20:40:44.242118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.242118  6508 net.cpp:165] Memory required for data: 38384868
I0928 20:40:44.242118  6508 layer_factory.cpp:58] Creating layer Scale11
I0928 20:40:44.242118  6508 net.cpp:100] Creating Layer Scale11
I0928 20:40:44.242118  6508 net.cpp:434] Scale11 <- Convolution13
I0928 20:40:44.242118  6508 net.cpp:395] Scale11 -> Convolution13 (in-place)
I0928 20:40:44.242118  6508 layer_factory.cpp:58] Creating layer Scale11
I0928 20:40:44.243119  6508 net.cpp:150] Setting up Scale11
I0928 20:40:44.243119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.243119  6508 net.cpp:165] Memory required for data: 38786276
I0928 20:40:44.243119  6508 layer_factory.cpp:58] Creating layer Eltwise5
I0928 20:40:44.243119  6508 net.cpp:100] Creating Layer Eltwise5
I0928 20:40:44.243119  6508 net.cpp:434] Eltwise5 <- Eltwise4_Eltwise4_0_split_1
I0928 20:40:44.243119  6508 net.cpp:434] Eltwise5 <- Convolution13
I0928 20:40:44.243119  6508 net.cpp:408] Eltwise5 -> Eltwise5
I0928 20:40:44.244118  6508 net.cpp:150] Setting up Eltwise5
I0928 20:40:44.244118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.244118  6508 net.cpp:165] Memory required for data: 39187684
I0928 20:40:44.244118  6508 layer_factory.cpp:58] Creating layer Eltwise5_Eltwise5_0_split
I0928 20:40:44.244118  6508 net.cpp:100] Creating Layer Eltwise5_Eltwise5_0_split
I0928 20:40:44.244118  6508 net.cpp:434] Eltwise5_Eltwise5_0_split <- Eltwise5
I0928 20:40:44.244118  6508 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_0
I0928 20:40:44.244118  6508 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_1
I0928 20:40:44.244118  6508 net.cpp:150] Setting up Eltwise5_Eltwise5_0_split
I0928 20:40:44.245118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.245118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.245118  6508 net.cpp:165] Memory required for data: 39990500
I0928 20:40:44.245118  6508 layer_factory.cpp:58] Creating layer Convolution14
I0928 20:40:44.245118  6508 net.cpp:100] Creating Layer Convolution14
I0928 20:40:44.245118  6508 net.cpp:434] Convolution14 <- Eltwise5_Eltwise5_0_split_0
I0928 20:40:44.245118  6508 net.cpp:408] Convolution14 -> Convolution14
I0928 20:40:44.245118  6508 net.cpp:150] Setting up Convolution14
I0928 20:40:44.246119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.246119  6508 net.cpp:165] Memory required for data: 40391908
I0928 20:40:44.246119  6508 layer_factory.cpp:58] Creating layer BatchNorm12
I0928 20:40:44.246119  6508 net.cpp:100] Creating Layer BatchNorm12
I0928 20:40:44.246119  6508 net.cpp:434] BatchNorm12 <- Convolution14
I0928 20:40:44.246119  6508 net.cpp:395] BatchNorm12 -> Convolution14 (in-place)
I0928 20:40:44.246119  6508 net.cpp:150] Setting up BatchNorm12
I0928 20:40:44.246119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.246119  6508 net.cpp:165] Memory required for data: 40793316
I0928 20:40:44.247118  6508 layer_factory.cpp:58] Creating layer Scale12
I0928 20:40:44.247118  6508 net.cpp:100] Creating Layer Scale12
I0928 20:40:44.247118  6508 net.cpp:434] Scale12 <- Convolution14
I0928 20:40:44.247118  6508 net.cpp:395] Scale12 -> Convolution14 (in-place)
I0928 20:40:44.247118  6508 layer_factory.cpp:58] Creating layer Scale12
I0928 20:40:44.247118  6508 net.cpp:150] Setting up Scale12
I0928 20:40:44.247118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.247118  6508 net.cpp:165] Memory required for data: 41194724
I0928 20:40:44.247118  6508 layer_factory.cpp:58] Creating layer ReLU10
I0928 20:40:44.248118  6508 net.cpp:100] Creating Layer ReLU10
I0928 20:40:44.248118  6508 net.cpp:434] ReLU10 <- Convolution14
I0928 20:40:44.248118  6508 net.cpp:395] ReLU10 -> Convolution14 (in-place)
I0928 20:40:44.248118  6508 net.cpp:150] Setting up ReLU10
I0928 20:40:44.248118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.248118  6508 net.cpp:165] Memory required for data: 41596132
I0928 20:40:44.249119  6508 layer_factory.cpp:58] Creating layer Convolution15
I0928 20:40:44.249119  6508 net.cpp:100] Creating Layer Convolution15
I0928 20:40:44.249119  6508 net.cpp:434] Convolution15 <- Convolution14
I0928 20:40:44.249119  6508 net.cpp:408] Convolution15 -> Convolution15
I0928 20:40:44.249119  6508 net.cpp:150] Setting up Convolution15
I0928 20:40:44.249119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.250118  6508 net.cpp:165] Memory required for data: 41997540
I0928 20:40:44.250118  6508 layer_factory.cpp:58] Creating layer BatchNorm13
I0928 20:40:44.250118  6508 net.cpp:100] Creating Layer BatchNorm13
I0928 20:40:44.250118  6508 net.cpp:434] BatchNorm13 <- Convolution15
I0928 20:40:44.250118  6508 net.cpp:395] BatchNorm13 -> Convolution15 (in-place)
I0928 20:40:44.250118  6508 net.cpp:150] Setting up BatchNorm13
I0928 20:40:44.250118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.250118  6508 net.cpp:165] Memory required for data: 42398948
I0928 20:40:44.250118  6508 layer_factory.cpp:58] Creating layer Scale13
I0928 20:40:44.250118  6508 net.cpp:100] Creating Layer Scale13
I0928 20:40:44.251118  6508 net.cpp:434] Scale13 <- Convolution15
I0928 20:40:44.251118  6508 net.cpp:395] Scale13 -> Convolution15 (in-place)
I0928 20:40:44.251118  6508 layer_factory.cpp:58] Creating layer Scale13
I0928 20:40:44.251118  6508 net.cpp:150] Setting up Scale13
I0928 20:40:44.251118  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.251118  6508 net.cpp:165] Memory required for data: 42800356
I0928 20:40:44.251118  6508 layer_factory.cpp:58] Creating layer Eltwise6
I0928 20:40:44.251118  6508 net.cpp:100] Creating Layer Eltwise6
I0928 20:40:44.251118  6508 net.cpp:434] Eltwise6 <- Eltwise5_Eltwise5_0_split_1
I0928 20:40:44.252120  6508 net.cpp:434] Eltwise6 <- Convolution15
I0928 20:40:44.252120  6508 net.cpp:408] Eltwise6 -> Eltwise6
I0928 20:40:44.252120  6508 net.cpp:150] Setting up Eltwise6
I0928 20:40:44.252120  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.252120  6508 net.cpp:165] Memory required for data: 43201764
I0928 20:40:44.252120  6508 layer_factory.cpp:58] Creating layer Eltwise6_Eltwise6_0_split
I0928 20:40:44.252120  6508 net.cpp:100] Creating Layer Eltwise6_Eltwise6_0_split
I0928 20:40:44.252120  6508 net.cpp:434] Eltwise6_Eltwise6_0_split <- Eltwise6
I0928 20:40:44.252120  6508 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_0
I0928 20:40:44.252120  6508 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_1
I0928 20:40:44.253119  6508 net.cpp:150] Setting up Eltwise6_Eltwise6_0_split
I0928 20:40:44.253119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.253119  6508 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:40:44.253119  6508 net.cpp:165] Memory required for data: 44004580
I0928 20:40:44.253119  6508 layer_factory.cpp:58] Creating layer Convolution16
I0928 20:40:44.253119  6508 net.cpp:100] Creating Layer Convolution16
I0928 20:40:44.253119  6508 net.cpp:434] Convolution16 <- Eltwise6_Eltwise6_0_split_0
I0928 20:40:44.253119  6508 net.cpp:408] Convolution16 -> Convolution16
I0928 20:40:44.254119  6508 net.cpp:150] Setting up Convolution16
I0928 20:40:44.254119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.254119  6508 net.cpp:165] Memory required for data: 44205284
I0928 20:40:44.254119  6508 layer_factory.cpp:58] Creating layer BatchNorm14
I0928 20:40:44.254119  6508 net.cpp:100] Creating Layer BatchNorm14
I0928 20:40:44.254119  6508 net.cpp:434] BatchNorm14 <- Convolution16
I0928 20:40:44.254119  6508 net.cpp:395] BatchNorm14 -> Convolution16 (in-place)
I0928 20:40:44.254119  6508 net.cpp:150] Setting up BatchNorm14
I0928 20:40:44.255120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.255120  6508 net.cpp:165] Memory required for data: 44405988
I0928 20:40:44.255120  6508 layer_factory.cpp:58] Creating layer Scale14
I0928 20:40:44.255120  6508 net.cpp:100] Creating Layer Scale14
I0928 20:40:44.255120  6508 net.cpp:434] Scale14 <- Convolution16
I0928 20:40:44.255120  6508 net.cpp:395] Scale14 -> Convolution16 (in-place)
I0928 20:40:44.255120  6508 layer_factory.cpp:58] Creating layer Scale14
I0928 20:40:44.255120  6508 net.cpp:150] Setting up Scale14
I0928 20:40:44.256119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.256119  6508 net.cpp:165] Memory required for data: 44606692
I0928 20:40:44.256119  6508 layer_factory.cpp:58] Creating layer ReLU11
I0928 20:40:44.256119  6508 net.cpp:100] Creating Layer ReLU11
I0928 20:40:44.256119  6508 net.cpp:434] ReLU11 <- Convolution16
I0928 20:40:44.256119  6508 net.cpp:395] ReLU11 -> Convolution16 (in-place)
I0928 20:40:44.256119  6508 net.cpp:150] Setting up ReLU11
I0928 20:40:44.256119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.256119  6508 net.cpp:165] Memory required for data: 44807396
I0928 20:40:44.256119  6508 layer_factory.cpp:58] Creating layer Convolution17
I0928 20:40:44.257119  6508 net.cpp:100] Creating Layer Convolution17
I0928 20:40:44.257119  6508 net.cpp:434] Convolution17 <- Convolution16
I0928 20:40:44.257119  6508 net.cpp:408] Convolution17 -> Convolution17
I0928 20:40:44.257119  6508 net.cpp:150] Setting up Convolution17
I0928 20:40:44.257119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.257119  6508 net.cpp:165] Memory required for data: 45008100
I0928 20:40:44.258119  6508 layer_factory.cpp:58] Creating layer BatchNorm15
I0928 20:40:44.258119  6508 net.cpp:100] Creating Layer BatchNorm15
I0928 20:40:44.258119  6508 net.cpp:434] BatchNorm15 <- Convolution17
I0928 20:40:44.258119  6508 net.cpp:395] BatchNorm15 -> Convolution17 (in-place)
I0928 20:40:44.258119  6508 net.cpp:150] Setting up BatchNorm15
I0928 20:40:44.258119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.258119  6508 net.cpp:165] Memory required for data: 45208804
I0928 20:40:44.258119  6508 layer_factory.cpp:58] Creating layer Scale15
I0928 20:40:44.259119  6508 net.cpp:100] Creating Layer Scale15
I0928 20:40:44.259119  6508 net.cpp:434] Scale15 <- Convolution17
I0928 20:40:44.259119  6508 net.cpp:395] Scale15 -> Convolution17 (in-place)
I0928 20:40:44.259119  6508 layer_factory.cpp:58] Creating layer Scale15
I0928 20:40:44.259119  6508 net.cpp:150] Setting up Scale15
I0928 20:40:44.259119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.259119  6508 net.cpp:165] Memory required for data: 45409508
I0928 20:40:44.259119  6508 layer_factory.cpp:58] Creating layer Pooling4
I0928 20:40:44.259119  6508 net.cpp:100] Creating Layer Pooling4
I0928 20:40:44.259119  6508 net.cpp:434] Pooling4 <- Eltwise6_Eltwise6_0_split_1
I0928 20:40:44.260119  6508 net.cpp:408] Pooling4 -> Pooling4
I0928 20:40:44.260119  6508 net.cpp:150] Setting up Pooling4
I0928 20:40:44.260119  6508 net.cpp:157] Top shape: 1 32 28 28 (25088)
I0928 20:40:44.260119  6508 net.cpp:165] Memory required for data: 45509860
I0928 20:40:44.260119  6508 layer_factory.cpp:58] Creating layer PadChannel2
I0928 20:40:44.260119  6508 net.cpp:100] Creating Layer PadChannel2
I0928 20:40:44.260119  6508 net.cpp:434] PadChannel2 <- Pooling4
I0928 20:40:44.260119  6508 net.cpp:408] PadChannel2 -> PadChannel2
I0928 20:40:44.260119  6508 net.cpp:150] Setting up PadChannel2
I0928 20:40:44.261119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.261119  6508 net.cpp:165] Memory required for data: 45710564
I0928 20:40:44.261119  6508 layer_factory.cpp:58] Creating layer Eltwise7
I0928 20:40:44.261119  6508 net.cpp:100] Creating Layer Eltwise7
I0928 20:40:44.261119  6508 net.cpp:434] Eltwise7 <- Convolution17
I0928 20:40:44.261119  6508 net.cpp:434] Eltwise7 <- PadChannel2
I0928 20:40:44.261119  6508 net.cpp:408] Eltwise7 -> Eltwise7
I0928 20:40:44.261119  6508 net.cpp:150] Setting up Eltwise7
I0928 20:40:44.262120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.262120  6508 net.cpp:165] Memory required for data: 45911268
I0928 20:40:44.262120  6508 layer_factory.cpp:58] Creating layer Eltwise7_Eltwise7_0_split
I0928 20:40:44.262120  6508 net.cpp:100] Creating Layer Eltwise7_Eltwise7_0_split
I0928 20:40:44.262120  6508 net.cpp:434] Eltwise7_Eltwise7_0_split <- Eltwise7
I0928 20:40:44.262120  6508 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_0
I0928 20:40:44.262120  6508 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_1
I0928 20:40:44.262120  6508 net.cpp:150] Setting up Eltwise7_Eltwise7_0_split
I0928 20:40:44.262120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.263119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.263119  6508 net.cpp:165] Memory required for data: 46312676
I0928 20:40:44.263119  6508 layer_factory.cpp:58] Creating layer Convolution18
I0928 20:40:44.263119  6508 net.cpp:100] Creating Layer Convolution18
I0928 20:40:44.263119  6508 net.cpp:434] Convolution18 <- Eltwise7_Eltwise7_0_split_0
I0928 20:40:44.263119  6508 net.cpp:408] Convolution18 -> Convolution18
I0928 20:40:44.264119  6508 net.cpp:150] Setting up Convolution18
I0928 20:40:44.264119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.264119  6508 net.cpp:165] Memory required for data: 46513380
I0928 20:40:44.264119  6508 layer_factory.cpp:58] Creating layer BatchNorm16
I0928 20:40:44.264119  6508 net.cpp:100] Creating Layer BatchNorm16
I0928 20:40:44.264119  6508 net.cpp:434] BatchNorm16 <- Convolution18
I0928 20:40:44.264119  6508 net.cpp:395] BatchNorm16 -> Convolution18 (in-place)
I0928 20:40:44.264119  6508 net.cpp:150] Setting up BatchNorm16
I0928 20:40:44.265120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.265120  6508 net.cpp:165] Memory required for data: 46714084
I0928 20:40:44.265120  6508 layer_factory.cpp:58] Creating layer Scale16
I0928 20:40:44.265120  6508 net.cpp:100] Creating Layer Scale16
I0928 20:40:44.265120  6508 net.cpp:434] Scale16 <- Convolution18
I0928 20:40:44.265120  6508 net.cpp:395] Scale16 -> Convolution18 (in-place)
I0928 20:40:44.265120  6508 layer_factory.cpp:58] Creating layer Scale16
I0928 20:40:44.265120  6508 net.cpp:150] Setting up Scale16
I0928 20:40:44.265120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.265120  6508 net.cpp:165] Memory required for data: 46914788
I0928 20:40:44.266119  6508 layer_factory.cpp:58] Creating layer ReLU12
I0928 20:40:44.266119  6508 net.cpp:100] Creating Layer ReLU12
I0928 20:40:44.266119  6508 net.cpp:434] ReLU12 <- Convolution18
I0928 20:40:44.266119  6508 net.cpp:395] ReLU12 -> Convolution18 (in-place)
I0928 20:40:44.266119  6508 net.cpp:150] Setting up ReLU12
I0928 20:40:44.266119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.266119  6508 net.cpp:165] Memory required for data: 47115492
I0928 20:40:44.266119  6508 layer_factory.cpp:58] Creating layer Convolution19
I0928 20:40:44.266119  6508 net.cpp:100] Creating Layer Convolution19
I0928 20:40:44.266119  6508 net.cpp:434] Convolution19 <- Convolution18
I0928 20:40:44.267119  6508 net.cpp:408] Convolution19 -> Convolution19
I0928 20:40:44.267119  6508 net.cpp:150] Setting up Convolution19
I0928 20:40:44.267119  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.267119  6508 net.cpp:165] Memory required for data: 47316196
I0928 20:40:44.267119  6508 layer_factory.cpp:58] Creating layer BatchNorm17
I0928 20:40:44.268120  6508 net.cpp:100] Creating Layer BatchNorm17
I0928 20:40:44.268120  6508 net.cpp:434] BatchNorm17 <- Convolution19
I0928 20:40:44.268120  6508 net.cpp:395] BatchNorm17 -> Convolution19 (in-place)
I0928 20:40:44.268120  6508 net.cpp:150] Setting up BatchNorm17
I0928 20:40:44.268120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.268120  6508 net.cpp:165] Memory required for data: 47516900
I0928 20:40:44.268120  6508 layer_factory.cpp:58] Creating layer Scale17
I0928 20:40:44.268120  6508 net.cpp:100] Creating Layer Scale17
I0928 20:40:44.268120  6508 net.cpp:434] Scale17 <- Convolution19
I0928 20:40:44.269120  6508 net.cpp:395] Scale17 -> Convolution19 (in-place)
I0928 20:40:44.269120  6508 layer_factory.cpp:58] Creating layer Scale17
I0928 20:40:44.269120  6508 net.cpp:150] Setting up Scale17
I0928 20:40:44.269120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.269120  6508 net.cpp:165] Memory required for data: 47717604
I0928 20:40:44.269120  6508 layer_factory.cpp:58] Creating layer Eltwise8
I0928 20:40:44.269120  6508 net.cpp:100] Creating Layer Eltwise8
I0928 20:40:44.269120  6508 net.cpp:434] Eltwise8 <- Eltwise7_Eltwise7_0_split_1
I0928 20:40:44.269120  6508 net.cpp:434] Eltwise8 <- Convolution19
I0928 20:40:44.270120  6508 net.cpp:408] Eltwise8 -> Eltwise8
I0928 20:40:44.270120  6508 net.cpp:150] Setting up Eltwise8
I0928 20:40:44.270120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.270120  6508 net.cpp:165] Memory required for data: 47918308
I0928 20:40:44.270120  6508 layer_factory.cpp:58] Creating layer Eltwise8_Eltwise8_0_split
I0928 20:40:44.270120  6508 net.cpp:100] Creating Layer Eltwise8_Eltwise8_0_split
I0928 20:40:44.270120  6508 net.cpp:434] Eltwise8_Eltwise8_0_split <- Eltwise8
I0928 20:40:44.270120  6508 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I0928 20:40:44.270120  6508 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I0928 20:40:44.271121  6508 net.cpp:150] Setting up Eltwise8_Eltwise8_0_split
I0928 20:40:44.271121  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.271121  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.271121  6508 net.cpp:165] Memory required for data: 48319716
I0928 20:40:44.271121  6508 layer_factory.cpp:58] Creating layer Convolution20
I0928 20:40:44.271121  6508 net.cpp:100] Creating Layer Convolution20
I0928 20:40:44.271121  6508 net.cpp:434] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I0928 20:40:44.271121  6508 net.cpp:408] Convolution20 -> Convolution20
I0928 20:40:44.272120  6508 net.cpp:150] Setting up Convolution20
I0928 20:40:44.272120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.272120  6508 net.cpp:165] Memory required for data: 48520420
I0928 20:40:44.272120  6508 layer_factory.cpp:58] Creating layer BatchNorm18
I0928 20:40:44.272120  6508 net.cpp:100] Creating Layer BatchNorm18
I0928 20:40:44.272120  6508 net.cpp:434] BatchNorm18 <- Convolution20
I0928 20:40:44.273120  6508 net.cpp:395] BatchNorm18 -> Convolution20 (in-place)
I0928 20:40:44.273120  6508 net.cpp:150] Setting up BatchNorm18
I0928 20:40:44.273120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.273120  6508 net.cpp:165] Memory required for data: 48721124
I0928 20:40:44.273120  6508 layer_factory.cpp:58] Creating layer Scale18
I0928 20:40:44.273120  6508 net.cpp:100] Creating Layer Scale18
I0928 20:40:44.273120  6508 net.cpp:434] Scale18 <- Convolution20
I0928 20:40:44.273120  6508 net.cpp:395] Scale18 -> Convolution20 (in-place)
I0928 20:40:44.273120  6508 layer_factory.cpp:58] Creating layer Scale18
I0928 20:40:44.273120  6508 net.cpp:150] Setting up Scale18
I0928 20:40:44.274121  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.274121  6508 net.cpp:165] Memory required for data: 48921828
I0928 20:40:44.274121  6508 layer_factory.cpp:58] Creating layer ReLU13
I0928 20:40:44.274121  6508 net.cpp:100] Creating Layer ReLU13
I0928 20:40:44.274121  6508 net.cpp:434] ReLU13 <- Convolution20
I0928 20:40:44.274121  6508 net.cpp:395] ReLU13 -> Convolution20 (in-place)
I0928 20:40:44.274121  6508 net.cpp:150] Setting up ReLU13
I0928 20:40:44.274121  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.274121  6508 net.cpp:165] Memory required for data: 49122532
I0928 20:40:44.275120  6508 layer_factory.cpp:58] Creating layer Convolution21
I0928 20:40:44.275120  6508 net.cpp:100] Creating Layer Convolution21
I0928 20:40:44.275120  6508 net.cpp:434] Convolution21 <- Convolution20
I0928 20:40:44.275120  6508 net.cpp:408] Convolution21 -> Convolution21
I0928 20:40:44.275120  6508 net.cpp:150] Setting up Convolution21
I0928 20:40:44.276120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.276120  6508 net.cpp:165] Memory required for data: 49323236
I0928 20:40:44.276120  6508 layer_factory.cpp:58] Creating layer BatchNorm19
I0928 20:40:44.276120  6508 net.cpp:100] Creating Layer BatchNorm19
I0928 20:40:44.276120  6508 net.cpp:434] BatchNorm19 <- Convolution21
I0928 20:40:44.276120  6508 net.cpp:395] BatchNorm19 -> Convolution21 (in-place)
I0928 20:40:44.276120  6508 net.cpp:150] Setting up BatchNorm19
I0928 20:40:44.276120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.276120  6508 net.cpp:165] Memory required for data: 49523940
I0928 20:40:44.276120  6508 layer_factory.cpp:58] Creating layer Scale19
I0928 20:40:44.277120  6508 net.cpp:100] Creating Layer Scale19
I0928 20:40:44.277120  6508 net.cpp:434] Scale19 <- Convolution21
I0928 20:40:44.277120  6508 net.cpp:395] Scale19 -> Convolution21 (in-place)
I0928 20:40:44.277120  6508 layer_factory.cpp:58] Creating layer Scale19
I0928 20:40:44.277120  6508 net.cpp:150] Setting up Scale19
I0928 20:40:44.277120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.277120  6508 net.cpp:165] Memory required for data: 49724644
I0928 20:40:44.277120  6508 layer_factory.cpp:58] Creating layer Eltwise9
I0928 20:40:44.278120  6508 net.cpp:100] Creating Layer Eltwise9
I0928 20:40:44.278120  6508 net.cpp:434] Eltwise9 <- Eltwise8_Eltwise8_0_split_1
I0928 20:40:44.278120  6508 net.cpp:434] Eltwise9 <- Convolution21
I0928 20:40:44.278120  6508 net.cpp:408] Eltwise9 -> Eltwise9
I0928 20:40:44.278120  6508 net.cpp:150] Setting up Eltwise9
I0928 20:40:44.278120  6508 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:40:44.278120  6508 net.cpp:165] Memory required for data: 49925348
I0928 20:40:44.278120  6508 layer_factory.cpp:58] Creating layer Pooling5
I0928 20:40:44.278120  6508 net.cpp:100] Creating Layer Pooling5
I0928 20:40:44.279120  6508 net.cpp:434] Pooling5 <- Eltwise9
I0928 20:40:44.279120  6508 net.cpp:408] Pooling5 -> Pooling5
I0928 20:40:44.279120  6508 net.cpp:150] Setting up Pooling5
I0928 20:40:44.279120  6508 net.cpp:157] Top shape: 1 64 1 1 (64)
I0928 20:40:44.279120  6508 net.cpp:165] Memory required for data: 49925604
I0928 20:40:44.279120  6508 layer_factory.cpp:58] Creating layer InnerProduct4
I0928 20:40:44.279120  6508 net.cpp:100] Creating Layer InnerProduct4
I0928 20:40:44.279120  6508 net.cpp:434] InnerProduct4 <- Pooling5
I0928 20:40:44.279120  6508 net.cpp:408] InnerProduct4 -> InnerProduct4
I0928 20:40:44.280120  6508 net.cpp:150] Setting up InnerProduct4
I0928 20:40:44.280120  6508 net.cpp:157] Top shape: 1 2 (2)
I0928 20:40:44.280120  6508 net.cpp:165] Memory required for data: 49925612
I0928 20:40:44.280120  6508 layer_factory.cpp:58] Creating layer InnerProduct4_InnerProduct4_0_split
I0928 20:40:44.280120  6508 net.cpp:100] Creating Layer InnerProduct4_InnerProduct4_0_split
I0928 20:40:44.280120  6508 net.cpp:434] InnerProduct4_InnerProduct4_0_split <- InnerProduct4
I0928 20:40:44.280120  6508 net.cpp:408] InnerProduct4_InnerProduct4_0_split -> InnerProduct4_InnerProduct4_0_split_0
I0928 20:40:44.280120  6508 net.cpp:408] InnerProduct4_InnerProduct4_0_split -> InnerProduct4_InnerProduct4_0_split_1
I0928 20:40:44.281121  6508 net.cpp:150] Setting up InnerProduct4_InnerProduct4_0_split
I0928 20:40:44.281121  6508 net.cpp:157] Top shape: 1 2 (2)
I0928 20:40:44.281121  6508 net.cpp:157] Top shape: 1 2 (2)
I0928 20:40:44.281121  6508 net.cpp:165] Memory required for data: 49925628
I0928 20:40:44.281121  6508 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:40:44.281121  6508 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0928 20:40:44.281121  6508 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct4_InnerProduct4_0_split_0
I0928 20:40:44.281121  6508 net.cpp:434] SoftmaxWithLoss1 <- ImageData2_ImageData1_1_split_0
I0928 20:40:44.282120  6508 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 20:40:44.282120  6508 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:40:44.282120  6508 net.cpp:150] Setting up SoftmaxWithLoss1
I0928 20:40:44.282120  6508 net.cpp:157] Top shape: (1)
I0928 20:40:44.282120  6508 net.cpp:160]     with loss weight 1
I0928 20:40:44.282120  6508 net.cpp:165] Memory required for data: 49925632
I0928 20:40:44.282120  6508 layer_factory.cpp:58] Creating layer Accuracy1
I0928 20:40:44.282120  6508 net.cpp:100] Creating Layer Accuracy1
I0928 20:40:44.283120  6508 net.cpp:434] Accuracy1 <- InnerProduct4_InnerProduct4_0_split_1
I0928 20:40:44.283120  6508 net.cpp:434] Accuracy1 <- ImageData2_ImageData1_1_split_1
I0928 20:40:44.283120  6508 net.cpp:408] Accuracy1 -> Accuracy1
I0928 20:40:44.283120  6508 net.cpp:150] Setting up Accuracy1
I0928 20:40:44.283120  6508 net.cpp:157] Top shape: (1)
I0928 20:40:44.283120  6508 net.cpp:165] Memory required for data: 49925636
I0928 20:40:44.283120  6508 net.cpp:228] Accuracy1 does not need backward computation.
I0928 20:40:44.283120  6508 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0928 20:40:44.283120  6508 net.cpp:226] InnerProduct4_InnerProduct4_0_split needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] InnerProduct4 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] Pooling5 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] Eltwise9 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] Scale19 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] BatchNorm19 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] Convolution21 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] ReLU13 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] Scale18 needs backward computation.
I0928 20:40:44.284121  6508 net.cpp:226] BatchNorm18 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Convolution20 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Eltwise8_Eltwise8_0_split needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Eltwise8 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Scale17 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] BatchNorm17 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Convolution19 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] ReLU12 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] Scale16 needs backward computation.
I0928 20:40:44.285120  6508 net.cpp:226] BatchNorm16 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Convolution18 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Eltwise7_Eltwise7_0_split needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Eltwise7 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] PadChannel2 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Pooling4 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Scale15 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] BatchNorm15 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] Convolution17 needs backward computation.
I0928 20:40:44.286120  6508 net.cpp:226] ReLU11 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Scale14 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] BatchNorm14 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Convolution16 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Eltwise6_Eltwise6_0_split needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Eltwise6 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Scale13 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] BatchNorm13 needs backward computation.
I0928 20:40:44.287122  6508 net.cpp:226] Convolution15 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] ReLU10 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] Scale12 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] BatchNorm12 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] Convolution14 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] Eltwise5_Eltwise5_0_split needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] Eltwise5 needs backward computation.
I0928 20:40:44.288121  6508 net.cpp:226] Scale11 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] BatchNorm11 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] Convolution13 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] ReLU9 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] Scale10 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] BatchNorm10 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] Convolution12 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] Eltwise4_Eltwise4_0_split needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] Eltwise4 needs backward computation.
I0928 20:40:44.289121  6508 net.cpp:226] PadChannel1 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Pooling3 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Scale9 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] BatchNorm9 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Convolution11 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] ReLU8 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Scale8 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] BatchNorm8 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Convolution10 needs backward computation.
I0928 20:40:44.290122  6508 net.cpp:226] Eltwise3_Eltwise3_0_split needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Eltwise3 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Scale7 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] BatchNorm7 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Convolution9 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] ReLU7 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Scale6 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] BatchNorm6 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Convolution8 needs backward computation.
I0928 20:40:44.291121  6508 net.cpp:226] Eltwise2_Eltwise2_0_split needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Eltwise2 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Scale5 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] BatchNorm5 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Convolution7 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] ReLU6 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Scale4 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] BatchNorm4 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Convolution6 needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Eltwise1_Eltwise1_0_split needs backward computation.
I0928 20:40:44.292121  6508 net.cpp:226] Eltwise1 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] Scale3 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] BatchNorm3 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] Convolution5 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] ReLU5 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] Scale2 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] BatchNorm2 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] Convolution4 needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] Convolution3_ReLU4_0_split needs backward computation.
I0928 20:40:44.293121  6508 net.cpp:226] ReLU4 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] Scale1 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] BatchNorm1 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] Convolution3 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] Transformer1 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] InnerProduct3 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] InnerProduct2 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] ReLU3 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] InnerProduct1 needs backward computation.
I0928 20:40:44.294121  6508 net.cpp:226] Pooling2 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:226] ReLU2 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:226] Convolution2 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:226] Pooling1 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:226] ReLU1 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:226] Convolution1 needs backward computation.
I0928 20:40:44.295121  6508 net.cpp:228] ImageData2_ImageData1_1_split does not need backward computation.
I0928 20:40:44.295121  6508 net.cpp:228] ImageData1_ImageData1_0_split does not need backward computation.
I0928 20:40:44.295121  6508 net.cpp:228] ImageData1 does not need backward computation.
I0928 20:40:44.295121  6508 net.cpp:270] This network produces output Accuracy1
I0928 20:40:44.296121  6508 net.cpp:270] This network produces output SoftmaxWithLoss1
I0928 20:40:44.296121  6508 net.cpp:283] Network initialization done.
I0928 20:40:44.296121  6508 solver.cpp:60] Solver scaffolding done.
I0928 20:40:44.296121  6508 caffe.cpp:252] Starting Optimization
I0928 20:40:44.296121  6508 solver.cpp:279] Solving resnet_cifar10
I0928 20:40:44.297122  6508 solver.cpp:280] Learning Rate Policy: step
I0928 20:40:44.310122  6508 transformer_layer.cpp:48] theta:0.000126304 -0.000235823 -0.000120005
-0.000283531 2.0697e-005 -7.68611e-005
I0928 20:40:44.327123  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:44.327123  6508 transformer_layer.cpp:65] -1.0486e-005 -1.46972e-005 -1.89083e-005
-2.31194e-005 -2.73305e-005 -3.15417e-005
-3.57528e-005 -3.99639e-005 -4.4175e-005
-4.83862e-005 -5.25973e-005 -5.68084e-005
-6.10196e-005 -6.52307e-005 -6.94418e-005
-7.36529e-005 -7.78641e-005 -8.20752e-005
I0928 20:40:44.749147  6508 solver.cpp:228] Iteration 0, loss = 0.693008
I0928 20:40:44.750147  6508 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.693008 (* 1 = 0.693008 loss)
I0928 20:40:44.750147  6508 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0928 20:40:44.760149  6508 transformer_layer.cpp:48] theta:0.000980272 -0.000728549 -0.000242505
-0.000561426 0.000380109 -0.000254936
I0928 20:40:44.761148  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:44.761148  6508 transformer_layer.cpp:65] -0.000494228 -0.000507238 -0.000520248
-0.000533257 -0.000546267 -0.000559277
-0.000572287 -0.000585297 -0.000598307
-0.000611316 -0.000624326 -0.000637336
-0.000650346 -0.000663356 -0.000676365
-0.000689375 -0.000702385 -0.000715395
I0928 20:40:45.189172  6508 transformer_layer.cpp:48] theta:0.000415813 -0.00042978 0.00150222
6.79015e-005 0.000599198 -0.000432593
I0928 20:40:45.189172  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:45.189172  6508 transformer_layer.cpp:65] 0.00151619 0.00150851 0.00150084
0.00149316 0.00148549 0.00147781
0.00147014 0.00146247 0.00145479
0.00144712 0.00143944 0.00143177
0.00142409 0.00141642 0.00140874
0.00140107 0.00139339 0.00138572
I0928 20:40:45.596195  6508 transformer_layer.cpp:48] theta:-0.00112871 0.000121007 0.00480603
0.000338028 0.000653106 0.00102557
I0928 20:40:45.597195  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:45.597195  6508 transformer_layer.cpp:65] 0.00581373 0.00581589 0.00581805
0.00582021 0.00582237 0.00582453
0.00582669 0.00582885 0.00583102
0.00583318 0.00583534 0.0058375
0.00583966 0.00584182 0.00584398
0.00584614 0.0058483 0.00585046
I0928 20:40:46.002219  6508 transformer_layer.cpp:48] theta:-0.247358 0.0679173 0.0260848
0.185097 -0.0605072 0.0573402
I0928 20:40:46.003219  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:46.003219  6508 transformer_layer.cpp:65] 0.205525 0.206738 0.207951
0.209164 0.210376 0.211589
0.212802 0.214015 0.215228
0.21644 0.217653 0.218866
0.220079 0.221292 0.222504
0.223717 0.22493 0.226143
I0928 20:40:46.400241  6508 transformer_layer.cpp:48] theta:-0.466461 0.130956 0.0516988
0.367516 -0.117203 0.121434
I0928 20:40:46.401242  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:46.401242  6508 transformer_layer.cpp:65] 0.387204 0.389543 0.391881
0.39422 0.396558 0.398897
0.401235 0.403574 0.405912
0.408251 0.410589 0.412928
0.415266 0.417605 0.419943
0.422282 0.42462 0.426959
I0928 20:40:46.800264  6508 transformer_layer.cpp:48] theta:-0.666537 0.188092 0.0723409
0.532043 -0.170268 0.181685
I0928 20:40:46.800264  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:46.801265  6508 transformer_layer.cpp:65] 0.550786 0.554145 0.557504
0.560863 0.564221 0.56758
0.570939 0.574298 0.577656
0.581015 0.584374 0.587733
0.591092 0.59445 0.597809
0.601168 0.604527 0.607885
I0928 20:40:47.204288  6508 transformer_layer.cpp:48] theta:-0.845968 0.238786 0.0890953
0.677009 -0.216779 0.232493
I0928 20:40:47.205287  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:47.205287  6508 transformer_layer.cpp:65] 0.696277 0.700541 0.704805
0.709069 0.713333 0.717597
0.721862 0.726126 0.73039
0.734654 0.738918 0.743182
0.747446 0.75171 0.755974
0.760238 0.764502 0.768766
I0928 20:40:47.610311  6508 transformer_layer.cpp:48] theta:-1.00585 0.287017 0.107782
0.809358 -0.253516 0.280668
I0928 20:40:47.610311  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:47.611311  6508 transformer_layer.cpp:65] 0.826612 0.831737 0.836862
0.841987 0.847113 0.852238
0.857363 0.862489 0.867614
0.872739 0.877865 0.88299
0.888115 0.893241 0.898366
0.903491 0.908617 0.913742
I0928 20:40:48.003928  6508 transformer_layer.cpp:48] theta:-1.15063 0.330679 0.124034
0.928227 -0.287251 0.32309
I0928 20:40:48.003928  6508 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:40:48.003928  6508 transformer_layer.cpp:65] 0.943989 0.949894 0.955799
0.961704 0.967609 0.973514
0.979419 0.985323 0.991228
0.997133 1.00304 1.00894
1.01485 1.02075 1.02666
1.03256 1.03847 1.04437
I0928 20:40:48.362730  6508 solver.cpp:454] Snapshotting to binary proto file snapshots/test_iter_10.caffemodel
I0928 20:40:48.378329  6508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/test_iter_10.solverstate
I0928 20:40:48.393929  6508 solver.cpp:322] Optimization Done.
I0928 20:40:48.393929  6508 caffe.cpp:255] Optimization Done.
