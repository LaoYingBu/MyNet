Log file created at: 2017/09/28 20:43:00
Running on machine: DNR4IPCOUPNVNIN
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0928 20:43:00.002517  8576 caffe.cpp:211] Use CPU.
I0928 20:43:00.002517  8576 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 600000
base_lr: 0.1
display: 20
max_iter: 10
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 150000
snapshot: 5000
snapshot_prefix: "snapshots/test"
solver_mode: CPU
net: "resnet_20_train_test_STN.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0928 20:43:00.002517  8576 solver.cpp:91] Creating training net from net file: resnet_20_train_test_STN.prototxt
I0928 20:43:00.002517  8576 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet_20_train_test_STN.prototxt
I0928 20:43:00.002517  8576 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 20:43:00.002517  8576 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer ImageData1
I0928 20:43:00.002517  8576 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0928 20:43:00.002517  8576 net.cpp:58] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "ImageData1"
  type: "ImageData"
  top: "ImageData1"
  top: "ImageData2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    crop_size: 112
    mean_value: 128
  }
  image_data_param {
    source: "image_list.txt"
    batch_size: 1
    shuffle: true
    new_height: 0
    new_width: 0
    is_color: false
    root_folder: ""
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "ImageData1"
  top: "Convolution1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling2"
  top: "InnerProduct1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "InnerProduct2"
  top: "InnerProduct3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 6
    weight_filler {
      type: "gaussian"
      value: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Transformer1"
  type: "Transformer"
  bottom: "ImageData1"
  bottom: "InnerProduct3"
  top: "Transformer1"
  transformer_param {
    num_theta: 6
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Transformer1"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution5"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution7"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution9"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise3"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel1"
  type: "PadChannel"
  bottom: "Pooling3"
  top: "PadChannel1"
  pad_channel_param {
    num_channels_to_pad: 16
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "PadChannel1"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution15"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Eltwise6"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel2"
  type: "PadChannel"
  bottom: "Pooling4"
  top: "PadChannel2"
  pad_channel_param {
    num_channels_to_pad: 32
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "PadChannel2"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Pooling5"
  top: "InnerProduct4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "SoftmaxWithLoss1"
}
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer ImageData1
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer ImageData1
I0928 20:43:00.080518  8576 net.cpp:408] ImageData1 -> ImageData1
I0928 20:43:00.080518  8576 net.cpp:408] ImageData1 -> ImageData2
I0928 20:43:00.080518  8576 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0928 20:43:00.080518  8576 image_data_layer.cpp:38] Opening file image_list.txt
I0928 20:43:00.080518  8576 image_data_layer.cpp:53] Shuffling data
I0928 20:43:00.080518  8576 image_data_layer.cpp:58] A total of 1 images.
I0928 20:43:00.080518  8576 image_data_layer.cpp:85] output data size: 1,1,112,112
I0928 20:43:00.080518  8576 net.cpp:150] Setting up ImageData1
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 (1)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 50180
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer ImageData1_ImageData1_0_split
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer ImageData1_ImageData1_0_split
I0928 20:43:00.080518  8576 net.cpp:434] ImageData1_ImageData1_0_split <- ImageData1
I0928 20:43:00.080518  8576 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_0
I0928 20:43:00.080518  8576 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_1
I0928 20:43:00.080518  8576 net.cpp:150] Setting up ImageData1_ImageData1_0_split
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 150532
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer Convolution1
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer Convolution1
I0928 20:43:00.080518  8576 net.cpp:434] Convolution1 <- ImageData1_ImageData1_0_split_0
I0928 20:43:00.080518  8576 net.cpp:408] Convolution1 -> Convolution1
I0928 20:43:00.080518  8576 net.cpp:150] Setting up Convolution1
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 953348
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer ReLU1
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer ReLU1
I0928 20:43:00.080518  8576 net.cpp:434] ReLU1 <- Convolution1
I0928 20:43:00.080518  8576 net.cpp:395] ReLU1 -> Convolution1 (in-place)
I0928 20:43:00.080518  8576 net.cpp:150] Setting up ReLU1
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 1756164
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer Pooling1
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer Pooling1
I0928 20:43:00.080518  8576 net.cpp:434] Pooling1 <- Convolution1
I0928 20:43:00.080518  8576 net.cpp:408] Pooling1 -> Pooling1
I0928 20:43:00.080518  8576 net.cpp:150] Setting up Pooling1
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 1956868
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer Convolution2
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer Convolution2
I0928 20:43:00.080518  8576 net.cpp:434] Convolution2 <- Pooling1
I0928 20:43:00.080518  8576 net.cpp:408] Convolution2 -> Convolution2
I0928 20:43:00.080518  8576 net.cpp:150] Setting up Convolution2
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 2157572
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer ReLU2
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer ReLU2
I0928 20:43:00.080518  8576 net.cpp:434] ReLU2 <- Convolution2
I0928 20:43:00.080518  8576 net.cpp:395] ReLU2 -> Convolution2 (in-place)
I0928 20:43:00.080518  8576 net.cpp:150] Setting up ReLU2
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 2358276
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer Pooling2
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer Pooling2
I0928 20:43:00.080518  8576 net.cpp:434] Pooling2 <- Convolution2
I0928 20:43:00.080518  8576 net.cpp:408] Pooling2 -> Pooling2
I0928 20:43:00.080518  8576 net.cpp:150] Setting up Pooling2
I0928 20:43:00.080518  8576 net.cpp:157] Top shape: 1 16 28 28 (12544)
I0928 20:43:00.080518  8576 net.cpp:165] Memory required for data: 2408452
I0928 20:43:00.080518  8576 layer_factory.cpp:58] Creating layer InnerProduct1
I0928 20:43:00.080518  8576 net.cpp:100] Creating Layer InnerProduct1
I0928 20:43:00.080518  8576 net.cpp:434] InnerProduct1 <- Pooling2
I0928 20:43:00.080518  8576 net.cpp:408] InnerProduct1 -> InnerProduct1
I0928 20:43:00.080518  8576 net.cpp:150] Setting up InnerProduct1
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 2408516
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer ReLU3
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer ReLU3
I0928 20:43:00.096117  8576 net.cpp:434] ReLU3 <- InnerProduct1
I0928 20:43:00.096117  8576 net.cpp:395] ReLU3 -> InnerProduct1 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up ReLU3
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 2408580
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer InnerProduct2
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer InnerProduct2
I0928 20:43:00.096117  8576 net.cpp:434] InnerProduct2 <- InnerProduct1
I0928 20:43:00.096117  8576 net.cpp:408] InnerProduct2 -> InnerProduct2
I0928 20:43:00.096117  8576 net.cpp:150] Setting up InnerProduct2
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 2408644
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer InnerProduct3
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer InnerProduct3
I0928 20:43:00.096117  8576 net.cpp:434] InnerProduct3 <- InnerProduct2
I0928 20:43:00.096117  8576 net.cpp:408] InnerProduct3 -> InnerProduct3
I0928 20:43:00.096117  8576 net.cpp:150] Setting up InnerProduct3
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 6 (6)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 2408668
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Transformer1
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Transformer1
I0928 20:43:00.096117  8576 net.cpp:434] Transformer1 <- ImageData1_ImageData1_0_split_1
I0928 20:43:00.096117  8576 net.cpp:434] Transformer1 <- InnerProduct3
I0928 20:43:00.096117  8576 net.cpp:408] Transformer1 -> Transformer1
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Transformer1
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 2458844
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Convolution3
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Convolution3
I0928 20:43:00.096117  8576 net.cpp:434] Convolution3 <- Transformer1
I0928 20:43:00.096117  8576 net.cpp:408] Convolution3 -> Convolution3
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Convolution3
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 3261660
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer BatchNorm1
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer BatchNorm1
I0928 20:43:00.096117  8576 net.cpp:434] BatchNorm1 <- Convolution3
I0928 20:43:00.096117  8576 net.cpp:395] BatchNorm1 -> Convolution3 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up BatchNorm1
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 4064476
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale1
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Scale1
I0928 20:43:00.096117  8576 net.cpp:434] Scale1 <- Convolution3
I0928 20:43:00.096117  8576 net.cpp:395] Scale1 -> Convolution3 (in-place)
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale1
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Scale1
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 4867292
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer ReLU4
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer ReLU4
I0928 20:43:00.096117  8576 net.cpp:434] ReLU4 <- Convolution3
I0928 20:43:00.096117  8576 net.cpp:395] ReLU4 -> Convolution3 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up ReLU4
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 5670108
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Convolution3_ReLU4_0_split
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Convolution3_ReLU4_0_split
I0928 20:43:00.096117  8576 net.cpp:434] Convolution3_ReLU4_0_split <- Convolution3
I0928 20:43:00.096117  8576 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_0
I0928 20:43:00.096117  8576 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_1
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Convolution3_ReLU4_0_split
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 7275740
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Convolution4
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Convolution4
I0928 20:43:00.096117  8576 net.cpp:434] Convolution4 <- Convolution3_ReLU4_0_split_0
I0928 20:43:00.096117  8576 net.cpp:408] Convolution4 -> Convolution4
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Convolution4
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 8078556
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer BatchNorm2
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer BatchNorm2
I0928 20:43:00.096117  8576 net.cpp:434] BatchNorm2 <- Convolution4
I0928 20:43:00.096117  8576 net.cpp:395] BatchNorm2 -> Convolution4 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up BatchNorm2
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 8881372
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale2
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Scale2
I0928 20:43:00.096117  8576 net.cpp:434] Scale2 <- Convolution4
I0928 20:43:00.096117  8576 net.cpp:395] Scale2 -> Convolution4 (in-place)
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale2
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Scale2
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 9684188
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer ReLU5
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer ReLU5
I0928 20:43:00.096117  8576 net.cpp:434] ReLU5 <- Convolution4
I0928 20:43:00.096117  8576 net.cpp:395] ReLU5 -> Convolution4 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up ReLU5
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 10487004
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Convolution5
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Convolution5
I0928 20:43:00.096117  8576 net.cpp:434] Convolution5 <- Convolution4
I0928 20:43:00.096117  8576 net.cpp:408] Convolution5 -> Convolution5
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Convolution5
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 11289820
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer BatchNorm3
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer BatchNorm3
I0928 20:43:00.096117  8576 net.cpp:434] BatchNorm3 <- Convolution5
I0928 20:43:00.096117  8576 net.cpp:395] BatchNorm3 -> Convolution5 (in-place)
I0928 20:43:00.096117  8576 net.cpp:150] Setting up BatchNorm3
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 12092636
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale3
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Scale3
I0928 20:43:00.096117  8576 net.cpp:434] Scale3 <- Convolution5
I0928 20:43:00.096117  8576 net.cpp:395] Scale3 -> Convolution5 (in-place)
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Scale3
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Scale3
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 12895452
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Eltwise1
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Eltwise1
I0928 20:43:00.096117  8576 net.cpp:434] Eltwise1 <- Convolution3_ReLU4_0_split_1
I0928 20:43:00.096117  8576 net.cpp:434] Eltwise1 <- Convolution5
I0928 20:43:00.096117  8576 net.cpp:408] Eltwise1 -> Eltwise1
I0928 20:43:00.096117  8576 net.cpp:150] Setting up Eltwise1
I0928 20:43:00.096117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.096117  8576 net.cpp:165] Memory required for data: 13698268
I0928 20:43:00.096117  8576 layer_factory.cpp:58] Creating layer Eltwise1_Eltwise1_0_split
I0928 20:43:00.096117  8576 net.cpp:100] Creating Layer Eltwise1_Eltwise1_0_split
I0928 20:43:00.096117  8576 net.cpp:434] Eltwise1_Eltwise1_0_split <- Eltwise1
I0928 20:43:00.096117  8576 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_0
I0928 20:43:00.111717  8576 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_1
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Eltwise1_Eltwise1_0_split
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 15303900
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Convolution6
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Convolution6
I0928 20:43:00.111717  8576 net.cpp:434] Convolution6 <- Eltwise1_Eltwise1_0_split_0
I0928 20:43:00.111717  8576 net.cpp:408] Convolution6 -> Convolution6
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Convolution6
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 16106716
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer BatchNorm4
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer BatchNorm4
I0928 20:43:00.111717  8576 net.cpp:434] BatchNorm4 <- Convolution6
I0928 20:43:00.111717  8576 net.cpp:395] BatchNorm4 -> Convolution6 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up BatchNorm4
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 16909532
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale4
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Scale4
I0928 20:43:00.111717  8576 net.cpp:434] Scale4 <- Convolution6
I0928 20:43:00.111717  8576 net.cpp:395] Scale4 -> Convolution6 (in-place)
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale4
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Scale4
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 17712348
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer ReLU6
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer ReLU6
I0928 20:43:00.111717  8576 net.cpp:434] ReLU6 <- Convolution6
I0928 20:43:00.111717  8576 net.cpp:395] ReLU6 -> Convolution6 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up ReLU6
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 18515164
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Convolution7
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Convolution7
I0928 20:43:00.111717  8576 net.cpp:434] Convolution7 <- Convolution6
I0928 20:43:00.111717  8576 net.cpp:408] Convolution7 -> Convolution7
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Convolution7
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 19317980
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer BatchNorm5
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer BatchNorm5
I0928 20:43:00.111717  8576 net.cpp:434] BatchNorm5 <- Convolution7
I0928 20:43:00.111717  8576 net.cpp:395] BatchNorm5 -> Convolution7 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up BatchNorm5
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 20120796
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale5
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Scale5
I0928 20:43:00.111717  8576 net.cpp:434] Scale5 <- Convolution7
I0928 20:43:00.111717  8576 net.cpp:395] Scale5 -> Convolution7 (in-place)
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale5
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Scale5
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 20923612
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Eltwise2
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Eltwise2
I0928 20:43:00.111717  8576 net.cpp:434] Eltwise2 <- Eltwise1_Eltwise1_0_split_1
I0928 20:43:00.111717  8576 net.cpp:434] Eltwise2 <- Convolution7
I0928 20:43:00.111717  8576 net.cpp:408] Eltwise2 -> Eltwise2
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Eltwise2
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 21726428
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Eltwise2_Eltwise2_0_split
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Eltwise2_Eltwise2_0_split
I0928 20:43:00.111717  8576 net.cpp:434] Eltwise2_Eltwise2_0_split <- Eltwise2
I0928 20:43:00.111717  8576 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_0
I0928 20:43:00.111717  8576 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_1
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Eltwise2_Eltwise2_0_split
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 23332060
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Convolution8
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Convolution8
I0928 20:43:00.111717  8576 net.cpp:434] Convolution8 <- Eltwise2_Eltwise2_0_split_0
I0928 20:43:00.111717  8576 net.cpp:408] Convolution8 -> Convolution8
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Convolution8
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 24134876
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer BatchNorm6
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer BatchNorm6
I0928 20:43:00.111717  8576 net.cpp:434] BatchNorm6 <- Convolution8
I0928 20:43:00.111717  8576 net.cpp:395] BatchNorm6 -> Convolution8 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up BatchNorm6
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 24937692
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale6
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Scale6
I0928 20:43:00.111717  8576 net.cpp:434] Scale6 <- Convolution8
I0928 20:43:00.111717  8576 net.cpp:395] Scale6 -> Convolution8 (in-place)
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale6
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Scale6
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 25740508
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer ReLU7
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer ReLU7
I0928 20:43:00.111717  8576 net.cpp:434] ReLU7 <- Convolution8
I0928 20:43:00.111717  8576 net.cpp:395] ReLU7 -> Convolution8 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up ReLU7
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 26543324
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Convolution9
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Convolution9
I0928 20:43:00.111717  8576 net.cpp:434] Convolution9 <- Convolution8
I0928 20:43:00.111717  8576 net.cpp:408] Convolution9 -> Convolution9
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Convolution9
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 27346140
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer BatchNorm7
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer BatchNorm7
I0928 20:43:00.111717  8576 net.cpp:434] BatchNorm7 <- Convolution9
I0928 20:43:00.111717  8576 net.cpp:395] BatchNorm7 -> Convolution9 (in-place)
I0928 20:43:00.111717  8576 net.cpp:150] Setting up BatchNorm7
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 28148956
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale7
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Scale7
I0928 20:43:00.111717  8576 net.cpp:434] Scale7 <- Convolution9
I0928 20:43:00.111717  8576 net.cpp:395] Scale7 -> Convolution9 (in-place)
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Scale7
I0928 20:43:00.111717  8576 net.cpp:150] Setting up Scale7
I0928 20:43:00.111717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.111717  8576 net.cpp:165] Memory required for data: 28951772
I0928 20:43:00.111717  8576 layer_factory.cpp:58] Creating layer Eltwise3
I0928 20:43:00.111717  8576 net.cpp:100] Creating Layer Eltwise3
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise3 <- Eltwise2_Eltwise2_0_split_1
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise3 <- Convolution9
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise3 -> Eltwise3
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Eltwise3
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 29754588
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Eltwise3_Eltwise3_0_split
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Eltwise3_Eltwise3_0_split
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise3_Eltwise3_0_split <- Eltwise3
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_0
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_1
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Eltwise3_Eltwise3_0_split
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 31360220
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Convolution10
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Convolution10
I0928 20:43:00.127317  8576 net.cpp:434] Convolution10 <- Eltwise3_Eltwise3_0_split_0
I0928 20:43:00.127317  8576 net.cpp:408] Convolution10 -> Convolution10
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Convolution10
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 31761628
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer BatchNorm8
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer BatchNorm8
I0928 20:43:00.127317  8576 net.cpp:434] BatchNorm8 <- Convolution10
I0928 20:43:00.127317  8576 net.cpp:395] BatchNorm8 -> Convolution10 (in-place)
I0928 20:43:00.127317  8576 net.cpp:150] Setting up BatchNorm8
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 32163036
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Scale8
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Scale8
I0928 20:43:00.127317  8576 net.cpp:434] Scale8 <- Convolution10
I0928 20:43:00.127317  8576 net.cpp:395] Scale8 -> Convolution10 (in-place)
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Scale8
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Scale8
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 32564444
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer ReLU8
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer ReLU8
I0928 20:43:00.127317  8576 net.cpp:434] ReLU8 <- Convolution10
I0928 20:43:00.127317  8576 net.cpp:395] ReLU8 -> Convolution10 (in-place)
I0928 20:43:00.127317  8576 net.cpp:150] Setting up ReLU8
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 32965852
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Convolution11
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Convolution11
I0928 20:43:00.127317  8576 net.cpp:434] Convolution11 <- Convolution10
I0928 20:43:00.127317  8576 net.cpp:408] Convolution11 -> Convolution11
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Convolution11
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 33367260
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer BatchNorm9
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer BatchNorm9
I0928 20:43:00.127317  8576 net.cpp:434] BatchNorm9 <- Convolution11
I0928 20:43:00.127317  8576 net.cpp:395] BatchNorm9 -> Convolution11 (in-place)
I0928 20:43:00.127317  8576 net.cpp:150] Setting up BatchNorm9
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 33768668
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Scale9
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Scale9
I0928 20:43:00.127317  8576 net.cpp:434] Scale9 <- Convolution11
I0928 20:43:00.127317  8576 net.cpp:395] Scale9 -> Convolution11 (in-place)
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Scale9
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Scale9
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 34170076
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Pooling3
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Pooling3
I0928 20:43:00.127317  8576 net.cpp:434] Pooling3 <- Eltwise3_Eltwise3_0_split_1
I0928 20:43:00.127317  8576 net.cpp:408] Pooling3 -> Pooling3
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Pooling3
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 34370780
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer PadChannel1
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer PadChannel1
I0928 20:43:00.127317  8576 net.cpp:434] PadChannel1 <- Pooling3
I0928 20:43:00.127317  8576 net.cpp:408] PadChannel1 -> PadChannel1
I0928 20:43:00.127317  8576 net.cpp:150] Setting up PadChannel1
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 34772188
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Eltwise4
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Eltwise4
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise4 <- Convolution11
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise4 <- PadChannel1
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise4 -> Eltwise4
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Eltwise4
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 35173596
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Eltwise4_Eltwise4_0_split
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Eltwise4_Eltwise4_0_split
I0928 20:43:00.127317  8576 net.cpp:434] Eltwise4_Eltwise4_0_split <- Eltwise4
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I0928 20:43:00.127317  8576 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Eltwise4_Eltwise4_0_split
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 35976412
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer Convolution12
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer Convolution12
I0928 20:43:00.127317  8576 net.cpp:434] Convolution12 <- Eltwise4_Eltwise4_0_split_0
I0928 20:43:00.127317  8576 net.cpp:408] Convolution12 -> Convolution12
I0928 20:43:00.127317  8576 net.cpp:150] Setting up Convolution12
I0928 20:43:00.127317  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.127317  8576 net.cpp:165] Memory required for data: 36377820
I0928 20:43:00.127317  8576 layer_factory.cpp:58] Creating layer BatchNorm10
I0928 20:43:00.127317  8576 net.cpp:100] Creating Layer BatchNorm10
I0928 20:43:00.127317  8576 net.cpp:434] BatchNorm10 <- Convolution12
I0928 20:43:00.127317  8576 net.cpp:395] BatchNorm10 -> Convolution12 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up BatchNorm10
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 36779228
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale10
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Scale10
I0928 20:43:00.142917  8576 net.cpp:434] Scale10 <- Convolution12
I0928 20:43:00.142917  8576 net.cpp:395] Scale10 -> Convolution12 (in-place)
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale10
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Scale10
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 37180636
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer ReLU9
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer ReLU9
I0928 20:43:00.142917  8576 net.cpp:434] ReLU9 <- Convolution12
I0928 20:43:00.142917  8576 net.cpp:395] ReLU9 -> Convolution12 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up ReLU9
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 37582044
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Convolution13
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Convolution13
I0928 20:43:00.142917  8576 net.cpp:434] Convolution13 <- Convolution12
I0928 20:43:00.142917  8576 net.cpp:408] Convolution13 -> Convolution13
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Convolution13
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 37983452
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer BatchNorm11
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer BatchNorm11
I0928 20:43:00.142917  8576 net.cpp:434] BatchNorm11 <- Convolution13
I0928 20:43:00.142917  8576 net.cpp:395] BatchNorm11 -> Convolution13 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up BatchNorm11
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 38384860
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale11
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Scale11
I0928 20:43:00.142917  8576 net.cpp:434] Scale11 <- Convolution13
I0928 20:43:00.142917  8576 net.cpp:395] Scale11 -> Convolution13 (in-place)
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale11
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Scale11
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 38786268
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Eltwise5
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Eltwise5
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise5 <- Eltwise4_Eltwise4_0_split_1
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise5 <- Convolution13
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise5 -> Eltwise5
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Eltwise5
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 39187676
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Eltwise5_Eltwise5_0_split
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Eltwise5_Eltwise5_0_split
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise5_Eltwise5_0_split <- Eltwise5
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_0
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_1
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Eltwise5_Eltwise5_0_split
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 39990492
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Convolution14
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Convolution14
I0928 20:43:00.142917  8576 net.cpp:434] Convolution14 <- Eltwise5_Eltwise5_0_split_0
I0928 20:43:00.142917  8576 net.cpp:408] Convolution14 -> Convolution14
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Convolution14
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 40391900
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer BatchNorm12
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer BatchNorm12
I0928 20:43:00.142917  8576 net.cpp:434] BatchNorm12 <- Convolution14
I0928 20:43:00.142917  8576 net.cpp:395] BatchNorm12 -> Convolution14 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up BatchNorm12
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 40793308
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale12
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Scale12
I0928 20:43:00.142917  8576 net.cpp:434] Scale12 <- Convolution14
I0928 20:43:00.142917  8576 net.cpp:395] Scale12 -> Convolution14 (in-place)
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale12
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Scale12
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 41194716
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer ReLU10
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer ReLU10
I0928 20:43:00.142917  8576 net.cpp:434] ReLU10 <- Convolution14
I0928 20:43:00.142917  8576 net.cpp:395] ReLU10 -> Convolution14 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up ReLU10
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 41596124
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Convolution15
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Convolution15
I0928 20:43:00.142917  8576 net.cpp:434] Convolution15 <- Convolution14
I0928 20:43:00.142917  8576 net.cpp:408] Convolution15 -> Convolution15
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Convolution15
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 41997532
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer BatchNorm13
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer BatchNorm13
I0928 20:43:00.142917  8576 net.cpp:434] BatchNorm13 <- Convolution15
I0928 20:43:00.142917  8576 net.cpp:395] BatchNorm13 -> Convolution15 (in-place)
I0928 20:43:00.142917  8576 net.cpp:150] Setting up BatchNorm13
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 42398940
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale13
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Scale13
I0928 20:43:00.142917  8576 net.cpp:434] Scale13 <- Convolution15
I0928 20:43:00.142917  8576 net.cpp:395] Scale13 -> Convolution15 (in-place)
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Scale13
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Scale13
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 42800348
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Eltwise6
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Eltwise6
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise6 <- Eltwise5_Eltwise5_0_split_1
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise6 <- Convolution15
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise6 -> Eltwise6
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Eltwise6
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 43201756
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Eltwise6_Eltwise6_0_split
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Eltwise6_Eltwise6_0_split
I0928 20:43:00.142917  8576 net.cpp:434] Eltwise6_Eltwise6_0_split <- Eltwise6
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_0
I0928 20:43:00.142917  8576 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_1
I0928 20:43:00.142917  8576 net.cpp:150] Setting up Eltwise6_Eltwise6_0_split
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.142917  8576 net.cpp:165] Memory required for data: 44004572
I0928 20:43:00.142917  8576 layer_factory.cpp:58] Creating layer Convolution16
I0928 20:43:00.142917  8576 net.cpp:100] Creating Layer Convolution16
I0928 20:43:00.142917  8576 net.cpp:434] Convolution16 <- Eltwise6_Eltwise6_0_split_0
I0928 20:43:00.142917  8576 net.cpp:408] Convolution16 -> Convolution16
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Convolution16
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 44205276
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer BatchNorm14
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer BatchNorm14
I0928 20:43:00.158517  8576 net.cpp:434] BatchNorm14 <- Convolution16
I0928 20:43:00.158517  8576 net.cpp:395] BatchNorm14 -> Convolution16 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up BatchNorm14
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 44405980
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale14
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Scale14
I0928 20:43:00.158517  8576 net.cpp:434] Scale14 <- Convolution16
I0928 20:43:00.158517  8576 net.cpp:395] Scale14 -> Convolution16 (in-place)
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale14
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Scale14
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 44606684
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer ReLU11
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer ReLU11
I0928 20:43:00.158517  8576 net.cpp:434] ReLU11 <- Convolution16
I0928 20:43:00.158517  8576 net.cpp:395] ReLU11 -> Convolution16 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up ReLU11
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 44807388
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Convolution17
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Convolution17
I0928 20:43:00.158517  8576 net.cpp:434] Convolution17 <- Convolution16
I0928 20:43:00.158517  8576 net.cpp:408] Convolution17 -> Convolution17
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Convolution17
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45008092
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer BatchNorm15
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer BatchNorm15
I0928 20:43:00.158517  8576 net.cpp:434] BatchNorm15 <- Convolution17
I0928 20:43:00.158517  8576 net.cpp:395] BatchNorm15 -> Convolution17 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up BatchNorm15
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45208796
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale15
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Scale15
I0928 20:43:00.158517  8576 net.cpp:434] Scale15 <- Convolution17
I0928 20:43:00.158517  8576 net.cpp:395] Scale15 -> Convolution17 (in-place)
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale15
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Scale15
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45409500
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Pooling4
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Pooling4
I0928 20:43:00.158517  8576 net.cpp:434] Pooling4 <- Eltwise6_Eltwise6_0_split_1
I0928 20:43:00.158517  8576 net.cpp:408] Pooling4 -> Pooling4
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Pooling4
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 32 28 28 (25088)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45509852
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer PadChannel2
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer PadChannel2
I0928 20:43:00.158517  8576 net.cpp:434] PadChannel2 <- Pooling4
I0928 20:43:00.158517  8576 net.cpp:408] PadChannel2 -> PadChannel2
I0928 20:43:00.158517  8576 net.cpp:150] Setting up PadChannel2
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45710556
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Eltwise7
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Eltwise7
I0928 20:43:00.158517  8576 net.cpp:434] Eltwise7 <- Convolution17
I0928 20:43:00.158517  8576 net.cpp:434] Eltwise7 <- PadChannel2
I0928 20:43:00.158517  8576 net.cpp:408] Eltwise7 -> Eltwise7
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Eltwise7
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 45911260
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Eltwise7_Eltwise7_0_split
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Eltwise7_Eltwise7_0_split
I0928 20:43:00.158517  8576 net.cpp:434] Eltwise7_Eltwise7_0_split <- Eltwise7
I0928 20:43:00.158517  8576 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_0
I0928 20:43:00.158517  8576 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_1
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Eltwise7_Eltwise7_0_split
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 46312668
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Convolution18
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Convolution18
I0928 20:43:00.158517  8576 net.cpp:434] Convolution18 <- Eltwise7_Eltwise7_0_split_0
I0928 20:43:00.158517  8576 net.cpp:408] Convolution18 -> Convolution18
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Convolution18
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 46513372
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer BatchNorm16
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer BatchNorm16
I0928 20:43:00.158517  8576 net.cpp:434] BatchNorm16 <- Convolution18
I0928 20:43:00.158517  8576 net.cpp:395] BatchNorm16 -> Convolution18 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up BatchNorm16
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 46714076
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale16
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Scale16
I0928 20:43:00.158517  8576 net.cpp:434] Scale16 <- Convolution18
I0928 20:43:00.158517  8576 net.cpp:395] Scale16 -> Convolution18 (in-place)
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale16
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Scale16
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 46914780
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer ReLU12
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer ReLU12
I0928 20:43:00.158517  8576 net.cpp:434] ReLU12 <- Convolution18
I0928 20:43:00.158517  8576 net.cpp:395] ReLU12 -> Convolution18 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up ReLU12
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 47115484
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Convolution19
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer Convolution19
I0928 20:43:00.158517  8576 net.cpp:434] Convolution19 <- Convolution18
I0928 20:43:00.158517  8576 net.cpp:408] Convolution19 -> Convolution19
I0928 20:43:00.158517  8576 net.cpp:150] Setting up Convolution19
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 47316188
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer BatchNorm17
I0928 20:43:00.158517  8576 net.cpp:100] Creating Layer BatchNorm17
I0928 20:43:00.158517  8576 net.cpp:434] BatchNorm17 <- Convolution19
I0928 20:43:00.158517  8576 net.cpp:395] BatchNorm17 -> Convolution19 (in-place)
I0928 20:43:00.158517  8576 net.cpp:150] Setting up BatchNorm17
I0928 20:43:00.158517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.158517  8576 net.cpp:165] Memory required for data: 47516892
I0928 20:43:00.158517  8576 layer_factory.cpp:58] Creating layer Scale17
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Scale17
I0928 20:43:00.174118  8576 net.cpp:434] Scale17 <- Convolution19
I0928 20:43:00.174118  8576 net.cpp:395] Scale17 -> Convolution19 (in-place)
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Scale17
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Scale17
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 47717596
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Eltwise8
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Eltwise8
I0928 20:43:00.174118  8576 net.cpp:434] Eltwise8 <- Eltwise7_Eltwise7_0_split_1
I0928 20:43:00.174118  8576 net.cpp:434] Eltwise8 <- Convolution19
I0928 20:43:00.174118  8576 net.cpp:408] Eltwise8 -> Eltwise8
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Eltwise8
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 47918300
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Eltwise8_Eltwise8_0_split
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Eltwise8_Eltwise8_0_split
I0928 20:43:00.174118  8576 net.cpp:434] Eltwise8_Eltwise8_0_split <- Eltwise8
I0928 20:43:00.174118  8576 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I0928 20:43:00.174118  8576 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Eltwise8_Eltwise8_0_split
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 48319708
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Convolution20
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Convolution20
I0928 20:43:00.174118  8576 net.cpp:434] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I0928 20:43:00.174118  8576 net.cpp:408] Convolution20 -> Convolution20
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Convolution20
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 48520412
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer BatchNorm18
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer BatchNorm18
I0928 20:43:00.174118  8576 net.cpp:434] BatchNorm18 <- Convolution20
I0928 20:43:00.174118  8576 net.cpp:395] BatchNorm18 -> Convolution20 (in-place)
I0928 20:43:00.174118  8576 net.cpp:150] Setting up BatchNorm18
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 48721116
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Scale18
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Scale18
I0928 20:43:00.174118  8576 net.cpp:434] Scale18 <- Convolution20
I0928 20:43:00.174118  8576 net.cpp:395] Scale18 -> Convolution20 (in-place)
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Scale18
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Scale18
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 48921820
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer ReLU13
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer ReLU13
I0928 20:43:00.174118  8576 net.cpp:434] ReLU13 <- Convolution20
I0928 20:43:00.174118  8576 net.cpp:395] ReLU13 -> Convolution20 (in-place)
I0928 20:43:00.174118  8576 net.cpp:150] Setting up ReLU13
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49122524
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Convolution21
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Convolution21
I0928 20:43:00.174118  8576 net.cpp:434] Convolution21 <- Convolution20
I0928 20:43:00.174118  8576 net.cpp:408] Convolution21 -> Convolution21
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Convolution21
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49323228
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer BatchNorm19
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer BatchNorm19
I0928 20:43:00.174118  8576 net.cpp:434] BatchNorm19 <- Convolution21
I0928 20:43:00.174118  8576 net.cpp:395] BatchNorm19 -> Convolution21 (in-place)
I0928 20:43:00.174118  8576 net.cpp:150] Setting up BatchNorm19
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49523932
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Scale19
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Scale19
I0928 20:43:00.174118  8576 net.cpp:434] Scale19 <- Convolution21
I0928 20:43:00.174118  8576 net.cpp:395] Scale19 -> Convolution21 (in-place)
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Scale19
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Scale19
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49724636
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Eltwise9
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Eltwise9
I0928 20:43:00.174118  8576 net.cpp:434] Eltwise9 <- Eltwise8_Eltwise8_0_split_1
I0928 20:43:00.174118  8576 net.cpp:434] Eltwise9 <- Convolution21
I0928 20:43:00.174118  8576 net.cpp:408] Eltwise9 -> Eltwise9
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Eltwise9
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49925340
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer Pooling5
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer Pooling5
I0928 20:43:00.174118  8576 net.cpp:434] Pooling5 <- Eltwise9
I0928 20:43:00.174118  8576 net.cpp:408] Pooling5 -> Pooling5
I0928 20:43:00.174118  8576 net.cpp:150] Setting up Pooling5
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 64 1 1 (64)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49925596
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer InnerProduct4
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer InnerProduct4
I0928 20:43:00.174118  8576 net.cpp:434] InnerProduct4 <- Pooling5
I0928 20:43:00.174118  8576 net.cpp:408] InnerProduct4 -> InnerProduct4
I0928 20:43:00.174118  8576 net.cpp:150] Setting up InnerProduct4
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: 1 2 (2)
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49925604
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:43:00.174118  8576 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0928 20:43:00.174118  8576 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct4
I0928 20:43:00.174118  8576 net.cpp:434] SoftmaxWithLoss1 <- ImageData2
I0928 20:43:00.174118  8576 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 20:43:00.174118  8576 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:43:00.174118  8576 net.cpp:150] Setting up SoftmaxWithLoss1
I0928 20:43:00.174118  8576 net.cpp:157] Top shape: (1)
I0928 20:43:00.174118  8576 net.cpp:160]     with loss weight 1
I0928 20:43:00.174118  8576 net.cpp:165] Memory required for data: 49925608
I0928 20:43:00.174118  8576 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] InnerProduct4 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Pooling5 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise9 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale19 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm19 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution21 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] ReLU13 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale18 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm18 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution20 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise8_Eltwise8_0_split needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise8 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale17 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm17 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution19 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] ReLU12 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale16 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm16 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution18 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise7_Eltwise7_0_split needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise7 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] PadChannel2 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Pooling4 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale15 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm15 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution17 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] ReLU11 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Scale14 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] BatchNorm14 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Convolution16 needs backward computation.
I0928 20:43:00.174118  8576 net.cpp:226] Eltwise6_Eltwise6_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise6 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale13 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm13 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution15 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU10 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale12 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm12 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution14 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise5_Eltwise5_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise5 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale11 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm11 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution13 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU9 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale10 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm10 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution12 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise4_Eltwise4_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise4 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] PadChannel1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Pooling3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale9 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm9 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution11 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU8 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale8 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm8 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution10 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise3_Eltwise3_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale7 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm7 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution9 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU7 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale6 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm6 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution8 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise2_Eltwise2_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale5 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm5 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution7 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU6 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale4 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm4 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution6 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise1_Eltwise1_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Eltwise1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution5 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU5 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution4 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution3_ReLU4_0_split needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU4 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Scale1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] BatchNorm1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Transformer1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] InnerProduct3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] InnerProduct2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU3 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] InnerProduct1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Pooling2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution2 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Pooling1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] ReLU1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:226] Convolution1 needs backward computation.
I0928 20:43:00.189718  8576 net.cpp:228] ImageData1_ImageData1_0_split does not need backward computation.
I0928 20:43:00.189718  8576 net.cpp:228] ImageData1 does not need backward computation.
I0928 20:43:00.189718  8576 net.cpp:270] This network produces output SoftmaxWithLoss1
I0928 20:43:00.189718  8576 net.cpp:283] Network initialization done.
I0928 20:43:00.189718  8576 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet_20_train_test_STN.prototxt
I0928 20:43:00.189718  8576 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0928 20:43:00.189718  8576 solver.cpp:181] Creating test net (#0) specified by net file: resnet_20_train_test_STN.prototxt
I0928 20:43:00.189718  8576 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer ImageData1
I0928 20:43:00.189718  8576 net.cpp:58] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "ImageData1"
  type: "ImageData"
  top: "ImageData1"
  top: "ImageData2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    crop_size: 112
    mean_value: 128
  }
  image_data_param {
    source: "image_list.txt"
    batch_size: 1
    shuffle: true
    new_height: 0
    new_width: 0
    is_color: false
    root_folder: ""
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "ImageData1"
  top: "Convolution1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling2"
  top: "InnerProduct1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "InnerProduct2"
  top: "InnerProduct3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 6
    weight_filler {
      type: "gaussian"
      value: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Transformer1"
  type: "Transformer"
  bottom: "ImageData1"
  bottom: "InnerProduct3"
  top: "Transformer1"
  transformer_param {
    num_theta: 6
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Transformer1"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution5"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution7"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution9"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise3"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel1"
  type: "PadChannel"
  bottom: "Pooling3"
  top: "PadChannel1"
  pad_channel_param {
    num_channels_to_pad: 16
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "PadChannel1"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution15"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Eltwise6"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "PadChannel2"
  type: "PadChannel"
  bottom: "Pooling4"
  top: "PadChannel2"
  pad_channel_param {
    num_channels_to_pad: 32
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "PadChannel2"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Pooling5"
  top: "InnerProduct4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct4"
  bottom: "ImageData2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer ImageData1
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer ImageData1
I0928 20:43:00.252117  8576 net.cpp:408] ImageData1 -> ImageData1
I0928 20:43:00.252117  8576 net.cpp:408] ImageData1 -> ImageData2
I0928 20:43:00.252117  8576 image_data_layer.cpp:38] Opening file image_list.txt
I0928 20:43:00.252117  8576 image_data_layer.cpp:53] Shuffling data
I0928 20:43:00.252117  8576 image_data_layer.cpp:58] A total of 1 images.
I0928 20:43:00.252117  8576 image_data_layer.cpp:85] output data size: 1,1,112,112
I0928 20:43:00.252117  8576 net.cpp:150] Setting up ImageData1
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 (1)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 50180
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer ImageData1_ImageData1_0_split
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer ImageData1_ImageData1_0_split
I0928 20:43:00.252117  8576 net.cpp:434] ImageData1_ImageData1_0_split <- ImageData1
I0928 20:43:00.252117  8576 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_0
I0928 20:43:00.252117  8576 net.cpp:408] ImageData1_ImageData1_0_split -> ImageData1_ImageData1_0_split_1
I0928 20:43:00.252117  8576 net.cpp:150] Setting up ImageData1_ImageData1_0_split
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 150532
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer ImageData2_ImageData1_1_split
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer ImageData2_ImageData1_1_split
I0928 20:43:00.252117  8576 net.cpp:434] ImageData2_ImageData1_1_split <- ImageData2
I0928 20:43:00.252117  8576 net.cpp:408] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_0
I0928 20:43:00.252117  8576 net.cpp:408] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_1
I0928 20:43:00.252117  8576 net.cpp:150] Setting up ImageData2_ImageData1_1_split
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 (1)
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 (1)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 150540
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer Convolution1
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer Convolution1
I0928 20:43:00.252117  8576 net.cpp:434] Convolution1 <- ImageData1_ImageData1_0_split_0
I0928 20:43:00.252117  8576 net.cpp:408] Convolution1 -> Convolution1
I0928 20:43:00.252117  8576 net.cpp:150] Setting up Convolution1
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 953356
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer ReLU1
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer ReLU1
I0928 20:43:00.252117  8576 net.cpp:434] ReLU1 <- Convolution1
I0928 20:43:00.252117  8576 net.cpp:395] ReLU1 -> Convolution1 (in-place)
I0928 20:43:00.252117  8576 net.cpp:150] Setting up ReLU1
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 1756172
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer Pooling1
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer Pooling1
I0928 20:43:00.252117  8576 net.cpp:434] Pooling1 <- Convolution1
I0928 20:43:00.252117  8576 net.cpp:408] Pooling1 -> Pooling1
I0928 20:43:00.252117  8576 net.cpp:150] Setting up Pooling1
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 1956876
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer Convolution2
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer Convolution2
I0928 20:43:00.252117  8576 net.cpp:434] Convolution2 <- Pooling1
I0928 20:43:00.252117  8576 net.cpp:408] Convolution2 -> Convolution2
I0928 20:43:00.252117  8576 net.cpp:150] Setting up Convolution2
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 2157580
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer ReLU2
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer ReLU2
I0928 20:43:00.252117  8576 net.cpp:434] ReLU2 <- Convolution2
I0928 20:43:00.252117  8576 net.cpp:395] ReLU2 -> Convolution2 (in-place)
I0928 20:43:00.252117  8576 net.cpp:150] Setting up ReLU2
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 2358284
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer Pooling2
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer Pooling2
I0928 20:43:00.252117  8576 net.cpp:434] Pooling2 <- Convolution2
I0928 20:43:00.252117  8576 net.cpp:408] Pooling2 -> Pooling2
I0928 20:43:00.252117  8576 net.cpp:150] Setting up Pooling2
I0928 20:43:00.252117  8576 net.cpp:157] Top shape: 1 16 28 28 (12544)
I0928 20:43:00.252117  8576 net.cpp:165] Memory required for data: 2408460
I0928 20:43:00.252117  8576 layer_factory.cpp:58] Creating layer InnerProduct1
I0928 20:43:00.252117  8576 net.cpp:100] Creating Layer InnerProduct1
I0928 20:43:00.252117  8576 net.cpp:434] InnerProduct1 <- Pooling2
I0928 20:43:00.252117  8576 net.cpp:408] InnerProduct1 -> InnerProduct1
I0928 20:43:00.252117  8576 net.cpp:150] Setting up InnerProduct1
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 2408524
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer ReLU3
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer ReLU3
I0928 20:43:00.267717  8576 net.cpp:434] ReLU3 <- InnerProduct1
I0928 20:43:00.267717  8576 net.cpp:395] ReLU3 -> InnerProduct1 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up ReLU3
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 2408588
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer InnerProduct2
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer InnerProduct2
I0928 20:43:00.267717  8576 net.cpp:434] InnerProduct2 <- InnerProduct1
I0928 20:43:00.267717  8576 net.cpp:408] InnerProduct2 -> InnerProduct2
I0928 20:43:00.267717  8576 net.cpp:150] Setting up InnerProduct2
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 (16)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 2408652
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer InnerProduct3
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer InnerProduct3
I0928 20:43:00.267717  8576 net.cpp:434] InnerProduct3 <- InnerProduct2
I0928 20:43:00.267717  8576 net.cpp:408] InnerProduct3 -> InnerProduct3
I0928 20:43:00.267717  8576 net.cpp:150] Setting up InnerProduct3
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 6 (6)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 2408676
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Transformer1
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Transformer1
I0928 20:43:00.267717  8576 net.cpp:434] Transformer1 <- ImageData1_ImageData1_0_split_1
I0928 20:43:00.267717  8576 net.cpp:434] Transformer1 <- InnerProduct3
I0928 20:43:00.267717  8576 net.cpp:408] Transformer1 -> Transformer1
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Transformer1
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 1 112 112 (12544)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 2458852
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Convolution3
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Convolution3
I0928 20:43:00.267717  8576 net.cpp:434] Convolution3 <- Transformer1
I0928 20:43:00.267717  8576 net.cpp:408] Convolution3 -> Convolution3
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Convolution3
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 3261668
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer BatchNorm1
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer BatchNorm1
I0928 20:43:00.267717  8576 net.cpp:434] BatchNorm1 <- Convolution3
I0928 20:43:00.267717  8576 net.cpp:395] BatchNorm1 -> Convolution3 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up BatchNorm1
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 4064484
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale1
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Scale1
I0928 20:43:00.267717  8576 net.cpp:434] Scale1 <- Convolution3
I0928 20:43:00.267717  8576 net.cpp:395] Scale1 -> Convolution3 (in-place)
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale1
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Scale1
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 4867300
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer ReLU4
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer ReLU4
I0928 20:43:00.267717  8576 net.cpp:434] ReLU4 <- Convolution3
I0928 20:43:00.267717  8576 net.cpp:395] ReLU4 -> Convolution3 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up ReLU4
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 5670116
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Convolution3_ReLU4_0_split
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Convolution3_ReLU4_0_split
I0928 20:43:00.267717  8576 net.cpp:434] Convolution3_ReLU4_0_split <- Convolution3
I0928 20:43:00.267717  8576 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_0
I0928 20:43:00.267717  8576 net.cpp:408] Convolution3_ReLU4_0_split -> Convolution3_ReLU4_0_split_1
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Convolution3_ReLU4_0_split
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 7275748
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Convolution4
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Convolution4
I0928 20:43:00.267717  8576 net.cpp:434] Convolution4 <- Convolution3_ReLU4_0_split_0
I0928 20:43:00.267717  8576 net.cpp:408] Convolution4 -> Convolution4
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Convolution4
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 8078564
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer BatchNorm2
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer BatchNorm2
I0928 20:43:00.267717  8576 net.cpp:434] BatchNorm2 <- Convolution4
I0928 20:43:00.267717  8576 net.cpp:395] BatchNorm2 -> Convolution4 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up BatchNorm2
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 8881380
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale2
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Scale2
I0928 20:43:00.267717  8576 net.cpp:434] Scale2 <- Convolution4
I0928 20:43:00.267717  8576 net.cpp:395] Scale2 -> Convolution4 (in-place)
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale2
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Scale2
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 9684196
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer ReLU5
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer ReLU5
I0928 20:43:00.267717  8576 net.cpp:434] ReLU5 <- Convolution4
I0928 20:43:00.267717  8576 net.cpp:395] ReLU5 -> Convolution4 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up ReLU5
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 10487012
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Convolution5
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Convolution5
I0928 20:43:00.267717  8576 net.cpp:434] Convolution5 <- Convolution4
I0928 20:43:00.267717  8576 net.cpp:408] Convolution5 -> Convolution5
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Convolution5
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 11289828
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer BatchNorm3
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer BatchNorm3
I0928 20:43:00.267717  8576 net.cpp:434] BatchNorm3 <- Convolution5
I0928 20:43:00.267717  8576 net.cpp:395] BatchNorm3 -> Convolution5 (in-place)
I0928 20:43:00.267717  8576 net.cpp:150] Setting up BatchNorm3
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 12092644
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale3
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Scale3
I0928 20:43:00.267717  8576 net.cpp:434] Scale3 <- Convolution5
I0928 20:43:00.267717  8576 net.cpp:395] Scale3 -> Convolution5 (in-place)
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Scale3
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Scale3
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 12895460
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Eltwise1
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Eltwise1
I0928 20:43:00.267717  8576 net.cpp:434] Eltwise1 <- Convolution3_ReLU4_0_split_1
I0928 20:43:00.267717  8576 net.cpp:434] Eltwise1 <- Convolution5
I0928 20:43:00.267717  8576 net.cpp:408] Eltwise1 -> Eltwise1
I0928 20:43:00.267717  8576 net.cpp:150] Setting up Eltwise1
I0928 20:43:00.267717  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.267717  8576 net.cpp:165] Memory required for data: 13698276
I0928 20:43:00.267717  8576 layer_factory.cpp:58] Creating layer Eltwise1_Eltwise1_0_split
I0928 20:43:00.267717  8576 net.cpp:100] Creating Layer Eltwise1_Eltwise1_0_split
I0928 20:43:00.267717  8576 net.cpp:434] Eltwise1_Eltwise1_0_split <- Eltwise1
I0928 20:43:00.267717  8576 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_0
I0928 20:43:00.267717  8576 net.cpp:408] Eltwise1_Eltwise1_0_split -> Eltwise1_Eltwise1_0_split_1
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Eltwise1_Eltwise1_0_split
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 15303908
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Convolution6
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Convolution6
I0928 20:43:00.283318  8576 net.cpp:434] Convolution6 <- Eltwise1_Eltwise1_0_split_0
I0928 20:43:00.283318  8576 net.cpp:408] Convolution6 -> Convolution6
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Convolution6
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 16106724
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer BatchNorm4
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer BatchNorm4
I0928 20:43:00.283318  8576 net.cpp:434] BatchNorm4 <- Convolution6
I0928 20:43:00.283318  8576 net.cpp:395] BatchNorm4 -> Convolution6 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up BatchNorm4
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 16909540
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale4
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Scale4
I0928 20:43:00.283318  8576 net.cpp:434] Scale4 <- Convolution6
I0928 20:43:00.283318  8576 net.cpp:395] Scale4 -> Convolution6 (in-place)
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale4
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Scale4
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 17712356
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer ReLU6
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer ReLU6
I0928 20:43:00.283318  8576 net.cpp:434] ReLU6 <- Convolution6
I0928 20:43:00.283318  8576 net.cpp:395] ReLU6 -> Convolution6 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up ReLU6
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 18515172
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Convolution7
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Convolution7
I0928 20:43:00.283318  8576 net.cpp:434] Convolution7 <- Convolution6
I0928 20:43:00.283318  8576 net.cpp:408] Convolution7 -> Convolution7
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Convolution7
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 19317988
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer BatchNorm5
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer BatchNorm5
I0928 20:43:00.283318  8576 net.cpp:434] BatchNorm5 <- Convolution7
I0928 20:43:00.283318  8576 net.cpp:395] BatchNorm5 -> Convolution7 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up BatchNorm5
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 20120804
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale5
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Scale5
I0928 20:43:00.283318  8576 net.cpp:434] Scale5 <- Convolution7
I0928 20:43:00.283318  8576 net.cpp:395] Scale5 -> Convolution7 (in-place)
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale5
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Scale5
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 20923620
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Eltwise2
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Eltwise2
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise2 <- Eltwise1_Eltwise1_0_split_1
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise2 <- Convolution7
I0928 20:43:00.283318  8576 net.cpp:408] Eltwise2 -> Eltwise2
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Eltwise2
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 21726436
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Eltwise2_Eltwise2_0_split
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Eltwise2_Eltwise2_0_split
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise2_Eltwise2_0_split <- Eltwise2
I0928 20:43:00.283318  8576 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_0
I0928 20:43:00.283318  8576 net.cpp:408] Eltwise2_Eltwise2_0_split -> Eltwise2_Eltwise2_0_split_1
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Eltwise2_Eltwise2_0_split
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 23332068
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Convolution8
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Convolution8
I0928 20:43:00.283318  8576 net.cpp:434] Convolution8 <- Eltwise2_Eltwise2_0_split_0
I0928 20:43:00.283318  8576 net.cpp:408] Convolution8 -> Convolution8
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Convolution8
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 24134884
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer BatchNorm6
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer BatchNorm6
I0928 20:43:00.283318  8576 net.cpp:434] BatchNorm6 <- Convolution8
I0928 20:43:00.283318  8576 net.cpp:395] BatchNorm6 -> Convolution8 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up BatchNorm6
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 24937700
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale6
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Scale6
I0928 20:43:00.283318  8576 net.cpp:434] Scale6 <- Convolution8
I0928 20:43:00.283318  8576 net.cpp:395] Scale6 -> Convolution8 (in-place)
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale6
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Scale6
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 25740516
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer ReLU7
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer ReLU7
I0928 20:43:00.283318  8576 net.cpp:434] ReLU7 <- Convolution8
I0928 20:43:00.283318  8576 net.cpp:395] ReLU7 -> Convolution8 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up ReLU7
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 26543332
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Convolution9
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Convolution9
I0928 20:43:00.283318  8576 net.cpp:434] Convolution9 <- Convolution8
I0928 20:43:00.283318  8576 net.cpp:408] Convolution9 -> Convolution9
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Convolution9
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 27346148
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer BatchNorm7
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer BatchNorm7
I0928 20:43:00.283318  8576 net.cpp:434] BatchNorm7 <- Convolution9
I0928 20:43:00.283318  8576 net.cpp:395] BatchNorm7 -> Convolution9 (in-place)
I0928 20:43:00.283318  8576 net.cpp:150] Setting up BatchNorm7
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 28148964
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale7
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Scale7
I0928 20:43:00.283318  8576 net.cpp:434] Scale7 <- Convolution9
I0928 20:43:00.283318  8576 net.cpp:395] Scale7 -> Convolution9 (in-place)
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Scale7
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Scale7
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 28951780
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Eltwise3
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Eltwise3
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise3 <- Eltwise2_Eltwise2_0_split_1
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise3 <- Convolution9
I0928 20:43:00.283318  8576 net.cpp:408] Eltwise3 -> Eltwise3
I0928 20:43:00.283318  8576 net.cpp:150] Setting up Eltwise3
I0928 20:43:00.283318  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.283318  8576 net.cpp:165] Memory required for data: 29754596
I0928 20:43:00.283318  8576 layer_factory.cpp:58] Creating layer Eltwise3_Eltwise3_0_split
I0928 20:43:00.283318  8576 net.cpp:100] Creating Layer Eltwise3_Eltwise3_0_split
I0928 20:43:00.283318  8576 net.cpp:434] Eltwise3_Eltwise3_0_split <- Eltwise3
I0928 20:43:00.298918  8576 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_0
I0928 20:43:00.298918  8576 net.cpp:408] Eltwise3_Eltwise3_0_split -> Eltwise3_Eltwise3_0_split_1
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Eltwise3_Eltwise3_0_split
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 16 112 112 (200704)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 31360228
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Convolution10
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Convolution10
I0928 20:43:00.298918  8576 net.cpp:434] Convolution10 <- Eltwise3_Eltwise3_0_split_0
I0928 20:43:00.298918  8576 net.cpp:408] Convolution10 -> Convolution10
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Convolution10
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 31761636
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer BatchNorm8
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer BatchNorm8
I0928 20:43:00.298918  8576 net.cpp:434] BatchNorm8 <- Convolution10
I0928 20:43:00.298918  8576 net.cpp:395] BatchNorm8 -> Convolution10 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up BatchNorm8
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 32163044
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale8
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Scale8
I0928 20:43:00.298918  8576 net.cpp:434] Scale8 <- Convolution10
I0928 20:43:00.298918  8576 net.cpp:395] Scale8 -> Convolution10 (in-place)
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale8
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Scale8
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 32564452
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer ReLU8
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer ReLU8
I0928 20:43:00.298918  8576 net.cpp:434] ReLU8 <- Convolution10
I0928 20:43:00.298918  8576 net.cpp:395] ReLU8 -> Convolution10 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up ReLU8
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 32965860
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Convolution11
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Convolution11
I0928 20:43:00.298918  8576 net.cpp:434] Convolution11 <- Convolution10
I0928 20:43:00.298918  8576 net.cpp:408] Convolution11 -> Convolution11
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Convolution11
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 33367268
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer BatchNorm9
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer BatchNorm9
I0928 20:43:00.298918  8576 net.cpp:434] BatchNorm9 <- Convolution11
I0928 20:43:00.298918  8576 net.cpp:395] BatchNorm9 -> Convolution11 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up BatchNorm9
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 33768676
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale9
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Scale9
I0928 20:43:00.298918  8576 net.cpp:434] Scale9 <- Convolution11
I0928 20:43:00.298918  8576 net.cpp:395] Scale9 -> Convolution11 (in-place)
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale9
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Scale9
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 34170084
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Pooling3
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Pooling3
I0928 20:43:00.298918  8576 net.cpp:434] Pooling3 <- Eltwise3_Eltwise3_0_split_1
I0928 20:43:00.298918  8576 net.cpp:408] Pooling3 -> Pooling3
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Pooling3
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 16 56 56 (50176)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 34370788
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer PadChannel1
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer PadChannel1
I0928 20:43:00.298918  8576 net.cpp:434] PadChannel1 <- Pooling3
I0928 20:43:00.298918  8576 net.cpp:408] PadChannel1 -> PadChannel1
I0928 20:43:00.298918  8576 net.cpp:150] Setting up PadChannel1
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 34772196
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Eltwise4
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Eltwise4
I0928 20:43:00.298918  8576 net.cpp:434] Eltwise4 <- Convolution11
I0928 20:43:00.298918  8576 net.cpp:434] Eltwise4 <- PadChannel1
I0928 20:43:00.298918  8576 net.cpp:408] Eltwise4 -> Eltwise4
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Eltwise4
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 35173604
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Eltwise4_Eltwise4_0_split
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Eltwise4_Eltwise4_0_split
I0928 20:43:00.298918  8576 net.cpp:434] Eltwise4_Eltwise4_0_split <- Eltwise4
I0928 20:43:00.298918  8576 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I0928 20:43:00.298918  8576 net.cpp:408] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Eltwise4_Eltwise4_0_split
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 35976420
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Convolution12
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Convolution12
I0928 20:43:00.298918  8576 net.cpp:434] Convolution12 <- Eltwise4_Eltwise4_0_split_0
I0928 20:43:00.298918  8576 net.cpp:408] Convolution12 -> Convolution12
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Convolution12
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 36377828
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer BatchNorm10
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer BatchNorm10
I0928 20:43:00.298918  8576 net.cpp:434] BatchNorm10 <- Convolution12
I0928 20:43:00.298918  8576 net.cpp:395] BatchNorm10 -> Convolution12 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up BatchNorm10
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 36779236
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale10
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Scale10
I0928 20:43:00.298918  8576 net.cpp:434] Scale10 <- Convolution12
I0928 20:43:00.298918  8576 net.cpp:395] Scale10 -> Convolution12 (in-place)
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale10
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Scale10
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 37180644
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer ReLU9
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer ReLU9
I0928 20:43:00.298918  8576 net.cpp:434] ReLU9 <- Convolution12
I0928 20:43:00.298918  8576 net.cpp:395] ReLU9 -> Convolution12 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up ReLU9
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 37582052
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Convolution13
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Convolution13
I0928 20:43:00.298918  8576 net.cpp:434] Convolution13 <- Convolution12
I0928 20:43:00.298918  8576 net.cpp:408] Convolution13 -> Convolution13
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Convolution13
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 37983460
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer BatchNorm11
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer BatchNorm11
I0928 20:43:00.298918  8576 net.cpp:434] BatchNorm11 <- Convolution13
I0928 20:43:00.298918  8576 net.cpp:395] BatchNorm11 -> Convolution13 (in-place)
I0928 20:43:00.298918  8576 net.cpp:150] Setting up BatchNorm11
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 38384868
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale11
I0928 20:43:00.298918  8576 net.cpp:100] Creating Layer Scale11
I0928 20:43:00.298918  8576 net.cpp:434] Scale11 <- Convolution13
I0928 20:43:00.298918  8576 net.cpp:395] Scale11 -> Convolution13 (in-place)
I0928 20:43:00.298918  8576 layer_factory.cpp:58] Creating layer Scale11
I0928 20:43:00.298918  8576 net.cpp:150] Setting up Scale11
I0928 20:43:00.298918  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.298918  8576 net.cpp:165] Memory required for data: 38786276
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Eltwise5
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Eltwise5
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise5 <- Eltwise4_Eltwise4_0_split_1
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise5 <- Convolution13
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise5 -> Eltwise5
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Eltwise5
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 39187684
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Eltwise5_Eltwise5_0_split
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Eltwise5_Eltwise5_0_split
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise5_Eltwise5_0_split <- Eltwise5
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_0
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise5_Eltwise5_0_split -> Eltwise5_Eltwise5_0_split_1
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Eltwise5_Eltwise5_0_split
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 39990500
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Convolution14
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Convolution14
I0928 20:43:00.314517  8576 net.cpp:434] Convolution14 <- Eltwise5_Eltwise5_0_split_0
I0928 20:43:00.314517  8576 net.cpp:408] Convolution14 -> Convolution14
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Convolution14
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 40391908
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer BatchNorm12
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer BatchNorm12
I0928 20:43:00.314517  8576 net.cpp:434] BatchNorm12 <- Convolution14
I0928 20:43:00.314517  8576 net.cpp:395] BatchNorm12 -> Convolution14 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up BatchNorm12
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 40793316
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale12
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Scale12
I0928 20:43:00.314517  8576 net.cpp:434] Scale12 <- Convolution14
I0928 20:43:00.314517  8576 net.cpp:395] Scale12 -> Convolution14 (in-place)
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale12
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Scale12
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 41194724
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer ReLU10
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer ReLU10
I0928 20:43:00.314517  8576 net.cpp:434] ReLU10 <- Convolution14
I0928 20:43:00.314517  8576 net.cpp:395] ReLU10 -> Convolution14 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up ReLU10
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 41596132
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Convolution15
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Convolution15
I0928 20:43:00.314517  8576 net.cpp:434] Convolution15 <- Convolution14
I0928 20:43:00.314517  8576 net.cpp:408] Convolution15 -> Convolution15
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Convolution15
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 41997540
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer BatchNorm13
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer BatchNorm13
I0928 20:43:00.314517  8576 net.cpp:434] BatchNorm13 <- Convolution15
I0928 20:43:00.314517  8576 net.cpp:395] BatchNorm13 -> Convolution15 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up BatchNorm13
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 42398948
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale13
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Scale13
I0928 20:43:00.314517  8576 net.cpp:434] Scale13 <- Convolution15
I0928 20:43:00.314517  8576 net.cpp:395] Scale13 -> Convolution15 (in-place)
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale13
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Scale13
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 42800356
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Eltwise6
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Eltwise6
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise6 <- Eltwise5_Eltwise5_0_split_1
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise6 <- Convolution15
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise6 -> Eltwise6
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Eltwise6
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 43201764
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Eltwise6_Eltwise6_0_split
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Eltwise6_Eltwise6_0_split
I0928 20:43:00.314517  8576 net.cpp:434] Eltwise6_Eltwise6_0_split <- Eltwise6
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_0
I0928 20:43:00.314517  8576 net.cpp:408] Eltwise6_Eltwise6_0_split -> Eltwise6_Eltwise6_0_split_1
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Eltwise6_Eltwise6_0_split
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 32 56 56 (100352)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 44004580
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Convolution16
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Convolution16
I0928 20:43:00.314517  8576 net.cpp:434] Convolution16 <- Eltwise6_Eltwise6_0_split_0
I0928 20:43:00.314517  8576 net.cpp:408] Convolution16 -> Convolution16
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Convolution16
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 44205284
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer BatchNorm14
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer BatchNorm14
I0928 20:43:00.314517  8576 net.cpp:434] BatchNorm14 <- Convolution16
I0928 20:43:00.314517  8576 net.cpp:395] BatchNorm14 -> Convolution16 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up BatchNorm14
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 44405988
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale14
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Scale14
I0928 20:43:00.314517  8576 net.cpp:434] Scale14 <- Convolution16
I0928 20:43:00.314517  8576 net.cpp:395] Scale14 -> Convolution16 (in-place)
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale14
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Scale14
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 44606692
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer ReLU11
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer ReLU11
I0928 20:43:00.314517  8576 net.cpp:434] ReLU11 <- Convolution16
I0928 20:43:00.314517  8576 net.cpp:395] ReLU11 -> Convolution16 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up ReLU11
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 44807396
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Convolution17
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Convolution17
I0928 20:43:00.314517  8576 net.cpp:434] Convolution17 <- Convolution16
I0928 20:43:00.314517  8576 net.cpp:408] Convolution17 -> Convolution17
I0928 20:43:00.314517  8576 net.cpp:150] Setting up Convolution17
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 45008100
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer BatchNorm15
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer BatchNorm15
I0928 20:43:00.314517  8576 net.cpp:434] BatchNorm15 <- Convolution17
I0928 20:43:00.314517  8576 net.cpp:395] BatchNorm15 -> Convolution17 (in-place)
I0928 20:43:00.314517  8576 net.cpp:150] Setting up BatchNorm15
I0928 20:43:00.314517  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.314517  8576 net.cpp:165] Memory required for data: 45208804
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale15
I0928 20:43:00.314517  8576 net.cpp:100] Creating Layer Scale15
I0928 20:43:00.314517  8576 net.cpp:434] Scale15 <- Convolution17
I0928 20:43:00.314517  8576 net.cpp:395] Scale15 -> Convolution17 (in-place)
I0928 20:43:00.314517  8576 layer_factory.cpp:58] Creating layer Scale15
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Scale15
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 45409508
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Pooling4
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Pooling4
I0928 20:43:00.330117  8576 net.cpp:434] Pooling4 <- Eltwise6_Eltwise6_0_split_1
I0928 20:43:00.330117  8576 net.cpp:408] Pooling4 -> Pooling4
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Pooling4
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 32 28 28 (25088)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 45509860
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer PadChannel2
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer PadChannel2
I0928 20:43:00.330117  8576 net.cpp:434] PadChannel2 <- Pooling4
I0928 20:43:00.330117  8576 net.cpp:408] PadChannel2 -> PadChannel2
I0928 20:43:00.330117  8576 net.cpp:150] Setting up PadChannel2
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 45710564
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Eltwise7
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Eltwise7
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise7 <- Convolution17
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise7 <- PadChannel2
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise7 -> Eltwise7
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Eltwise7
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 45911268
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Eltwise7_Eltwise7_0_split
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Eltwise7_Eltwise7_0_split
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise7_Eltwise7_0_split <- Eltwise7
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_0
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise7_Eltwise7_0_split -> Eltwise7_Eltwise7_0_split_1
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Eltwise7_Eltwise7_0_split
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 46312676
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Convolution18
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Convolution18
I0928 20:43:00.330117  8576 net.cpp:434] Convolution18 <- Eltwise7_Eltwise7_0_split_0
I0928 20:43:00.330117  8576 net.cpp:408] Convolution18 -> Convolution18
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Convolution18
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 46513380
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer BatchNorm16
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer BatchNorm16
I0928 20:43:00.330117  8576 net.cpp:434] BatchNorm16 <- Convolution18
I0928 20:43:00.330117  8576 net.cpp:395] BatchNorm16 -> Convolution18 (in-place)
I0928 20:43:00.330117  8576 net.cpp:150] Setting up BatchNorm16
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 46714084
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale16
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Scale16
I0928 20:43:00.330117  8576 net.cpp:434] Scale16 <- Convolution18
I0928 20:43:00.330117  8576 net.cpp:395] Scale16 -> Convolution18 (in-place)
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale16
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Scale16
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 46914788
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer ReLU12
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer ReLU12
I0928 20:43:00.330117  8576 net.cpp:434] ReLU12 <- Convolution18
I0928 20:43:00.330117  8576 net.cpp:395] ReLU12 -> Convolution18 (in-place)
I0928 20:43:00.330117  8576 net.cpp:150] Setting up ReLU12
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 47115492
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Convolution19
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Convolution19
I0928 20:43:00.330117  8576 net.cpp:434] Convolution19 <- Convolution18
I0928 20:43:00.330117  8576 net.cpp:408] Convolution19 -> Convolution19
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Convolution19
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 47316196
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer BatchNorm17
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer BatchNorm17
I0928 20:43:00.330117  8576 net.cpp:434] BatchNorm17 <- Convolution19
I0928 20:43:00.330117  8576 net.cpp:395] BatchNorm17 -> Convolution19 (in-place)
I0928 20:43:00.330117  8576 net.cpp:150] Setting up BatchNorm17
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 47516900
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale17
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Scale17
I0928 20:43:00.330117  8576 net.cpp:434] Scale17 <- Convolution19
I0928 20:43:00.330117  8576 net.cpp:395] Scale17 -> Convolution19 (in-place)
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale17
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Scale17
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 47717604
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Eltwise8
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Eltwise8
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise8 <- Eltwise7_Eltwise7_0_split_1
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise8 <- Convolution19
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise8 -> Eltwise8
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Eltwise8
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 47918308
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Eltwise8_Eltwise8_0_split
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Eltwise8_Eltwise8_0_split
I0928 20:43:00.330117  8576 net.cpp:434] Eltwise8_Eltwise8_0_split <- Eltwise8
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I0928 20:43:00.330117  8576 net.cpp:408] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Eltwise8_Eltwise8_0_split
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 48319716
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Convolution20
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Convolution20
I0928 20:43:00.330117  8576 net.cpp:434] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I0928 20:43:00.330117  8576 net.cpp:408] Convolution20 -> Convolution20
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Convolution20
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 48520420
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer BatchNorm18
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer BatchNorm18
I0928 20:43:00.330117  8576 net.cpp:434] BatchNorm18 <- Convolution20
I0928 20:43:00.330117  8576 net.cpp:395] BatchNorm18 -> Convolution20 (in-place)
I0928 20:43:00.330117  8576 net.cpp:150] Setting up BatchNorm18
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 48721124
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale18
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Scale18
I0928 20:43:00.330117  8576 net.cpp:434] Scale18 <- Convolution20
I0928 20:43:00.330117  8576 net.cpp:395] Scale18 -> Convolution20 (in-place)
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Scale18
I0928 20:43:00.330117  8576 net.cpp:150] Setting up Scale18
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 48921828
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer ReLU13
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer ReLU13
I0928 20:43:00.330117  8576 net.cpp:434] ReLU13 <- Convolution20
I0928 20:43:00.330117  8576 net.cpp:395] ReLU13 -> Convolution20 (in-place)
I0928 20:43:00.330117  8576 net.cpp:150] Setting up ReLU13
I0928 20:43:00.330117  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.330117  8576 net.cpp:165] Memory required for data: 49122532
I0928 20:43:00.330117  8576 layer_factory.cpp:58] Creating layer Convolution21
I0928 20:43:00.330117  8576 net.cpp:100] Creating Layer Convolution21
I0928 20:43:00.330117  8576 net.cpp:434] Convolution21 <- Convolution20
I0928 20:43:00.330117  8576 net.cpp:408] Convolution21 -> Convolution21
I0928 20:43:00.345717  8576 net.cpp:150] Setting up Convolution21
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49323236
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer BatchNorm19
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer BatchNorm19
I0928 20:43:00.345717  8576 net.cpp:434] BatchNorm19 <- Convolution21
I0928 20:43:00.345717  8576 net.cpp:395] BatchNorm19 -> Convolution21 (in-place)
I0928 20:43:00.345717  8576 net.cpp:150] Setting up BatchNorm19
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49523940
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer Scale19
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer Scale19
I0928 20:43:00.345717  8576 net.cpp:434] Scale19 <- Convolution21
I0928 20:43:00.345717  8576 net.cpp:395] Scale19 -> Convolution21 (in-place)
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer Scale19
I0928 20:43:00.345717  8576 net.cpp:150] Setting up Scale19
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49724644
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer Eltwise9
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer Eltwise9
I0928 20:43:00.345717  8576 net.cpp:434] Eltwise9 <- Eltwise8_Eltwise8_0_split_1
I0928 20:43:00.345717  8576 net.cpp:434] Eltwise9 <- Convolution21
I0928 20:43:00.345717  8576 net.cpp:408] Eltwise9 -> Eltwise9
I0928 20:43:00.345717  8576 net.cpp:150] Setting up Eltwise9
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 64 28 28 (50176)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925348
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer Pooling5
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer Pooling5
I0928 20:43:00.345717  8576 net.cpp:434] Pooling5 <- Eltwise9
I0928 20:43:00.345717  8576 net.cpp:408] Pooling5 -> Pooling5
I0928 20:43:00.345717  8576 net.cpp:150] Setting up Pooling5
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 64 1 1 (64)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925604
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer InnerProduct4
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer InnerProduct4
I0928 20:43:00.345717  8576 net.cpp:434] InnerProduct4 <- Pooling5
I0928 20:43:00.345717  8576 net.cpp:408] InnerProduct4 -> InnerProduct4
I0928 20:43:00.345717  8576 net.cpp:150] Setting up InnerProduct4
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 2 (2)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925612
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer InnerProduct4_InnerProduct4_0_split
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer InnerProduct4_InnerProduct4_0_split
I0928 20:43:00.345717  8576 net.cpp:434] InnerProduct4_InnerProduct4_0_split <- InnerProduct4
I0928 20:43:00.345717  8576 net.cpp:408] InnerProduct4_InnerProduct4_0_split -> InnerProduct4_InnerProduct4_0_split_0
I0928 20:43:00.345717  8576 net.cpp:408] InnerProduct4_InnerProduct4_0_split -> InnerProduct4_InnerProduct4_0_split_1
I0928 20:43:00.345717  8576 net.cpp:150] Setting up InnerProduct4_InnerProduct4_0_split
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 2 (2)
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: 1 2 (2)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925628
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0928 20:43:00.345717  8576 net.cpp:434] SoftmaxWithLoss1 <- InnerProduct4_InnerProduct4_0_split_0
I0928 20:43:00.345717  8576 net.cpp:434] SoftmaxWithLoss1 <- ImageData2_ImageData1_1_split_0
I0928 20:43:00.345717  8576 net.cpp:408] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer SoftmaxWithLoss1
I0928 20:43:00.345717  8576 net.cpp:150] Setting up SoftmaxWithLoss1
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: (1)
I0928 20:43:00.345717  8576 net.cpp:160]     with loss weight 1
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925632
I0928 20:43:00.345717  8576 layer_factory.cpp:58] Creating layer Accuracy1
I0928 20:43:00.345717  8576 net.cpp:100] Creating Layer Accuracy1
I0928 20:43:00.345717  8576 net.cpp:434] Accuracy1 <- InnerProduct4_InnerProduct4_0_split_1
I0928 20:43:00.345717  8576 net.cpp:434] Accuracy1 <- ImageData2_ImageData1_1_split_1
I0928 20:43:00.345717  8576 net.cpp:408] Accuracy1 -> Accuracy1
I0928 20:43:00.345717  8576 net.cpp:150] Setting up Accuracy1
I0928 20:43:00.345717  8576 net.cpp:157] Top shape: (1)
I0928 20:43:00.345717  8576 net.cpp:165] Memory required for data: 49925636
I0928 20:43:00.345717  8576 net.cpp:228] Accuracy1 does not need backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] InnerProduct4_InnerProduct4_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] InnerProduct4 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Pooling5 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise9 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale19 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm19 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution21 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU13 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale18 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm18 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution20 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise8_Eltwise8_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise8 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale17 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm17 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution19 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU12 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale16 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm16 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution18 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise7_Eltwise7_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise7 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] PadChannel2 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Pooling4 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale15 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm15 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution17 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU11 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale14 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm14 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution16 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise6_Eltwise6_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise6 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale13 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm13 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution15 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU10 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale12 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm12 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution14 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise5_Eltwise5_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise5 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale11 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm11 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution13 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU9 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale10 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm10 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution12 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise4_Eltwise4_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise4 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] PadChannel1 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Pooling3 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale9 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm9 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution11 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU8 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale8 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm8 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution10 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise3_Eltwise3_0_split needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Eltwise3 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale7 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] BatchNorm7 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Convolution9 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] ReLU7 needs backward computation.
I0928 20:43:00.345717  8576 net.cpp:226] Scale6 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm6 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution8 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Eltwise2_Eltwise2_0_split needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Eltwise2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Scale5 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm5 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution7 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU6 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Scale4 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm4 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution6 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Eltwise1_Eltwise1_0_split needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Eltwise1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Scale3 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm3 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution5 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU5 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Scale2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution4 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution3_ReLU4_0_split needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU4 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Scale1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] BatchNorm1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution3 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Transformer1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] InnerProduct3 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] InnerProduct2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU3 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] InnerProduct1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Pooling2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution2 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Pooling1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] ReLU1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:226] Convolution1 needs backward computation.
I0928 20:43:00.361317  8576 net.cpp:228] ImageData2_ImageData1_1_split does not need backward computation.
I0928 20:43:00.361317  8576 net.cpp:228] ImageData1_ImageData1_0_split does not need backward computation.
I0928 20:43:00.361317  8576 net.cpp:228] ImageData1 does not need backward computation.
I0928 20:43:00.361317  8576 net.cpp:270] This network produces output Accuracy1
I0928 20:43:00.361317  8576 net.cpp:270] This network produces output SoftmaxWithLoss1
I0928 20:43:00.361317  8576 net.cpp:283] Network initialization done.
I0928 20:43:00.361317  8576 solver.cpp:60] Solver scaffolding done.
I0928 20:43:00.361317  8576 caffe.cpp:252] Starting Optimization
I0928 20:43:00.361317  8576 solver.cpp:279] Solving resnet_cifar10
I0928 20:43:00.361317  8576 solver.cpp:280] Learning Rate Policy: step
I0928 20:43:00.376917  8576 transformer_layer.cpp:48] theta:4.84829e-005 4.81206e-005 0.000135965
3.72535e-005 0.000142627 7.27602e-005
I0928 20:43:00.376917  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:00.376917  8576 transformer_layer.cpp:65] 3.9362e-005 4.02213e-005 4.10806e-005
4.19398e-005 4.27991e-005 4.36584e-005
4.45177e-005 4.5377e-005 4.62363e-005
4.70956e-005 4.79549e-005 4.88142e-005
4.96735e-005 5.05328e-005 5.13921e-005
5.22514e-005 5.31107e-005 5.397e-005
I0928 20:43:00.798118  8576 solver.cpp:228] Iteration 0, loss = 0.69326
I0928 20:43:00.798118  8576 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.69326 (* 1 = 0.69326 loss)
I0928 20:43:00.798118  8576 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0928 20:43:00.813719  8576 transformer_layer.cpp:48] theta:0.010336 -0.00923382 -0.00263001
-0.00272014 0.00450442 0.0100793
I0928 20:43:00.813719  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:00.813719  8576 transformer_layer.cpp:65] -0.00373221 -0.0038971 -0.00406199
-0.00422688 -0.00439177 -0.00455666
-0.00472155 -0.00488644 -0.00505133
-0.00521622 -0.00538111 -0.005546
-0.00571089 -0.00587578 -0.00604067
-0.00620556 -0.00637045 -0.00653534
I0928 20:43:01.234920  8576 transformer_layer.cpp:48] theta:0.0197514 -0.0174962 -0.00513344
-0.00523405 0.00870034 0.0193559
I0928 20:43:01.234920  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:01.234920  8576 transformer_layer.cpp:65] -0.00738859 -0.00770103 -0.00801346
-0.00832589 -0.00863832 -0.00895076
-0.00926319 -0.00957562 -0.00988805
-0.0102005 -0.0105129 -0.0108253
-0.0111378 -0.0114502 -0.0117626
-0.0120751 -0.0123875 -0.0126999
I0928 20:43:01.624920  8576 transformer_layer.cpp:48] theta:0.0336245 -0.0277257 -0.0110826
-0.00873742 0.0139642 0.0446908
I0928 20:43:01.624920  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:01.624920  8576 transformer_layer.cpp:65] -0.0169814 -0.0174765 -0.0179716
-0.0184667 -0.0189618 -0.0194569
-0.019952 -0.0204471 -0.0209422
-0.0214373 -0.0219324 -0.0224275
-0.0229227 -0.0234178 -0.0239129
-0.024408 -0.0249031 -0.0253982
I0928 20:43:02.014920  8576 transformer_layer.cpp:48] theta:0.0991767 -0.102343 -0.0465325
-0.0394671 -0.00749758 0.0441301
I0928 20:43:02.014920  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:02.014920  8576 transformer_layer.cpp:65] -0.0433667 -0.0451942 -0.0470218
-0.0488493 -0.0506769 -0.0525044
-0.054332 -0.0561595 -0.057987
-0.0598146 -0.0616421 -0.0634697
-0.0652972 -0.0671248 -0.0689523
-0.0707799 -0.0726074 -0.074435
I0928 20:43:02.420521  8576 transformer_layer.cpp:48] theta:0.180086 -0.202928 -0.0860966
-0.0751057 -0.0386656 0.047323
I0928 20:43:02.420521  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:02.420521  8576 transformer_layer.cpp:65] -0.0632555 -0.0668792 -0.0705029
-0.0741266 -0.0777503 -0.081374
-0.0849977 -0.0886215 -0.0922451
-0.0958689 -0.0994926 -0.103116
-0.10674 -0.110364 -0.113987
-0.117611 -0.121235 -0.124859
I0928 20:43:02.810523  8576 transformer_layer.cpp:48] theta:0.254892 -0.296574 -0.121408
-0.108421 -0.068221 0.048269
I0928 20:43:02.810523  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:02.810523  8576 transformer_layer.cpp:65] -0.0797249 -0.0850209 -0.0903169
-0.0956128 -0.100909 -0.106205
-0.111501 -0.116797 -0.122093
-0.127389 -0.132685 -0.137981
-0.143277 -0.148573 -0.153868
-0.159164 -0.16446 -0.169756
I0928 20:43:03.216122  8576 transformer_layer.cpp:48] theta:0.322546 -0.379702 -0.154902
-0.142025 -0.0973091 0.0431625
I0928 20:43:03.216122  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:03.231722  8576 transformer_layer.cpp:65] -0.0977464 -0.104527 -0.111307
-0.118088 -0.124868 -0.131648
-0.138429 -0.145209 -0.15199
-0.15877 -0.16555 -0.172331
-0.179111 -0.185892 -0.192672
-0.199452 -0.206233 -0.213013
I0928 20:43:03.637323  8576 transformer_layer.cpp:48] theta:0.382783 -0.456079 -0.184156
-0.170808 -0.124426 0.0418768
I0928 20:43:03.637323  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:03.637323  8576 transformer_layer.cpp:65] -0.11086 -0.119004 -0.127148
-0.135292 -0.143437 -0.151581
-0.159725 -0.167869 -0.176014
-0.184158 -0.192302 -0.200447
-0.208591 -0.216735 -0.224879
-0.233024 -0.241168 -0.249312
I0928 20:43:04.027324  8576 transformer_layer.cpp:48] theta:0.437183 -0.526019 -0.209321
-0.195872 -0.148454 0.0410069
I0928 20:43:04.027324  8576 transformer_layer.cpp:52] -1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
-1 -1 -1
I0928 20:43:04.027324  8576 transformer_layer.cpp:65] -0.120486 -0.129879 -0.139272
-0.148666 -0.158059 -0.167452
-0.176845 -0.186238 -0.195632
-0.205025 -0.214418 -0.223811
-0.233204 -0.242598 -0.251991
-0.261384 -0.270777 -0.28017
I0928 20:43:04.432925  8576 solver.cpp:454] Snapshotting to binary proto file snapshots/test_iter_10.caffemodel
I0928 20:43:04.448525  8576 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/test_iter_10.solverstate
I0928 20:43:04.448525  8576 solver.cpp:322] Optimization Done.
I0928 20:43:04.464125  8576 caffe.cpp:255] Optimization Done.
